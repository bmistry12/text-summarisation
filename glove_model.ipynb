{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "glove-model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bV27LCvjfwkR",
        "outputId": "fb15ad49-619a-4b36-cbf8-a774ac682e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "!python -m nltk.downloader stopwords wordnet punkt averaged_perceptron_tagger\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.layers import Attention\n",
        "from keras.models import Model, load_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install rouge\n",
        "from rouge import Rouge\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/63/ac/b93411318529980ab7f41e59ed64ec3ffed08ead32389e29eb78585dd55d/rouge-0.3.2-py3-none-any.whl\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2feqtBEHiaS4"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "omclwb_CiEZr",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=10\n",
        "EPOCHS=200\n",
        "latent_dim=256\n",
        "embedding_dim=50\n",
        "test_train_split=0.15\n",
        "build_number=\"1\"\n",
        "LEARNING_RATE=0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L1hVy0J07Gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create rouge object for evaluation\n",
        "rouge = Rouge()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gNPOLXNLiiX5"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cchT-sW8kGP4"
      },
      "source": [
        "Read In Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1LLVyg34iLP5",
        "outputId": "3eeaca80-04e4-46c7-f20b-2d39f011dcfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Only needed if running on Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vtGVB1bR9KHT",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('./drive/My Drive/originals-l.csv')\n",
        "# df = pd.read_csv('./Reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "869501f5-ec3c-454a-a321-81d6be5a561f",
        "id": "9GeVXWUS9JRL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "df.count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.count of       Unnamed: 0  ...                                            summary\n",
              "0              0  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "1              1  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "2              2  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "3              3  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "4              4  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "...          ...  ...                                                ...\n",
              "3096        3096  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "3097        3097  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "3098        3098  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "3099        3099  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "3100        3100  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "\n",
              "[3101 rows x 4 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "541c55bd-5d17-4114-bf30-80480674e4b4",
        "id": "PYplzyHC9I_c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>file</th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01.story</td>\n",
              "      <td>Its official US President Barack Obama want la...</td>\n",
              "      <td>Syrian official Obama climbed top tree doesnt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef.story</td>\n",
              "      <td>Its official US President Barack Obama want la...</td>\n",
              "      <td>Syrian official Obama climbed top tree doesnt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>00027e965c8264c35cc1bc55556db388da82b07f.story</td>\n",
              "      <td>Its official US President Barack Obama want la...</td>\n",
              "      <td>Syrian official Obama climbed top tree doesnt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0002c17436637c4fe1837c935c04de47adb18e9a.story</td>\n",
              "      <td>Its official US President Barack Obama want la...</td>\n",
              "      <td>Syrian official Obama climbed top tree doesnt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0003ad6ef0c37534f80b55b4235108024b407f0b.story</td>\n",
              "      <td>Its official US President Barack Obama want la...</td>\n",
              "      <td>Syrian official Obama climbed top tree doesnt ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                            summary\n",
              "0           0  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "1           1  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "2           2  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "3           3  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "4           4  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QZzZjP4vFzVw"
      },
      "source": [
        "Remove .'s that appear in stuff like U.S.A and U.N - Eventually need to move this to dataprocessing.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4e3a1UjziN5g",
        "colab": {}
      },
      "source": [
        "# print(df['summary'][0])\n",
        "# df['summary'] = df['summary'].apply(lambda x: re.sub(r'\\..*$',' ',str(x)))\n",
        "# print(df['summary'][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "60CqA1Km6PvJ",
        "outputId": "3a5d4fc4-c47d-447b-d0b2-9b5ca0e66d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(df['summary'][0])\n",
        "df['summary'] = df['summary'].apply(lambda x: re.sub(r'\\.','',str(x)))\n",
        "print(df['summary'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Syrian official Obama climbed top tree doesnt know get Obama sends letter heads House Senate Obama seek congressional approval military action Syria Aim determine whether CW used says U.N. spokesman\n",
            "Syrian official Obama climbed top tree doesnt know get Obama sends letter heads House Senate Obama seek congressional approval military action Syria Aim determine whether CW used says UN spokesman\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jmYf4I1bGA8N"
      },
      "source": [
        "Check for rows with null values in them, and copy these into a new dataframe (df1). Drop any rows in df1 from df to ensure no NaN valued rows are present/\n",
        "\n",
        "*Note. using simply dropna(how='any') does not seem to drop any of the rows*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Ws0uSZv8Xnw",
        "outputId": "25735dcc-c5b1-433d-dfd1-16f79741d3fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(df.isnull().values.any())\n",
        "print(df.shape)\n",
        "\n",
        "df1 = df[df.isna().any(axis=1)]\n",
        "print(df1.shape)\n",
        "\n",
        "df.drop(df1.index, axis=0,inplace=True)\n",
        "print(df.shape)\n",
        "print(df.isnull().values.any())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "(3101, 4)\n",
            "(0, 4)\n",
            "(3101, 4)\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AECubdYP9dsc",
        "colab_type": "text"
      },
      "source": [
        "Cut down text to 20 words, and summaries to 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0W-le6ofi74",
        "colab_type": "code",
        "outputId": "b54870de-151a-477d-f8a6-187f05d6a578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(df['text'][0])\n",
        "df['text'] = df['text'].apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: \" \".join(x[:20]))\n",
        "print(df['text'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Its official US President Barack Obama want lawmaker weigh whether use military force Syria Obama sent letter head House Senate Saturday night hour announce believe military action Syrian target right step take allege use chemical weapon The propose legislation Obama asks Congress approve use military force deter disrupt prevent degrade potential future us chemical weapon weapon mass destruction Its step set turn international crisis fierce domestic political battle There key question loom debate What UN weapon inspector find Syria What happens Congress vote And Syrian government react In televise address White House Rose Garden earlier Saturday president say would take case Congress want While I believe I authority carry military action without specific congressional authorization I know country strong take course action even effective say We debate issue big business usual Obama say top congressional leader agree schedule debate body return Washington September 9 The Senate Foreign Relations Committee hold hearing matter Tuesday Sen Robert Menendez say Transcript Read Obamas full remark Syrian crisis Latest development UN inspector leave Syria Obamas remark come shortly UN inspector left Syria carry evidence determine whether chemical weapon use attack early last week Damascus suburb The aim game mandate clear ascertain whether chemical weapon use UN spokesman Martin Nesirky told reporter Saturday But use weapon report toxic gas attack Damascus suburb August 21 key point global debate Syrian crisis Top US official say there doubt Syrian government behind Syrian official deny responsibility blame jihadist fight rebel British US intelligence report say attack involve chemical weapon UN official stress importance wait official report inspector The inspector share finding UN SecretaryGeneral Ban Kimoon Ban say want wait UN team final report complete present UN Security Council The Organization Prohibition Chemical Weapons nine inspector belong say Saturday could take three week analyze evidence collect It need time able analyze information sample Nesirky say He note Ban repeatedly say alternative political solution crisis Syria military solution option Bergen Syria problem hell US Obama This menace must confront Obamas senior adviser debate next step take president comment Saturday come amid mount political pressure situation Syria Some US lawmaker call immediate action others warn step could become quagmire Some global leader express support British Parliaments vote military action earlier week blow Obamas hope get strong backing key NATO ally On Saturday Obama propose say would limited military action Syrian President Bashar alAssad Any military attack would openended include US ground force say Syrias allege use chemical weapon earlier month assault human dignity president say A failure respond force Obama argue could lead escalate use chemical weapon proliferation terrorist group would people harm In world many danger menace must confront Syria missile strike What would happen next Map US allied asset around Syria Obama decision come Friday night On Friday night president make lastminute decision consult lawmaker What happen vote Its unclear A senior administration official told CNN Obama authority act without Congress even Congress reject request authorization use force Obama Saturday continued shore support strike alAssad government He spoke phone French President Francois Hollande Rose Garden speech The two leader agree international community must deliver resolute message Assad regime others would consider use chemical weapon crime unacceptable violate international norm held accountable world White House say Meanwhile uncertainty loom Congress would weigh US military official say remain ready 5 key assertion US intelligence report Syria Syria Who want chemical weapon horror Reactions mixed Obamas speech A spokesman Syrian National Coalition say opposition group disappointed Obamas announcement Our fear lack action could embolden regime repeat attack serious way say spokesman Louay Safi So quite concerned Some member Congress applaud Obamas decision House Speaker John Boehner Majority Leader Eric Cantor Majority Whip Kevin McCarthy Conference Chair Cathy McMorris Rodgers issue statement Saturday praise president Under Constitution responsibility declare war lie Congress Republican lawmaker say We glad president seek authorization military action Syria response serious substantive question raise More 160 legislator include 63 Obamas fellow Democrats sign letter call either vote least full debate US action British Prime Minister David Cameron whose attempt get lawmaker country support military action Syria fail earlier week respond Obamas speech Twitter post Saturday I understand support Barack Obamas position Syria Cameron say An influential lawmaker Russia stood Syria criticize United States theory The main reason Obama turn Congress military operation get enough support either world among ally US United States Alexei Pushkov chairman internationalaffairs committee Russian State Duma say Twitter post In United States scatter group antiwar protester around country take street Saturday Like many Americanswere tire United States get involve invade bombing country say Robin Rosecrans among hundred Los Angeles demonstration What Syrias neighbor think Why Russia China Iran stand Assad Syrias government unfazed After Obamas speech military political analyst Syrian state TV say Obama embarrass Russia opposes military action Syria cry help someone come rescue face two defeat political military level Syrias prime minister appear unfazed saberrattling The Syrian Armys status maximum readiness finger trigger confront challenge Wael Nader alHalqi say meeting delegation Syrian expatriate Italy accord banner Syria State TV broadcast prior Obamas address An anchor Syrian state television say Obama appear prepare aggression Syria base repeat lie A top Syrian diplomat told state television network Obama face pressure take military action Israel Turkey Arabs rightwing extremist United States I think do well Cameron term take issue Parliament say Bashar Jaafari Syrias ambassador United Nations Both Obama Cameron say climbed top tree dont know get The Syrian government deny use chemical weapon August 21 attack say jihadist fight rebel use effort turn global sentiment British intelligence put number people kill attack 350 On Saturday Obama say told well 1000 people murder US Secretary State John Kerry Friday cite death toll 1429 400 child No explanation offer discrepancy Iran US military action Syria would spark disaster Opinion Why strike Syria bad idea\n",
            "Its official US President Barack Obama want lawmaker weigh whether use military force Syria Obama sent letter head House Senate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNwMSyzZgexI",
        "colab_type": "code",
        "outputId": "58e10976-7342-4f5e-f893-236f3298ae28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(df['summary'][0])\n",
        "df['summary'] = df['summary'].apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: \" \".join(x[:10]))\n",
        "print(df['summary'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Syrian official Obama climbed top tree doesnt know get Obama sends letter heads House Senate Obama seek congressional approval military action Syria Aim determine whether CW used says UN spokesman\n",
            "Syrian official Obama climbed top tree doesnt know get Obama\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nSVW1P-Ji_7R"
      },
      "source": [
        "Word Count Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M72pGpsDjCrc",
        "outputId": "e23166ef-ed7d-40a7-fed2-1affed67878a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in df['text']:\n",
        "      text_word_count.append(len(i.split(' ')))\n",
        "\n",
        "for i in df['summary']:\n",
        "      summary_word_count.append(len(i.split(' ')))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.ylabel('Documents')\n",
        "plt.xlabel('Word Count')\n",
        "# plt.savefig('word_count_distro' + str(build_number) + '.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEWCAYAAACAOivfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM8uYk4CZWcacBMzMMvZfBCLosyrzgBIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s89eZTkH8YrD",
        "colab_type": "code",
        "outputId": "44d08c2d-f70f-4031-e6bb-f68738379451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "word_dict = {}\n",
        "text = df['text'].apply(lambda x: nltk.word_tokenize(x))\n",
        "\n",
        "for index, row in text.iteritems():\n",
        "  for word in row:\n",
        "    if word not in word_dict.keys():\n",
        "      word_dict[word] = 1\n",
        "    else:\n",
        "      word_dict[word] += 1\n",
        "\n",
        "print(len(word_dict))\n",
        "sorted_dict = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "print(sorted_dict)\n",
        "x, y = zip(*sorted_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n",
            "[('Obama', 6202), ('Its', 3101), ('official', 3101), ('US', 3101), ('President', 3101), ('Barack', 3101), ('want', 3101), ('lawmaker', 3101), ('weigh', 3101), ('whether', 3101), ('use', 3101), ('military', 3101), ('force', 3101), ('Syria', 3101), ('sent', 3101), ('letter', 3101), ('head', 3101), ('House', 3101), ('Senate', 3101)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BylQYAlHFbNb",
        "colab_type": "code",
        "outputId": "65bb134b-6346-4635-e804-0f2fde0a459e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# accept_words = list(x[3:])\n",
        "accept_words = list(x)\n",
        "accept_words = [x.lower() for x in accept_words]\n",
        "print(accept_words)\n",
        "print(df['text'][2])\n",
        "# print(df['text'][451])\n",
        "df['text'] = df['text'].apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: \" \".join([word for word in x if word.lower() in accept_words]))\n",
        "print(df['text'][2])\n",
        "# print(df['text'][451])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['obama', 'its', 'official', 'us', 'president', 'barack', 'want', 'lawmaker', 'weigh', 'whether', 'use', 'military', 'force', 'syria', 'sent', 'letter', 'head', 'house', 'senate']\n",
            "Its official US President Barack Obama want lawmaker weigh whether use military force Syria Obama sent letter head House Senate\n",
            "Its official US President Barack Obama want lawmaker weigh whether use military force Syria Obama sent letter head House Senate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhk5FT8jLtds",
        "colab_type": "code",
        "outputId": "4a193d34-71bb-43d3-a739-d36fc00f25d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "word_dict = {}\n",
        "text = df['summary'].apply(lambda x: nltk.word_tokenize(x))\n",
        "\n",
        "for index, row in text.iteritems():\n",
        "  for word in row:\n",
        "    if word not in word_dict.keys():\n",
        "      word_dict[word] = 1\n",
        "    else:\n",
        "      word_dict[word] += 1\n",
        "\n",
        "print(len(word_dict))\n",
        "sorted_dict = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "print(sorted_dict)\n",
        "x, y = zip(*sorted_dict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[('Obama', 6202), ('Syrian', 3101), ('official', 3101), ('climbed', 3101), ('top', 3101), ('tree', 3101), ('doesnt', 3101), ('know', 3101), ('get', 3101)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS67k2PkLuzc",
        "colab_type": "code",
        "outputId": "f9383b66-2642-4691-aa8f-552ce3d9e636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# accept_words = list(x[4:])\n",
        "accept_words = list(x)\n",
        "accept_words = [x.lower() for x in accept_words]\n",
        "print(accept_words)\n",
        "print(df['summary'][2])\n",
        "# print(df['summary'][451])\n",
        "df['summary'] = df['summary'].apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: \" \".join([word for word in x if word.lower() in accept_words]))\n",
        "print(df['summary'][2])\n",
        "# print(df['summary'][451])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['obama', 'syrian', 'official', 'climbed', 'top', 'tree', 'doesnt', 'know', 'get']\n",
            "Syrian official Obama climbed top tree doesnt know get Obama\n",
            "Syrian official Obama climbed top tree doesnt know get Obama\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbpPDk83ZSXI",
        "colab_type": "code",
        "outputId": "c8ccb162-004e-4f12-f492-03ee3184863b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in df['text']:\n",
        "      text_word_count.append(len(i.split(' ')))\n",
        "\n",
        "for i in df['summary']:\n",
        "      summary_word_count.append(len(i.split(' ')))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.ylabel('Documents')\n",
        "plt.xlabel('Word Count')\n",
        "# plt.savefig('word_count_distro' + str(build_number) + '.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEWCAYAAACAOivfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM8uYk4CZWcacBMzMMvZfBCLosyrzgBIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nNZ2tVpljHTc"
      },
      "source": [
        "Max Text Lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3T01Jf-XjGKO",
        "outputId": "4eb0e92d-1c55-45fb-89c7-572da4015148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "max_text_len = max([len(txt.split(' ')) for txt in df['text']])\n",
        "max_summary_len = max([len(txt.split(' ')) for txt in df['summary']])\n",
        "print(max_text_len)\n",
        "print(max_summary_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CGl1z0OFjTsr"
      },
      "source": [
        "### Training-Validation Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SwmBST04juu6"
      },
      "source": [
        "X - Articles text </br>\n",
        "Y - Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f1_YrHcDjN6e",
        "colab": {}
      },
      "source": [
        "# convert to numpy array\n",
        "X = np.array(df['text'])\n",
        "Y = np.array(df['summary'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XGHJXwaojYAV",
        "outputId": "215574f6-6e9a-446c-8c0c-b8caeb37762a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "x_tr,x_val,y_tr,y_val=train_test_split(X,Y,test_size=test_train_split,random_state=0,shuffle=True)\n",
        "print(x_tr.shape)\n",
        "print(x_val.shape)\n",
        "print(y_tr.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2635,)\n",
            "(466,)\n",
            "(2635,)\n",
            "(466,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F9BaBUY0YaQ",
        "colab_type": "text"
      },
      "source": [
        "## GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymiCWKv90X7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_index = {}\n",
        "with open('./drive/My Drive/glove/glove.6B.' + str(embedding_dim) + 'd.txt') as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embedding_index[word] = coefs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIZvswoZmlCb",
        "colab_type": "code",
        "outputId": "22285120-d393-467a-eb01-5a9f6af4b89b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(embedding_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbjgCoOmmwb6",
        "colab_type": "code",
        "outputId": "37286e0d-f212-4e14-e425-df62f70b3710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print(embedding_index.get(\"us\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.19086    0.24339    1.2768    -0.038207   0.6094    -0.70188\n",
            "  0.040862  -0.44903    0.0080416 -0.18819   -0.68578   -0.12465\n",
            " -0.32855   -0.073507   0.79112    0.31981    0.081126  -0.033057\n",
            " -0.6007     0.014536   0.42773    0.71318    0.13327   -0.64247\n",
            "  0.066402  -2.2346     0.013668  -0.45647    0.40542   -0.0042052\n",
            "  3.4561     0.54602   -0.3789     0.58198   -0.22852   -0.8409\n",
            " -0.30465   -0.69669   -0.4232    -0.81757    0.036113   0.25739\n",
            "  1.745     -0.61482    0.41547    0.40002   -0.51528    0.89973\n",
            " -0.54324    0.69393  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SzWpoc9OjjdV"
      },
      "source": [
        "### Word Embeddings - Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iLVdVklnjq1i"
      },
      "source": [
        "X Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z7qUrNpbjpI2",
        "outputId": "ab2190ef-fac6-494c-e13f-dd4250b2dee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_dict = {}\n",
        "text = df['text']\n",
        "\n",
        "for row in text: \n",
        "  for word in row.split(\" \"):\n",
        "    if word not in word_dict:\n",
        "      word_dict[word] = 1\n",
        "    else:\n",
        "      word_dict[word] += 1\n",
        "\n",
        "print(len(word_dict))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnrYczEn19K8",
        "colab_type": "code",
        "outputId": "f3e8cf53-59d6-4133-df86-703576fa962d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=len(word_dict), split=\" \") \n",
        "x_tokenizer.fit_on_texts(list(X))\n",
        "\n",
        "x_embedding_matrix = np.zeros(((x_tokenizer.num_words)+1, embedding_dim),dtype='float32')\n",
        "print(x_embedding_matrix.shape)\n",
        "for word,i in x_tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in glove will be zeros\n",
        "        x_embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6qbg_6TKj4HK",
        "outputId": "1d563e2b-b194-45ef-e49f-a4923afdd262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# # #prepare a tokenizer for reviews on training data\n",
        "# x_tokenizer = Tokenizer(num_words=len(word_dict), split=\" \") \n",
        "# x_tokenizer.fit_on_texts(list(X))\n",
        "\n",
        "# #convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=x_voc, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=x_voc, padding='post')\n",
        "\n",
        "print(x_voc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7HbKly2Ld64",
        "colab_type": "code",
        "outputId": "f5e7eee6-2020-4383-843f-4fa55c702b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(x_tokenizer.num_words)\n",
        "print(x_voc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6NsdijM3j6RJ"
      },
      "source": [
        "Y Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CG6Q2G-Wj79A",
        "outputId": "c6b3cb38-816e-4e54-f703-bc4fc1488aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_word_dict = {}\n",
        "summ = df['summary']\n",
        "\n",
        "for row in summ: \n",
        "  for word in row.split(\" \"):\n",
        "    if word not in y_word_dict:\n",
        "      y_word_dict[word] = 1\n",
        "    else:\n",
        "      y_word_dict[word] += 1\n",
        "\n",
        "print(len(y_word_dict))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJg5DOHaVFR2",
        "colab_type": "code",
        "outputId": "6b4c44d7-2cef-4606-c591-8a6fb7d4b4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=len(y_word_dict), split=\" \") \n",
        "y_tokenizer.fit_on_texts(list(Y))\n",
        "\n",
        "y_embedding_matrix = np.zeros((x_tokenizer.num_words +1, embedding_dim),dtype='float32')\n",
        "print(y_embedding_matrix.shape)\n",
        "print(len( y_tokenizer.word_index))\n",
        "for word,i in y_tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "    # Words not found in glove will be zeros\n",
        "        y_embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 50)\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C5ugAAnIj91g",
        "outputId": "e46b4562-613d-4e92-a011-c16f4d42448b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "# y_tokenizer = Tokenizer(num_words=len(y_word_dict), split=\" \") \n",
        "# y_tokenizer.fit_on_texts(list(Y))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words + 1\n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=x_voc, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=x_voc, padding='post')\n",
        "\n",
        "print(y_voc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUlUQubBBDwy",
        "colab_type": "text"
      },
      "source": [
        "### GloVe Word Coverage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85ljb_dXBhaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def coverage(dict, total):\n",
        "  covered = 0\n",
        "  for words, _ in dict.items():\n",
        "    if embedding_index.get(word) is not None:\n",
        "      covered += 1\n",
        "  return (covered/total * 100)\n",
        "\n",
        "text_total = len()\n",
        "text_covered = coverage(x_word_dict,text_total)\n",
        "\n",
        "summ_total = len()\n",
        "summ_covered = coverage(y_word_dict,summ_total)\n",
        "\n",
        "print(\"Original Text Coverage: \" + str(text_covered) + \"%\")\n",
        "print(\"Summary Coverage: \" + str(summ_covered) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zntqptcwj_lh"
      },
      "source": [
        "## Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uc0JOUvqkWUL"
      },
      "source": [
        "#### Encoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9dx-9BT6kZMw",
        "colab": {}
      },
      "source": [
        "# bidirectional encoder\n",
        "encoder_inputs = Input(shape=(x_voc,))\n",
        "#embedding layer\n",
        "# changed trainable to false\n",
        "# enc_emb_layer =  Embedding(x_voc,embedding_dim,trainable=True)\n",
        "enc_emb_layer = Embedding(x_voc, embedding_dim, weights=[x_embedding_matrix], \n",
        "                          input_length=x_voc, trainable=False)\n",
        "enc_emb = enc_emb_layer(encoder_inputs)\n",
        "\n",
        "#encoder lstm \n",
        "encoder_lstm = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True))\n",
        "encoder_outputs, fw_state_h, fw_state_c, bw_state_h, bw_state_c = encoder_lstm(enc_emb)\n",
        "\n",
        "state_h = Concatenate()([fw_state_h, bw_state_h])\n",
        "state_c = Concatenate()([fw_state_c, bw_state_c])\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8JJUPBdfkdlb"
      },
      "source": [
        "#### Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VLgYfdF3kb1A",
        "colab": {}
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(x_voc,))\n",
        "\n",
        "#embedding layer\n",
        "#changed trainable to false\n",
        "# dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=False)\n",
        "dec_emb_layer = Embedding(x_voc, embedding_dim,\n",
        "                          weights=[y_embedding_matrix], input_length=x_voc, \n",
        "                          trainable=False)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim*2, return_sequences=True, return_state=True)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(\n",
        "    dec_emb, initial_state=encoder_states)\n",
        "                                                          \n",
        "#dense layer\n",
        "decoder_dense = Dense(y_voc, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rIpBF_fAkfuG"
      },
      "source": [
        "#### Combined LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ASIlTOT_khrn",
        "outputId": "6cdc3fdd-9c35-4081-f5fd-e2ef07dee2bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 20, 50)       1000        input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_20 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) [(None, 20, 512), (N 628736      embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 20, 50)       1000        input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 512)          0           bidirectional_4[0][1]            \n",
            "                                                                 bidirectional_4[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 512)          0           bidirectional_4[0][2]            \n",
            "                                                                 bidirectional_4[0][4]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   [(None, 20, 512), (N 1153024     embedding_8[0][0]                \n",
            "                                                                 concatenate_7[0][0]              \n",
            "                                                                 concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 20, 10)       5130        lstm_8[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,788,890\n",
            "Trainable params: 1,786,890\n",
            "Non-trainable params: 2,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi9_HXvVwS1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = RMSprop(lr=LEARNING_RATE, rho=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gMQ1ZrF0ksMT",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o12XRjJykuA-"
      },
      "source": [
        "- Early Stopping Callback to ensure we stop when Validation Loss is lowest - minimises risk of overfitting\n",
        "- Model Checkpoint saves the model after each epoch so that we can load the model with the best weights later on. Alternatively, it allows us to continue training the model at a later data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6R-qwZoNkspo",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3, restore_best_weights=False)\n",
        "filepath = \"./drive/My Drive/project-model/saved-model-{epoch:02d}.hdf5\"\n",
        "mc = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02-CPYWhXiYz",
        "colab_type": "text"
      },
      "source": [
        "#### Use this method to train a new model. To continue training a previously trained model see below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Yil8ApSM-sK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# history = model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:], batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[es], validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4ScM7ZQNZwy",
        "colab_type": "code",
        "outputId": "950ec70c-d51a-49f5-864d-8cdc15a46346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(x_tr.shape)\n",
        "print(y_tr.shape)\n",
        "print(y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1).shape)\n",
        "print(y_val.reshape(y_val.shape[0],y_val.shape[1], 1).shape)\n",
        "y_tr_3d = y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)\n",
        "y_val_3d = y_val.reshape(y_val.shape[0],y_val.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2635, 20)\n",
            "(2635, 20)\n",
            "(2635, 20, 1)\n",
            "(466, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pbnxf9ZWk4I0",
        "outputId": "95ef2b2b-9f0a-4d29-e11e-25f4867484df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "history = model.fit([x_tr,y_tr], y_tr_3d, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[es],\n",
        "                    validation_data=([x_val,y_val], y_val_3d))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2635 samples, validate on 466 samples\n",
            "Epoch 1/200\n",
            "2635/2635 [==============================] - 31s 12ms/step - loss: 0.2004 - val_loss: 0.0033\n",
            "Epoch 2/200\n",
            "2635/2635 [==============================] - 29s 11ms/step - loss: 0.0013 - val_loss: 6.2426e-05\n",
            "Epoch 3/200\n",
            "2635/2635 [==============================] - 28s 11ms/step - loss: 1.1127e-05 - val_loss: 1.6808e-06\n",
            "Epoch 4/200\n",
            "2635/2635 [==============================] - 28s 11ms/step - loss: 1.3393e-06 - val_loss: 1.1683e-06\n",
            "Epoch 5/200\n",
            "2635/2635 [==============================] - 29s 11ms/step - loss: 1.1034e-06 - val_loss: 1.0610e-06\n",
            "Epoch 6/200\n",
            "2635/2635 [==============================] - 28s 11ms/step - loss: 1.0528e-06 - val_loss: 1.0431e-06\n",
            "Epoch 7/200\n",
            "2635/2635 [==============================] - 28s 10ms/step - loss: 1.0431e-06 - val_loss: 1.0431e-06\n",
            "Epoch 8/200\n",
            "2635/2635 [==============================] - 27s 10ms/step - loss: 1.0431e-06 - val_loss: 1.0431e-06\n",
            "Epoch 9/200\n",
            "2635/2635 [==============================] - 28s 10ms/step - loss: 1.0431e-06 - val_loss: 1.0431e-06\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N52zaYcKlAXE",
        "outputId": "8abfc7bd-afa9-4dee-a6e3-94ddc5baf670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='validation')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "# plt.savefig('loss' + str(build_number) + '.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJpq28ZhJXaF",
        "colab_type": "code",
        "outputId": "e5b5c1a0-2636-439f-ee30-32275e802973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "print(reverse_source_word_index)\n",
        "print(reverse_target_word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 'obama', 2: 'its', 3: 'official', 4: 'us', 5: 'president', 6: 'barack', 7: 'want', 8: 'lawmaker', 9: 'weigh', 10: 'whether', 11: 'use', 12: 'military', 13: 'force', 14: 'syria', 15: 'sent', 16: 'letter', 17: 'head', 18: 'house', 19: 'senate'}\n",
            "{1: 'obama', 2: 'syrian', 3: 'official', 4: 'climbed', 5: 'top', 6: 'tree', 7: 'doesnt', 8: 'know', 9: 'get'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r1Q7SWH_lGxE",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "biBjzpLQlPhf",
        "outputId": "77e66ec6-1307-4ad9-cfc9-7075176e53c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "encoder_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 20, 50)       1000        input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) [(None, 20, 512), (N 628736      embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 512)          0           bidirectional_4[0][1]            \n",
            "                                                                 bidirectional_4[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 512)          0           bidirectional_4[0][2]            \n",
            "                                                                 bidirectional_4[0][4]            \n",
            "==================================================================================================\n",
            "Total params: 629,736\n",
            "Trainable params: 628,736\n",
            "Non-trainable params: 1,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAvDUaSWaqYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim*2,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim*2,))\n",
        "decoder_hidden_state_input = Input(shape=(x_voc,latent_dim*2))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_inputs)\n",
        "decoder_states = [state_h2, state_c2]\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c], [decoder_outputs2] + decoder_states)\n",
        "# decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs2] + decoder_states)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wmvKd7pNlQXs",
        "outputId": "367bff3a-9bcf-442a-b57f-28db190db1ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "decoder_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_20 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 20, 50)       1000        input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_21 (InputLayer)           (None, 512)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           (None, 512)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   [(None, 20, 512), (N 1153024     embedding_8[1][0]                \n",
            "                                                                 input_21[0][0]                   \n",
            "                                                                 input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 20, 10)       5130        lstm_8[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,159,154\n",
            "Trainable params: 1,158,154\n",
            "Non-trainable params: 1,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ywir6L6wlUE-"
      },
      "source": [
        "### Methods for Reversing Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qoKuk0dElZZm",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jSR-0MHclb0G"
      },
      "source": [
        "### Summarisation Method "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7WYZgAXelbLU",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq): \n",
        "    # Encode the input as state vectors.\n",
        "    print(input_seq)\n",
        "    print(input_seq.shape)\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    print(e_out)\n",
        "    # target = [0,0,0....n] where n = y_voc\n",
        "    target_seq = np.zeros((1, x_voc))\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "      # Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs2] + decoder_states)\n",
        "      # print(target_seq)\n",
        "      output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c]) \n",
        "      print(output_tokens.shape)\n",
        "      print(output_tokens)\n",
        "      print(\"output tokens\")\n",
        "      print(output_tokens[0,-1,:])\n",
        "      print(\"output tokens\")\n",
        "      print(output_tokens[0,-1,:][1:])\n",
        "      sampled_token_index = np.argmax(output_tokens[0, -1, :][1:])\n",
        "      print(sampled_token_index)\n",
        "      if (sampled_token_index != 0 ):\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        # print(sampled_token)\n",
        "        decoded_sentence += ' '+sampled_token\n",
        "      else :\n",
        "        print(\"sadface\")\n",
        "        stop_condition = True\n",
        "      if (len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "              stop_condition = True\n",
        "       # Update the target sequence (of length 1).\n",
        "      # target_seq = np.zeros((1,1))\n",
        "      # target_seq = np.zeros((1, x_voc))\n",
        "      target_seq[0, sampled_token_index] = 1\n",
        "\n",
        "      # Update internal states\n",
        "      e_h, e_c = h, c\n",
        "      \n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "STnQkiZzlhbb"
      },
      "source": [
        "## Test Model Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d_RFVVqxfmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getRouge(gt, pred):\n",
        "  return rouge.get_scores(pred, gt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IC1oCOOHlgjh",
        "outputId": "92cbf5c2-3262-4467-8e38-dbecbf2174b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(0,1):\n",
        "    print(\"Article:\",seq2text(x_tr[i]))\n",
        "    original = seq2summary(y_tr[i])\n",
        "    print(\"Original summary:\",original)\n",
        "    x_tr_i_reshaped = x_tr[i].reshape(1,x_voc)\n",
        "    summary = decode_sequence(x_tr_i_reshaped)\n",
        "    print(\"Generated summary:\",summary)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    if summary != \"\":    \n",
        "      print(\"ROUGE score: \")\n",
        "      score = getRouge(str(summary), str(original))\n",
        "      print(score)\n",
        "      print(score[0].get('rouge-1').get('f'))\n",
        "      print(score[0].get('rouge-1').get('p'))\n",
        "      print(score[0].get('rouge-1').get('r'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article: its official us president barack obama want lawmaker weigh whether use military force syria obama sent letter head house \n",
            "Original summary: syrian official obama climbed top tree doesnt know obama \n",
            "[[ 2  3  4  5  6  1  7  8  9 10 11 12 13 14  1 15 16 17 18  0]]\n",
            "(1, 20)\n",
            "[[[-0.07773072  0.05032222 -0.11376712 ...  0.8891824   0.8311318\n",
            "    0.81105804]\n",
            "  [-0.08259559 -0.03561947 -0.1864926  ...  0.87035155  0.7830941\n",
            "    0.7828974 ]\n",
            "  [-0.14179438 -0.01409576 -0.27232262 ...  0.8034873   0.78099287\n",
            "    0.85959786]\n",
            "  ...\n",
            "  [-0.5627328  -0.72558093 -0.83237237 ...  0.24178576  0.17009717\n",
            "    0.14010893]\n",
            "  [-0.60408497 -0.72696984 -0.80134267 ...  0.11083563  0.13650014\n",
            "    0.05775976]\n",
            "  [-0.5779301  -0.7640892  -0.79729545 ...  0.00171523  0.00132766\n",
            "    0.00165226]]]\n",
            "(1, 20, 10)\n",
            "[[[6.3088324e-12 3.6451173e-10 9.9999964e-01 3.4208688e-07 9.4498250e-11\n",
            "   8.1326239e-12 3.8029718e-11 8.6377079e-11 3.9878123e-12 1.6482303e-11]\n",
            "  [2.7224936e-11 7.7480200e-07 5.6053827e-06 9.9999368e-01 9.0924788e-09\n",
            "   4.4517067e-11 6.1628549e-11 1.0939455e-09 3.5418189e-11 3.2714528e-10]\n",
            "  [2.7401428e-10 9.9973351e-01 2.0912586e-07 2.3787262e-04 2.8229069e-05\n",
            "   4.8737629e-08 1.0260324e-09 9.5999063e-08 5.3646837e-10 3.8634269e-09]\n",
            "  [5.2619537e-10 6.5031706e-04 5.9634315e-09 5.6226277e-08 9.9933112e-01\n",
            "   1.8092742e-05 2.5338286e-08 3.9494631e-07 1.4223680e-09 3.5506862e-09]\n",
            "  [2.1536228e-09 1.8061943e-06 3.9801660e-09 1.1937843e-09 2.2290424e-03\n",
            "   9.9775320e-01 1.0131691e-05 5.7639622e-06 1.9499652e-08 8.6999821e-09]\n",
            "  [1.7821987e-08 5.8075182e-07 8.3008871e-09 2.2712721e-09 3.9982169e-06\n",
            "   1.4491042e-02 9.8464638e-01 8.5654698e-04 1.4949809e-06 1.5120103e-08]\n",
            "  [1.3932970e-08 9.7912323e-07 6.2764891e-09 1.3134523e-09 8.8101920e-08\n",
            "   4.5679790e-06 2.7775103e-03 9.9714738e-01 6.9575923e-05 2.5571663e-09]\n",
            "  [3.9985923e-07 3.7694426e-05 7.5556725e-09 3.0126879e-09 3.5151572e-08\n",
            "   2.7357737e-07 1.8053242e-05 6.3235681e-03 9.9361998e-01 1.1967844e-08]\n",
            "  [2.2167887e-03 8.0890673e-01 2.6959552e-07 4.8998341e-08 5.5958856e-07\n",
            "   2.2190998e-06 2.1746566e-05 3.7590056e-04 1.8847497e-01 7.4057334e-07]\n",
            "  [9.9997103e-01 2.3795465e-05 7.2786128e-09 6.9075540e-10 5.9415375e-09\n",
            "   2.9668220e-08 1.3633371e-07 1.4109146e-07 4.7368335e-06 2.8304214e-08]\n",
            "  [1.0000000e+00 2.3263908e-08 1.0903028e-09 7.4594206e-11 3.4967085e-10\n",
            "   1.6201679e-09 6.0591767e-09 1.8436528e-09 2.5712716e-08 2.2566988e-09]\n",
            "  [1.0000000e+00 8.7535676e-09 1.7502929e-09 1.0717908e-10 4.1422082e-10\n",
            "   1.7507503e-09 6.3371974e-09 1.4150722e-09 1.3977921e-08 2.3699851e-09]\n",
            "  [1.0000000e+00 6.3728463e-09 2.2918039e-09 1.2692968e-10 4.4389339e-10\n",
            "   1.7861868e-09 6.5310086e-09 1.2884649e-09 1.1430096e-08 2.4773219e-09]\n",
            "  [1.0000000e+00 5.1663442e-09 2.7539282e-09 1.3559821e-10 4.4638448e-10\n",
            "   1.6986860e-09 6.2631282e-09 1.1433471e-09 9.6602530e-09 2.5044355e-09]\n",
            "  [1.0000000e+00 4.5538164e-09 3.3938308e-09 1.4888177e-10 4.6579562e-10\n",
            "   1.6639378e-09 6.1696630e-09 1.0697081e-09 8.7195575e-09 2.6453775e-09]\n",
            "  [1.0000000e+00 4.3225001e-09 4.3706838e-09 1.7381424e-10 5.1336518e-10\n",
            "   1.7109055e-09 6.3560819e-09 1.0710842e-09 8.4413445e-09 2.9552270e-09]\n",
            "  [1.0000000e+00 4.3762229e-09 5.8478182e-09 2.1547529e-10 5.9526983e-10\n",
            "   1.8431502e-09 6.8219554e-09 1.1407788e-09 8.6827967e-09 3.4657024e-09]\n",
            "  [1.0000000e+00 4.6851700e-09 8.0444398e-09 2.8028277e-10 7.1965994e-10\n",
            "   2.0679503e-09 7.5682589e-09 1.2764327e-09 9.3705061e-09 4.2215564e-09]\n",
            "  [1.0000000e+00 5.2566582e-09 1.1264119e-08 3.7804687e-10 8.9842866e-10\n",
            "   2.4000955e-09 8.6165750e-09 1.4807642e-09 1.0485605e-08 5.2892544e-09]\n",
            "  [1.0000000e+00 6.1272107e-09 1.5934479e-08 5.2466193e-10 1.1492766e-09\n",
            "   2.8643858e-09 1.0018439e-08 1.7622785e-09 1.2060643e-08 6.7657040e-09]]]\n",
            "output tokens\n",
            "[1.0000000e+00 6.1272107e-09 1.5934479e-08 5.2466193e-10 1.1492766e-09\n",
            " 2.8643858e-09 1.0018439e-08 1.7622785e-09 1.2060643e-08 6.7657040e-09]\n",
            "output tokens\n",
            "[6.1272107e-09 1.5934479e-08 5.2466193e-10 1.1492766e-09 2.8643858e-09\n",
            " 1.0018439e-08 1.7622785e-09 1.2060643e-08 6.7657040e-09]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[1.00000000e+00 7.36601491e-09 2.26723991e-08 7.46322448e-10\n",
            "   1.49910229e-09 3.50012686e-09 1.18624772e-08 2.13690110e-09\n",
            "   1.41823158e-08 8.79250628e-09]\n",
            "  [9.99999881e-01 1.52691229e-07 3.33924071e-08 1.19319532e-09\n",
            "   2.15730744e-09 7.48074225e-09 2.12308500e-08 2.87098212e-09\n",
            "   8.22062862e-09 1.62297997e-08]\n",
            "  [1.00000000e+00 1.44706735e-08 2.70750284e-08 8.72970474e-10\n",
            "   1.99716710e-09 5.48042456e-09 1.62822325e-08 2.79150258e-09\n",
            "   1.29717499e-08 1.03799627e-08]\n",
            "  [1.00000000e+00 1.27452608e-08 3.03159986e-08 1.04096975e-09\n",
            "   2.06535256e-09 5.02774888e-09 1.44675267e-08 2.65080202e-09\n",
            "   1.42339145e-08 1.13335998e-08]\n",
            "  [1.00000000e+00 1.40814533e-08 4.30459934e-08 1.54608415e-09\n",
            "   2.76368395e-09 6.14229290e-09 1.73104091e-08 3.26709748e-09\n",
            "   1.83808506e-08 1.52095136e-08]\n",
            "  [9.99999881e-01 1.70970580e-08 6.31675761e-08 2.37045517e-09\n",
            "   3.81252674e-09 7.85804488e-09 2.16261071e-08 4.17076595e-09\n",
            "   2.39099460e-08 2.08254889e-08]\n",
            "  [9.99999881e-01 2.14838582e-08 9.24815353e-08 3.67127861e-09\n",
            "   5.30440802e-09 1.01948556e-08 2.72443668e-08 5.35179590e-09\n",
            "   3.08193151e-08 2.85775670e-08]\n",
            "  [9.99999642e-01 2.76149752e-08 1.34622837e-07 5.73907499e-09\n",
            "   7.44786721e-09 1.33612721e-08 3.44874316e-08 6.90882196e-09\n",
            "   3.95729991e-08 3.93520132e-08]\n",
            "  [9.99999523e-01 3.61079877e-08 1.94646020e-07 9.04039421e-09\n",
            "   1.05602833e-08 1.76591257e-08 4.38216183e-08 8.98375507e-09\n",
            "   5.07743678e-08 5.44295382e-08]\n",
            "  [9.99999523e-01 4.78439866e-08 2.79256369e-07 1.43104550e-08\n",
            "   1.51128354e-08 2.34946622e-08 5.58371092e-08 1.17668799e-08\n",
            "   6.51561791e-08 7.55937322e-08]\n",
            "  [9.99999046e-01 6.40448832e-08 3.97184891e-07 2.26972574e-08\n",
            "   2.18059739e-08 3.14154001e-08 7.12774977e-08 1.55152495e-08\n",
            "   8.36286418e-08 1.05318819e-07]\n",
            "  [9.99998808e-01 8.63913101e-08 5.59652563e-07 3.59763170e-08\n",
            "   3.16845608e-08 4.21665263e-08 9.10895110e-08 2.05799378e-08\n",
            "   1.07346665e-07 1.47027777e-07]\n",
            "  [9.99998450e-01 1.17178580e-07 7.80904145e-07 5.68634491e-08\n",
            "   4.63090011e-08 5.67705776e-08 1.16488998e-07 2.74439778e-08\n",
            "   1.37785463e-07 2.05429586e-07]\n",
            "  [9.99997854e-01 1.59527758e-07 1.07884500e-06 8.94612668e-08\n",
            "   6.80084540e-08 7.66457546e-08 1.49053136e-07 3.67760862e-08\n",
            "   1.76834902e-07 2.86963513e-07]\n",
            "  [9.99997020e-01 2.17666525e-07 1.47583046e-06 1.39886751e-07\n",
            "   1.00254297e-07 1.03778781e-07 1.90850912e-07 4.95062835e-08\n",
            "   2.26915517e-07 4.00387052e-07]\n",
            "  [9.99996066e-01 2.97298755e-07 1.99971419e-06 2.17139075e-07\n",
            "   1.48202005e-07 1.40980262e-07 2.44622868e-07 6.69327704e-08\n",
            "   2.91126725e-07 5.57557939e-07]\n",
            "  [9.99994636e-01 4.06091289e-07 2.68535837e-06 3.34280600e-07\n",
            "   2.19476135e-07 1.92260188e-07 3.14035049e-07 9.08729092e-08\n",
            "   3.73445459e-07 7.74482885e-07]\n",
            "  [9.99992728e-01 5.54273868e-07 3.57679664e-06 5.10006828e-07\n",
            "   3.25282286e-07 2.63369600e-07 4.04029265e-07 1.23873065e-07\n",
            "   4.78981974e-07 1.07269216e-06]\n",
            "  [9.99990106e-01 7.55369911e-07 4.73033742e-06 7.70688530e-07\n",
            "   4.81966424e-07 3.62573928e-07 5.21308380e-07 1.69500225e-07\n",
            "   6.14311148e-07 1.48102856e-06]\n",
            "  [9.99986529e-01 1.02702995e-06 6.21884328e-06 1.15295893e-06\n",
            "   7.13152644e-07 5.01741624e-07 6.75000422e-07 2.32741698e-07\n",
            "   7.87896568e-07 2.03791251e-06]]]\n",
            "output tokens\n",
            "[9.9998653e-01 1.0270300e-06 6.2188433e-06 1.1529589e-06 7.1315264e-07\n",
            " 5.0174162e-07 6.7500042e-07 2.3274170e-07 7.8789657e-07 2.0379125e-06]\n",
            "output tokens\n",
            "[1.0270300e-06 6.2188433e-06 1.1529589e-06 7.1315264e-07 5.0174162e-07\n",
            " 6.7500042e-07 2.3274170e-07 7.8789657e-07 2.0379125e-06]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[9.99981880e-01 1.39199744e-06 8.13750012e-06 1.70696740e-06\n",
            "   1.05262643e-06 6.97860060e-07 8.77586103e-07 3.20554477e-07\n",
            "   1.01065916e-06 2.79425035e-06]\n",
            "  [9.99956608e-01 2.40378504e-05 8.05473428e-06 1.54741633e-06\n",
            "   1.42097804e-06 1.75342404e-06 1.37319478e-06 4.31977014e-07\n",
            "   5.95855454e-07 4.07648668e-06]\n",
            "  [9.99982476e-01 3.36018002e-06 5.79916423e-06 1.03746754e-06\n",
            "   1.36654785e-06 1.14019269e-06 1.08430038e-06 4.08026551e-07\n",
            "   7.47461513e-07 2.64165692e-06]\n",
            "  [9.99984622e-01 2.15195359e-06 5.41397003e-06 1.01149305e-06\n",
            "   1.22586800e-06 9.79834340e-07 9.60379680e-07 3.74872229e-07\n",
            "   8.01821386e-07 2.46882792e-06]\n",
            "  [9.99983191e-01 1.87811975e-06 6.24245968e-06 1.20130437e-06\n",
            "   1.32845651e-06 1.03102263e-06 1.04678247e-06 4.19520205e-07\n",
            "   9.62549620e-07 2.78295670e-06]\n",
            "  [9.99979854e-01 1.93615710e-06 7.74017644e-06 1.54696545e-06\n",
            "   1.54758084e-06 1.17199488e-06 1.21148798e-06 4.95438087e-07\n",
            "   1.17677484e-06 3.34555239e-06]\n",
            "  [9.99974966e-01 2.18313153e-06 9.87950170e-06 2.08180018e-06\n",
            "   1.89249329e-06 1.39488486e-06 1.44550984e-06 6.03291141e-07\n",
            "   1.44461546e-06 4.15979594e-06]\n",
            "  [9.99968052e-01 2.60326237e-06 1.27796211e-05 2.88103774e-06\n",
            "   2.40549662e-06 1.71877184e-06 1.76315802e-06 7.52439973e-07\n",
            "   1.78184507e-06 5.29027375e-06]\n",
            "  [9.99958515e-01 3.22153278e-06 1.66342779e-05 4.05856144e-06\n",
            "   3.15543775e-06 2.17923275e-06 2.19042386e-06 9.58123337e-07\n",
            "   2.21150208e-06 6.83885992e-06]\n",
            "  [9.99945641e-01 4.08847609e-06 2.17097895e-05 5.77672745e-06\n",
            "   4.24483687e-06 2.83047643e-06 2.76557330e-06 1.24245400e-06\n",
            "   2.76431274e-06 8.94774166e-06]\n",
            "  [9.99928117e-01 5.27876364e-06 2.83601075e-05 8.26159339e-06\n",
            "   5.82281064e-06 3.75216746e-06 3.54310873e-06 1.63711195e-06\n",
            "   3.48119579e-06 1.18101607e-05]\n",
            "  [9.99904156e-01 6.89444369e-06 3.70495545e-05 1.18224425e-05\n",
            "   8.10273377e-06 5.05981325e-06 4.60000956e-06 2.18734908e-06\n",
            "   4.41698649e-06 1.56854803e-05]\n",
            "  [9.99871731e-01 9.07098820e-06 4.83833319e-05 1.68764236e-05\n",
            "   1.13854048e-05 6.91949390e-06 6.04481147e-06 2.95776749e-06\n",
            "   5.64558786e-06 2.09190475e-05]\n",
            "  [9.99827743e-01 1.19859860e-05 6.31455332e-05 2.39793899e-05\n",
            "   1.60881045e-05 9.56801614e-06 8.03026705e-06 4.04051798e-06\n",
            "   7.26712960e-06 2.79676387e-05]\n",
            "  [9.99768674e-01 1.58706462e-05 8.23453738e-05 3.38644495e-05\n",
            "   2.27798319e-05 1.33397207e-05 1.07709147e-05 5.56675514e-06\n",
            "   9.41762937e-06 3.74311930e-05]\n",
            "  [9.99688745e-01 2.10253529e-05 1.07272608e-04 4.74902990e-05\n",
            "   3.22222913e-05 1.87012647e-05 1.45668510e-05 7.72255225e-06\n",
            "   1.22821457e-05 5.00924471e-05]\n",
            "  [9.99581039e-01 2.78401803e-05 1.39563926e-04 6.61024242e-05\n",
            "   4.54171022e-05 2.62957328e-05 1.98358121e-05 1.07706892e-05\n",
            "   1.61125827e-05 6.69659858e-05]\n",
            "  [9.99437153e-01 3.68223591e-05 1.81281634e-04 9.13098629e-05\n",
            "   6.36584737e-05 3.69966692e-05 2.71551708e-05 1.50800352e-05\n",
            "   2.12513150e-05 8.93578035e-05]\n",
            "  [9.99245048e-01 4.86324752e-05 2.35008847e-04 1.25181192e-04\n",
            "   8.85945701e-05 5.19741916e-05 3.73167350e-05 2.11647584e-05\n",
            "   2.81627763e-05 1.18939708e-04]\n",
            "  [9.98989999e-01 6.41321094e-05 3.03964101e-04 1.70363419e-04\n",
            "   1.22299854e-04 7.27733568e-05 5.13961822e-05 2.97356182e-05\n",
            "   3.74750889e-05 1.57839240e-04]]]\n",
            "output tokens\n",
            "[9.9899000e-01 6.4132109e-05 3.0396410e-04 1.7036342e-04 1.2229985e-04\n",
            " 7.2773357e-05 5.1396182e-05 2.9735618e-05 3.7475089e-05 1.5783924e-04]\n",
            "output tokens\n",
            "[6.4132109e-05 3.0396410e-04 1.7036342e-04 1.2229985e-04 7.2773357e-05\n",
            " 5.1396182e-05 2.9735618e-05 3.7475089e-05 1.5783924e-04]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[9.98652935e-01 8.44450697e-05 3.92136484e-04 2.30225138e-04\n",
            "   1.67366365e-04 1.01407939e-04 7.08399457e-05 4.17659612e-05\n",
            "   5.00340539e-05 2.08749188e-04]\n",
            "  [9.96919274e-01 1.67674315e-03 3.43415624e-04 1.53409084e-04\n",
            "   1.95513319e-04 2.60310888e-04 1.02762737e-04 5.46770098e-05\n",
            "   3.13340206e-05 2.62563321e-04]\n",
            "  [9.98948514e-01 1.88414837e-04 2.04457436e-04 7.70003971e-05\n",
            "   1.51590619e-04 1.37917203e-04 7.34613350e-05 4.20429969e-05\n",
            "   3.01336968e-05 1.46454942e-04]\n",
            "  [9.99211788e-01 8.89233561e-05 1.76810980e-04 6.44148604e-05\n",
            "   1.08839435e-04 9.82038691e-05 6.39233258e-05 3.60765771e-05\n",
            "   3.19780520e-05 1.18965370e-04]\n",
            "  [9.99283493e-01 6.22116931e-05 1.81452808e-04 6.44814281e-05\n",
            "   8.80756634e-05 7.95723172e-05 6.00344392e-05 3.38843456e-05\n",
            "   3.49717920e-05 1.11739522e-04]\n",
            "  [9.99280632e-01 5.44332433e-05 2.00337076e-04 7.18172232e-05\n",
            "   7.89523256e-05 7.06324936e-05 5.84916525e-05 3.30388357e-05\n",
            "   3.80482888e-05 1.13566181e-04]\n",
            "  [9.99226570e-01 5.44621835e-05 2.29988174e-04 8.59071079e-05\n",
            "   7.82152856e-05 6.81150705e-05 5.93261502e-05 3.35656587e-05\n",
            "   4.14756578e-05 1.22462938e-04]\n",
            "  [9.99121845e-01 5.95276324e-05 2.70994642e-04 1.08162560e-04\n",
            "   8.48972704e-05 7.10377135e-05 6.30238574e-05 3.57853642e-05\n",
            "   4.58980794e-05 1.38775838e-04]\n",
            "  [9.98958111e-01 6.92288013e-05 3.25827801e-04 1.41252473e-04\n",
            "   9.96436502e-05 7.95780434e-05 7.02745529e-05 4.01590587e-05\n",
            "   5.20558860e-05 1.64016456e-04]\n",
            "  [9.98717785e-01 8.42177105e-05 3.98440898e-04 1.89117796e-04\n",
            "   1.24579368e-04 9.49081223e-05 8.21252543e-05 4.73814616e-05\n",
            "   6.08064584e-05 2.00737195e-04]\n",
            "  [9.98375177e-01 1.05880208e-04 4.94347245e-04 2.57171545e-04\n",
            "   1.63446050e-04 1.19307544e-04 1.00196819e-04 5.85303496e-05\n",
            "   7.32462358e-05 2.52681290e-04]\n",
            "  [9.97893870e-01 1.36321381e-04 6.20901410e-04 3.52575356e-04\n",
            "   2.21912182e-04 1.56447131e-04 1.26952131e-04 7.52608394e-05\n",
            "   9.08814400e-05 3.25052592e-04]\n",
            "  [9.97222781e-01 1.78483882e-04 7.87699420e-04 4.84563352e-04\n",
            "   3.07964598e-04 2.11810999e-04 1.66044469e-04 1.00066369e-04\n",
            "   1.15843897e-04 4.24862083e-04]\n",
            "  [9.96294558e-01 2.36351189e-04 1.00703398e-03 6.64778403e-04\n",
            "   4.32265719e-04 2.93210032e-04 2.22762057e-04 1.36626099e-04\n",
            "   1.51166416e-04 5.61317429e-04]\n",
            "  [9.95020986e-01 3.15217039e-04 1.29434105e-03 9.07587935e-04\n",
            "   6.08351140e-04 4.11297777e-04 3.04558547e-04 1.90244464e-04\n",
            "   2.01127070e-04 7.46198813e-04]\n",
            "  [9.93290782e-01 4.22007841e-04 1.66853936e-03 1.23031682e-03\n",
            "   8.52543104e-04 5.79953776e-04 4.21614823e-04 2.68356845e-04\n",
            "   2.71659461e-04 9.94160771e-04]\n",
            "  [9.90966856e-01 5.65628870e-04 2.15217494e-03 1.65332668e-03\n",
            "   1.18353427e-03 8.16369662e-04 5.87328046e-04 3.81041638e-04\n",
            "   3.70804511e-04 1.32288213e-03]\n",
            "  [9.87887025e-01 7.57302274e-04 2.77126464e-03 2.19988450e-03\n",
            "   1.62169954e-03 1.14070729e-03 8.18585628e-04 5.41428337e-04\n",
            "   5.09146368e-04 1.75300369e-03]\n",
            "  [9.83865678e-01 1.01082167e-03 3.55473091e-03 2.89574731e-03\n",
            "   2.18828814e-03 1.57530070e-03 1.13565824e-03 7.65858276e-04\n",
            "   7.00136297e-04 2.30779080e-03]\n",
            "  [9.78699207e-01 1.34267448e-03 4.53344593e-03 3.76849598e-03\n",
            "   2.90474412e-03 2.14354135e-03 1.56162796e-03 1.07367418e-03\n",
            "   9.60205565e-04 3.01254774e-03]]]\n",
            "output tokens\n",
            "[9.7869921e-01 1.3426745e-03 4.5334459e-03 3.7684960e-03 2.9047441e-03\n",
            " 2.1435414e-03 1.5616280e-03 1.0736742e-03 9.6020557e-04 3.0125477e-03]\n",
            "output tokens\n",
            "[0.00134267 0.00453345 0.0037685  0.00290474 0.00214354 0.00156163\n",
            " 0.00107367 0.00096021 0.00301255]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[9.7217065e-01 1.7719819e-03 5.7389857e-03 4.8466930e-03 3.7923735e-03\n",
            "   2.8687799e-03 2.1214210e-03 1.4866153e-03 1.3085922e-03 3.8938813e-03]\n",
            "  [9.3199134e-01 3.9272826e-02 4.6245982e-03 2.7275064e-03 4.1076345e-03\n",
            "   7.4074273e-03 2.7499734e-03 1.8627617e-03 7.9215551e-04 4.4638305e-03]\n",
            "  [9.8051238e-01 3.7592703e-03 2.4501192e-03 1.1746023e-03 2.7690178e-03\n",
            "   3.3223727e-03 1.8277582e-03 1.2381239e-03 6.6479237e-04 2.2816157e-03]\n",
            "  [9.8710281e-01 1.4784783e-03 1.9892491e-03 9.0060552e-04 1.7224853e-03\n",
            "   2.0164587e-03 1.4591332e-03 9.7180379e-04 6.7040254e-04 1.6885323e-03]\n",
            "  [9.8983335e-01 9.0509362e-04 1.8832514e-03 8.2537648e-04 1.1778900e-03\n",
            "   1.3539309e-03 1.1718955e-03 7.8232394e-04 6.5563736e-04 1.4113270e-03]\n",
            "  [9.9108726e-01 7.0872135e-04 1.9133625e-03 8.4963022e-04 9.1484125e-04\n",
            "   1.0118473e-03 9.6582365e-04 6.4398738e-04 6.2145601e-04 1.2830165e-03]\n",
            "  [9.9145812e-01 6.4593682e-04 2.0320856e-03 9.5144525e-04 8.1500335e-04\n",
            "   8.4963004e-04 8.4267330e-04 5.5855024e-04 5.8954390e-04 1.2570239e-03]\n",
            "  [9.9112928e-01 6.5462769e-04 2.2380634e-03 1.1365921e-03 8.2579406e-04\n",
            "   8.0192433e-04 7.9340336e-04 5.2240671e-04 5.7737750e-04 1.3205286e-03]\n",
            "  [9.9011701e-01 7.1882078e-04 2.5475894e-03 1.4251878e-03 9.3390816e-04\n",
            "   8.4310002e-04 8.1068801e-04 5.3181482e-04 5.9502211e-04 1.4767880e-03]\n",
            "  [9.8832536e-01 8.3967595e-04 2.9876505e-03 1.8485392e-03 1.1516041e-03\n",
            "   9.7240484e-04 8.9554029e-04 5.8807939e-04 6.5003021e-04 1.7412226e-03]\n",
            "  [9.8555666e-01 1.0279405e-03 3.5950441e-03 2.4482531e-03 1.5115268e-03\n",
            "   1.2080745e-03 1.0596166e-03 6.9998653e-04 7.5205875e-04 2.1408468e-03]\n",
            "  [9.8151267e-01 1.3020668e-03 4.4168341e-03 3.2752079e-03 2.0648069e-03\n",
            "   1.5859462e-03 1.3266989e-03 8.8549400e-04 9.1601704e-04 2.7143599e-03]\n",
            "  [9.7579318e-01 1.6879676e-03 5.5100722e-03 4.3871682e-03 2.8783330e-03\n",
            "   2.1593561e-03 1.7343271e-03 1.1736297e-03 1.1644382e-03 3.5115671e-03]\n",
            "  [9.6791071e-01 2.2189431e-03 6.9394005e-03 5.8442075e-03 4.0280316e-03\n",
            "   2.9972193e-03 2.3348364e-03 1.6062701e-03 1.5294283e-03 4.5909528e-03]\n",
            "  [9.5732838e-01 2.9347986e-03 8.7713310e-03 7.7013928e-03 5.5864570e-03\n",
            "   4.1772551e-03 3.1939303e-03 2.2384687e-03 2.0537369e-03 6.0142316e-03]\n",
            "  [9.4353062e-01 3.8793811e-03 1.1064853e-02 9.9992501e-03 7.6059517e-03\n",
            "   5.7726111e-03 4.3845512e-03 3.1353701e-03 2.7898557e-03 7.8375479e-03]\n",
            "  [9.2612064e-01 5.0960416e-03 1.3859381e-02 1.2753811e-02 1.0102126e-02\n",
            "   7.8333477e-03 5.9747235e-03 4.3638665e-03 3.7957835e-03 1.0100243e-02]\n",
            "  [9.0492171e-01 6.6213217e-03 1.7163105e-02 1.5949564e-02 1.3044717e-02\n",
            "   1.0368638e-02 8.0108903e-03 5.9790169e-03 5.1267082e-03 1.2814234e-02]\n",
            "  [8.8004589e-01 8.4781330e-03 2.0945974e-02 1.9538598e-02 1.6361158e-02\n",
            "   1.3338090e-02 1.0502162e-02 8.0085387e-03 6.8236236e-03 1.5957858e-02]\n",
            "  [8.5189480e-01 1.0670638e-02 2.5141096e-02 2.3447718e-02 1.9953040e-02\n",
            "   1.6658207e-02 1.3412951e-02 1.0441699e-02 8.9022573e-03 1.9477561e-02]]]\n",
            "output tokens\n",
            "[0.8518948  0.01067064 0.0251411  0.02344772 0.01995304 0.01665821\n",
            " 0.01341295 0.0104417  0.00890226 0.01947756]\n",
            "output tokens\n",
            "[0.01067064 0.0251411  0.02344772 0.01995304 0.01665821 0.01341295\n",
            " 0.0104417  0.00890226 0.01947756]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[0.8210877  0.0131827  0.02965472 0.02759143 0.02371913 0.02022248\n",
            "   0.01666881 0.01322872 0.01134687 0.0232974 ]\n",
            "  [0.6244113  0.2329543  0.01785952 0.01120422 0.01941139 0.04110888\n",
            "   0.01566019 0.01251461 0.00511767 0.01975786]\n",
            "  [0.8788913  0.0266624  0.01151708 0.00580989 0.01537627 0.02149188\n",
            "   0.01290586 0.00977877 0.00512456 0.01244197]\n",
            "  [0.9249175  0.00958776 0.00917446 0.00434322 0.00900466 0.012028\n",
            "   0.00981419 0.00728473 0.00496946 0.00887592]\n",
            "  [0.9456322  0.00540067 0.0082822  0.00381754 0.00567114 0.00729507\n",
            "   0.00716127 0.00532035 0.00446042 0.00695902]\n",
            "  [0.95628154 0.00390794 0.00797173 0.00376463 0.00409731 0.00497021\n",
            "   0.00533151 0.00393809 0.00381634 0.00592063]\n",
            "  [0.9611662  0.00331454 0.00803445 0.00405592 0.00345622 0.00388001\n",
            "   0.00425334 0.00310009 0.00327515 0.00546409]\n",
            "  [0.962025   0.00315889 0.00844828 0.00468919 0.00337702 0.00347894\n",
            "   0.00373328 0.00268187 0.00294368 0.0054638 ]\n",
            "  [0.95952964 0.00330068 0.0092493  0.00571882 0.00373723 0.00354046\n",
            "   0.00362746 0.00257912 0.00283836 0.00587893]\n",
            "  [0.9537046  0.00370777 0.01049997 0.00723184 0.00454997 0.00400596\n",
            "   0.00387392 0.00274417 0.00295602 0.00672575]\n",
            "  [0.94412404 0.00439772 0.01228068 0.00933193 0.00591175 0.00491621\n",
            "   0.00448134 0.0031843  0.00330938 0.00806265]\n",
            "  [0.930058   0.00541642 0.01468081 0.01211898 0.00796791 0.00637743\n",
            "   0.00551423 0.00395374 0.00393803 0.00997447]\n",
            "  [0.9106477  0.00682494 0.01778143 0.01566107 0.01086967 0.0085322\n",
            "   0.00707819 0.00514542 0.00490897 0.01255048]\n",
            "  [0.8851568  0.00868547 0.02162869 0.01996135 0.01471291 0.01151639\n",
            "   0.00929726 0.0068772  0.00631048 0.01585349]\n",
            "  [0.85329044 0.01104375 0.02620356 0.02493053 0.01947038 0.01539816\n",
            "   0.01227625 0.00926518 0.00823723 0.01988455]\n",
            "  [0.8154866  0.0139107  0.03140052 0.03038039 0.02495026 0.02011641\n",
            "   0.01605112 0.0123825  0.01076542 0.02455615]\n",
            "  [0.7730269  0.01724961 0.03703015 0.03605077 0.03081563 0.02545386\n",
            "   0.02054556 0.01621497 0.01392224 0.02969024]\n",
            "  [0.72785604 0.02097587 0.04285134 0.04166599 0.03666968 0.03107341\n",
            "   0.02556105 0.02063585 0.01766127 0.03504949]\n",
            "  [0.68215215 0.02497024 0.04862182 0.04699746 0.04216717 0.03660891\n",
            "   0.03081479 0.0254199  0.021857   0.04039045]\n",
            "  [0.6378416  0.02910076 0.05414464 0.05190487 0.04709609 0.04176476\n",
            "   0.03601155 0.03029613 0.02632485 0.04551483]]]\n",
            "output tokens\n",
            "[0.6378416  0.02910076 0.05414464 0.05190487 0.04709609 0.04176476\n",
            " 0.03601155 0.03029613 0.02632485 0.04551483]\n",
            "output tokens\n",
            "[0.02910076 0.05414464 0.05190487 0.04709609 0.04176476 0.03601155\n",
            " 0.03029613 0.02632485 0.04551483]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[0.5962625  0.03324402 0.05929225 0.05634207 0.05139704 0.04637547\n",
            "   0.04091425 0.03501524 0.03085958 0.05029765]\n",
            "  [0.34428325 0.42295027 0.02568606 0.01624294 0.03049514 0.06926671\n",
            "   0.02706259 0.02376163 0.00990406 0.03034734]\n",
            "  [0.71392405 0.06868842 0.02341754 0.01192393 0.03342673 0.05013769\n",
            "   0.03180462 0.02566915 0.01378589 0.02722201]\n",
            "  [0.81895685 0.02497972 0.01952861 0.00932962 0.02019306 0.02858908\n",
            "   0.02491018 0.01962324 0.01372091 0.02016875]\n",
            "  [0.87121165 0.01380397 0.01762779 0.00824403 0.01258802 0.01699204\n",
            "   0.01779378 0.01399997 0.0120229  0.01571584]\n",
            "  [0.8996707  0.00968642 0.01669926 0.00805836 0.00891639 0.01124948\n",
            "   0.012785   0.00997082 0.00986206 0.0131015 ]\n",
            "  [0.9138678  0.00793773 0.01646677 0.00855785 0.00737201 0.00854587\n",
            "   0.00983484 0.00753935 0.0080814  0.01179643]\n",
            "  [0.9183301  0.00731651 0.0169191  0.00973282 0.00708024 0.00749168\n",
            "   0.0083624  0.00629461 0.00696191 0.01151063]\n",
            "  [0.91522545 0.00741588 0.01810785 0.01166186 0.0077216  0.00748783\n",
            "   0.00791663 0.00588017 0.00647787 0.01210488]\n",
            "  [0.9052474  0.00810266 0.02010007 0.01445963 0.00926812 0.00834028\n",
            "   0.00827286 0.0061095  0.00655212 0.01354734]\n",
            "  [0.88818896 0.00935731 0.02296321 0.01823223 0.01184317 0.01006842\n",
            "   0.00937933 0.00694025 0.00715369 0.01587345]\n",
            "  [0.86343944 0.01120874 0.02674095 0.0230236  0.01561781 0.01279807\n",
            "   0.01129375 0.00842922 0.00831085 0.01913759]\n",
            "  [0.8305077  0.0136926  0.03141527 0.0287582  0.0206956  0.01666885\n",
            "   0.01412312 0.01068866 0.01009464 0.02335529]\n",
            "  [0.789571   0.0168159  0.03686843 0.03520286 0.02699001 0.02172822\n",
            "   0.01795463 0.01383403 0.01258917 0.02844583]\n",
            "  [0.7418959  0.02053006 0.04286801 0.04197836 0.03414881 0.02783118\n",
            "   0.02277822 0.01791859 0.01585201 0.03419892]\n",
            "  [0.6898881  0.02472221 0.04909587 0.04863585 0.0415933  0.03460206\n",
            "   0.02842747 0.02287058 0.019873   0.04029155]\n",
            "  [0.6366508  0.02923004 0.05521707 0.05477296 0.04867958 0.04150383\n",
            "   0.03457616 0.02846504 0.0245469  0.04635765]\n",
            "  [0.5852354  0.03387284 0.06095654 0.06013232 0.05489798 0.04799276\n",
            "   0.04080568 0.03435446 0.02967409 0.05207798]\n",
            "  [0.53796214 0.03848352 0.066146   0.06463586 0.05999839 0.05367303\n",
            "   0.04671326 0.0401508  0.03499222 0.05724476]\n",
            "  [0.49609992 0.04292854 0.07072598 0.06835229 0.06399212 0.05837185\n",
            "   0.05200607 0.04551994 0.04022696 0.06177631]]]\n",
            "output tokens\n",
            "[0.49609992 0.04292854 0.07072598 0.06835229 0.06399212 0.05837185\n",
            " 0.05200607 0.04551994 0.04022696 0.06177631]\n",
            "output tokens\n",
            "[0.04292854 0.07072598 0.06835229 0.06399212 0.05837185 0.05200607\n",
            " 0.04551994 0.04022696 0.06177631]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[0.459926   0.04711438 0.07471658 0.07143167 0.06706647 0.06212042\n",
            "   0.0565431  0.05024742 0.04514309 0.06569085]\n",
            "  [0.23268944 0.50339144 0.02745741 0.01738428 0.03390001 0.07933458\n",
            "   0.03139243 0.0288403  0.01221799 0.03339208]\n",
            "  [0.59867233 0.10053927 0.03057878 0.01562269 0.0449102  0.06951242\n",
            "   0.0452291  0.03763235 0.02056921 0.03673369]\n",
            "  [0.73632956 0.03783557 0.02678548 0.01284485 0.02835948 0.04119312\n",
            "   0.03694579 0.02994028 0.02126887 0.02849697]\n",
            "  [0.8110379  0.0210419  0.02454387 0.01155278 0.01789608 0.0246768\n",
            "   0.02657045 0.02147916 0.01870632 0.02249468]\n",
            "  [0.85368824 0.01467507 0.02327238 0.01133825 0.01267844 0.01628183\n",
            "   0.01896619 0.0151765  0.01518164 0.01874146]\n",
            "  [0.8758676  0.01187918 0.02280927 0.01200439 0.01042997 0.01227342\n",
            "   0.01442097 0.01132456 0.0122362  0.01675437]\n",
            "  [0.88386154 0.0107898  0.02321525 0.01355833 0.00994606 0.01066261\n",
            "   0.01210624 0.00932024 0.01035598 0.016184  ]\n",
            "  [0.88104737 0.01077007 0.02456965 0.01609245 0.01075748 0.01055722\n",
            "   0.01131828 0.00858728 0.00947552 0.01682471]\n",
            "  [0.8688236  0.01158559 0.02693161 0.0197188  0.01278631 0.01163991\n",
            "   0.01168188 0.00880443 0.00943579 0.01859215]\n",
            "  [0.8474164  0.01316326 0.03033094 0.02450612 0.01614124 0.01388464\n",
            "   0.01307085 0.00986551 0.01014693 0.02147409]\n",
            "  [0.8166458  0.0154901  0.03474087 0.03040786 0.02095953 0.01738923\n",
            "   0.01550285 0.0117999  0.01160224 0.02546161]\n",
            "  [0.7766707  0.01855108 0.04003846 0.03720064 0.02724535 0.02223541\n",
            "   0.01904215 0.01469685 0.01384574 0.03047368]\n",
            "  [0.72862804 0.02228568 0.04597923 0.04447152 0.03472957 0.02835162\n",
            "   0.02370246 0.0186265  0.01692579 0.03629959]\n",
            "  [0.6749218  0.02656755 0.0522157  0.05168635 0.04283263 0.03541786\n",
            "   0.02936052 0.02355965 0.02084548 0.04259252]\n",
            "  [0.6189374  0.03121444 0.05836741 0.05832737 0.05079078 0.04287902\n",
            "   0.03571669 0.0293122  0.02552333 0.04893136]\n",
            "  [0.56426674 0.03602206 0.06411207 0.06403432 0.05789651 0.05008512\n",
            "   0.04233318 0.03554602 0.03077918 0.05492481]\n",
            "  [0.51385105 0.04080186 0.06924969 0.06867412 0.06371047 0.0564858\n",
            "   0.04873847 0.04183498 0.03635216 0.06030133]\n",
            "  [0.46946725 0.04540503 0.07371261 0.07231712 0.06813219 0.06176851\n",
            "   0.05454426 0.04776657 0.04194407 0.06494244]\n",
            "  [0.43169063 0.04972784 0.07753166 0.07515506 0.0713293  0.06588216\n",
            "   0.05951952 0.05303244 0.04727247 0.06885891]]]\n",
            "output tokens\n",
            "[0.43169063 0.04972784 0.07753166 0.07515506 0.0713293  0.06588216\n",
            " 0.05951952 0.05303244 0.04727247 0.06885891]\n",
            "output tokens\n",
            "[0.04972784 0.07753166 0.07515506 0.0713293  0.06588216 0.05951952\n",
            " 0.05303244 0.04727247 0.06885891]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[0.40018037 0.05370665 0.08078839 0.07741515 0.07360585 0.06897034\n",
            "   0.06360156 0.0574745  0.05211705 0.07214017]\n",
            "  [0.1924765  0.5334587  0.02778574 0.01760034 0.03489042 0.0826866\n",
            "   0.0328977  0.03082865 0.01316892 0.03420641]\n",
            "  [0.54302526 0.1166286  0.03373377 0.01726239 0.05014723 0.07867707\n",
            "   0.0517443  0.04363333 0.02405395 0.04109414]\n",
            "  [0.692945   0.04483769 0.03037375 0.01459248 0.0324951  0.04772492\n",
            "   0.04332035 0.03554389 0.02543807 0.03272874]\n",
            "  [0.7782973  0.02511054 0.02812918 0.01327989 0.02070724 0.0288183\n",
            "   0.03138712 0.02567475 0.02250356 0.02609217]\n",
            "  [0.8283515  0.01750967 0.02674929 0.01308738 0.01471015 0.01903912\n",
            "   0.02240401 0.01813034 0.01822859 0.0217899 ]\n",
            "  [0.854932   0.01411612 0.0261821  0.01385389 0.01209049 0.01432372\n",
            "   0.01697495 0.01347227 0.01460905 0.01944547]\n",
            "  [0.86500764 0.01274501 0.02655181 0.01560508 0.01149765 0.01240034\n",
            "   0.01417951 0.01102573 0.01227721 0.01870995]\n",
            "  [0.8625663  0.01263484 0.02796245 0.01844138 0.01238713 0.01222466\n",
            "   0.01318345 0.01009719 0.01115163 0.01935106]\n",
            "  [0.849419   0.01349176 0.03046913 0.02246806 0.01465015 0.01340944\n",
            "   0.01352616 0.01028709 0.01102445 0.02125465]\n",
            "  [0.8260899  0.0152074  0.03407685 0.02772486 0.01837832 0.01589647\n",
            "   0.01503433 0.01144789 0.01176749 0.02437643]\n",
            "  [0.7927051  0.01773936 0.03871601 0.03410813 0.02367814 0.01975788\n",
            "   0.01769527 0.01358621 0.01334825 0.02866556]\n",
            "  [0.74983215 0.02103969 0.04420694 0.04131347 0.03048952 0.02503323\n",
            "   0.02154111 0.01677014 0.01578932 0.03398435]\n",
            "  [0.69912267 0.02501006 0.05024679 0.04884379 0.0384455  0.03158215\n",
            "   0.02654021 0.02103809 0.01911439 0.04005637]\n",
            "  [0.643491   0.02948766 0.05644739 0.05610948 0.04686384 0.03899992\n",
            "   0.03251135 0.02631527 0.02329604 0.04647796]\n",
            "  [0.5866621  0.03426484 0.06242142 0.06259001 0.05491725 0.04666039\n",
            "   0.03909811 0.03236564 0.02821949 0.05280064]\n",
            "  [0.5322857  0.03912897 0.06787454 0.06797314 0.06190019 0.05388518\n",
            "   0.04582576 0.03880777 0.0336752  0.05864352]\n",
            "  [0.48310816 0.04389839 0.07265452 0.07219911 0.06743032 0.06014434\n",
            "   0.05221608 0.04519324 0.03938252 0.0637733 ]\n",
            "  [0.44058663 0.04843898 0.07674138 0.07540711 0.07148446 0.06517653\n",
            "   0.05790059 0.05111123 0.04503507 0.06811803]\n",
            "  [0.40498143 0.05266258 0.08020058 0.07783615 0.07429697 0.06898737\n",
            "   0.06268179 0.05627296 0.0503526  0.07172754]]]\n",
            "output tokens\n",
            "[0.40498143 0.05266258 0.08020058 0.07783615 0.07429697 0.06898737\n",
            " 0.06268179 0.05627296 0.0503526  0.07172754]\n",
            "output tokens\n",
            "[0.05266258 0.08020058 0.07783615 0.07429697 0.06898737 0.06268179\n",
            " 0.05627296 0.0503526  0.07172754]\n",
            "1\n",
            "Generated summary:  obama obama obama obama obama obama obama obama obama\n",
            "\n",
            "\n",
            "ROUGE score: \n",
            "[{'rouge-1': {'f': 0.2222222202469136, 'p': 0.125, 'r': 1.0}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.12670565302131262, 'p': 0.125, 'r': 1.0}}]\n",
            "0.2222222202469136\n",
            "0.125\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}