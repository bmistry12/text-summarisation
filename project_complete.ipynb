{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project-complete.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV27LCvjfwkR",
        "colab_type": "code",
        "outputId": "8ff724c9-c914-4c1a-8f72-7fb8a7bcf7bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "!python -m nltk.downloader stopwords wordnet punkt averaged_perceptron_tagger\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.layers import Attention\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2feqtBEHiaS4",
        "colab_type": "text"
      },
      "source": [
        "### Env Vars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omclwb_CiEZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=70\n",
        "EPOCHS=1\n",
        "latent_dim=128\n",
        "embedding_dim=128\n",
        "test_train_split=0.20\n",
        "build_number=\"1\"\n",
        "# LEARNING_RATE=0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNPOLXNLiiX5",
        "colab_type": "text"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cchT-sW8kGP4",
        "colab_type": "text"
      },
      "source": [
        "Read In Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LLVyg34iLP5",
        "colab_type": "code",
        "outputId": "43f2db75-cd1b-42af-ec08-ecaa29741c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Op7xyUiHSv",
        "colab_type": "code",
        "outputId": "49741a0a-23ba-4304-d89f-08595c062125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "df = pd.read_csv('./drive/My Drive/data0.csv')\n",
        "df.head(1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>file</th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0002c17436637c4fe1837c935c04de47adb18e9a.story</td>\n",
              "      <td>Los Angeles A medical doctor Vancouver British...</td>\n",
              "      <td>NEW A Canadian doctor says part team examining...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                            summary\n",
              "0           0  ...  NEW A Canadian doctor says part team examining...\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptOkktH2CLqg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "3fc0066a-d008-4b8e-e113-594d7bdf0990"
      },
      "source": [
        "df.count"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.count of      Unnamed: 0  ...                                            summary\n",
              "0             0  ...  NEW A Canadian doctor says part team examining...\n",
              "1             1  ...  The 15 new cardinals installed February 14 . T...\n",
              "2             2  ...  NEW Bermudan premier Above humanitarian act . ...\n",
              "3             3  ...  A 4yearold boy latest victim maneating leopard...\n",
              "4             4  ...  NEW Kyle White Without team would Medal Honor ...\n",
              "..          ...  ...                                                ...\n",
              "758         758  ...  John Avlon Most people fail jobs dont get paid...\n",
              "759         759  ...  Brandt Snedeker Justin Rose share third round ...\n",
              "760         760  ...  At least 95 people dead almost 2 million other...\n",
              "761         761  ...  Australian Prime Minister Kevin Rudd tweets cr...\n",
              "762         762  ...  The distinction determine deportation U.S. cha...\n",
              "\n",
              "[763 rows x 4 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogB1RqsqreG2",
        "colab_type": "text"
      },
      "source": [
        "Split for now so we are only aiming for one summary per text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e3a1UjziN5g",
        "colab_type": "code",
        "outputId": "5265ceba-c96a-48d1-998c-a499480a451c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(df['summary'][0])\n",
        "df['summary'] = df['summary'].apply(lambda x: re.sub(r'\\..*$',' ',str(x)))\n",
        "print(df['summary'][0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NEW A Canadian doctor says part team examining Harry Burkhart 2010 . NEW Diagnosis autism severe anxiety posttraumatic stress disorder depression . Burkhart also suspected German arson probe officials say . Prosecutors believe German national set string fires Los Angeles\n",
            "NEW A Canadian doctor says part team examining Harry Burkhart 2010  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSVW1P-Ji_7R",
        "colab_type": "text"
      },
      "source": [
        "Word Count Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M72pGpsDjCrc",
        "colab_type": "code",
        "outputId": "fdae29fd-10a2-4840-f284-a0c3ff7406a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in df['text']:\n",
        "      text_word_count.append(len(i.split(' ')))\n",
        "\n",
        "for i in df['summary']:\n",
        "      summary_word_count.append(len(i.split(' ')))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.ylabel('Documents')\n",
        "plt.xlabel('Word Count')\n",
        "plt.savefig('word_count_distro' + str(build_number) + '.png')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEWCAYAAACdaNcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNZ2tVpljHTc",
        "colab_type": "text"
      },
      "source": [
        "Max Text Lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T01Jf-XjGKO",
        "colab_type": "code",
        "outputId": "37b450a1-8bc6-4c2d-8255-5c5b4bceeca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "max_text_len = max([len(txt) for txt in df['text']])\n",
        "max_summary_len = max([len(txt) for txt in df['summary']])\n",
        "print(max_text_len)\n",
        "print(max_summary_len)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7301\n",
            "115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGl1z0OFjTsr",
        "colab_type": "text"
      },
      "source": [
        "### Training-Validation Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwmBST04juu6",
        "colab_type": "text"
      },
      "source": [
        "X - Articles text </br>\n",
        "Y - Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1_YrHcDjN6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to numpy array\n",
        "X = np.array(df['text'])\n",
        "Y = np.array(df['summary'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGHJXwaojYAV",
        "colab_type": "code",
        "outputId": "c17b901a-03f6-48fb-c0b1-a7e139240774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "x_tr,x_val,y_tr,y_val=train_test_split(X,Y,test_size=test_train_split,random_state=0,shuffle=True)\n",
        "print(x_tr.shape)\n",
        "print(x_val.shape)\n",
        "print(y_tr.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(610,)\n",
            "(153,)\n",
            "(610,)\n",
            "(153,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzWpoc9OjjdV",
        "colab_type": "text"
      },
      "source": [
        "### Word Embeddings - Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLVdVklnjq1i",
        "colab_type": "text"
      },
      "source": [
        "X Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7qUrNpbjpI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_dict = {}\n",
        "text = df['text']\n",
        "\n",
        "for row in text: \n",
        "  for word in row.split(\" \"):\n",
        "    if word not in word_dict:\n",
        "      word_dict[word] = 1\n",
        "    else:\n",
        "      word_dict[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qbg_6TKj4HK",
        "colab_type": "code",
        "outputId": "62cdd39a-b15a-4b15-d9e7-3942c4e62b03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# #prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=len(word_dict)) \n",
        "x_tokenizer.fit_on_texts(list(X))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "print(x_voc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdwGLWiRloV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('xtokenizer.pickle', 'wb') as handle:\n",
        "  pickle.dump(x_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NsdijM3j6RJ",
        "colab_type": "text"
      },
      "source": [
        "Y Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG6Q2G-Wj79A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_dict = {}\n",
        "text = df['summary']\n",
        "\n",
        "for row in text: \n",
        "  for word in row.split(\" \"):\n",
        "    if word not in word_dict:\n",
        "      word_dict[word] = 1\n",
        "    else:\n",
        "      word_dict[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5ugAAnIj91g",
        "colab_type": "code",
        "outputId": "4b6f1fa6-43df-4457-d982-c8678855d213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=len(word_dict)) \n",
        "y_tokenizer.fit_on_texts(list(Y))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1\n",
        "print(y_voc)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzpeT5fXlp3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('ytokenizer.pickle', 'wb') as handle:\n",
        "  pickle.dump(y_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zntqptcwj_lh",
        "colab_type": "text"
      },
      "source": [
        "## Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc0JOUvqkWUL",
        "colab_type": "text"
      },
      "source": [
        "#### Encoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dx-9BT6kZMw",
        "colab_type": "code",
        "outputId": "a7ea0d51-ab76-46ca-9316-a0abb2017f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "#encoder lstm \n",
        "encoder_lstm = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JJUPBdfkdlb",
        "colab_type": "text"
      },
      "source": [
        "#### Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLgYfdF3kb1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "                                                          \n",
        "#dense layer\n",
        "decoder_dense = Dense(y_voc, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIpBF_fAkfuG",
        "colab_type": "text"
      },
      "source": [
        "#### Combined LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASIlTOT_khrn",
        "colab_type": "code",
        "outputId": "a84b995c-916c-4e3c-d59f-d54dae49577c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 7301)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 7301, 128)    3803136     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 128)    489728      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 7301, 128),  131584      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 128),  131584      embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 3826)   493554      lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 5,049,586\n",
            "Trainable params: 5,049,586\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMQ1ZrF0ksMT",
        "colab_type": "code",
        "outputId": "079e9100-b528-4ce3-a7c7-2a76dec875b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o12XRjJykuA-",
        "colab_type": "text"
      },
      "source": [
        "Early Stopping Callback to ensure we stop when Validation Loss is lowest - minimises risk of overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R-qwZoNkspo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=4, restore_best_weights=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbnxf9ZWk4I0",
        "colab_type": "code",
        "outputId": "39578a96-4b09-4f20-c834-831a65131d10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "history = model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:], batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 610 samples, validate on 153 samples\n",
            "Epoch 1/1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "610/610 [==============================] - 124s 203ms/step - loss: 6.1889 - val_loss: 2.5368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEkRn71fk7up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model' + str(build_number) + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N52zaYcKlAXE",
        "colab_type": "code",
        "outputId": "af8cb02c-672d-4636-e430-7ca8c426e664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.savefig('loss' + str(build_number) + '.png')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxSFAxiWlDad",
        "colab_type": "text"
      },
      "source": [
        "## Inference Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm1b46qtlFnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1Q7SWH_lGxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_inputs)\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c], [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biBjzpLQlPhf",
        "colab_type": "code",
        "outputId": "97f5fdcd-cc69-42de-c1c2-cd4d45c17ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "encoder_model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 7301)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 7301, 128)         3803136   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, 7301, 128), (None 131584    \n",
            "=================================================================\n",
            "Total params: 3,934,720\n",
            "Trainable params: 3,934,720\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmvKd7pNlQXs",
        "colab_type": "code",
        "outputId": "393146ef-606e-4a31-f5f0-fa5c0fa3e956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "decoder_model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 128)    489728      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 128),  131584      embedding_2[1][0]                \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 3826)   493554      lstm_2[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,114,866\n",
            "Trainable params: 1,114,866\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywir6L6wlUE-",
        "colab_type": "text"
      },
      "source": [
        "### Methhods for Reversing Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoKuk0dElZZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSR-0MHclb0G",
        "colab_type": "text"
      },
      "source": [
        "### Summarisation Method "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WYZgAXelbLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq): \n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, max_summary_len))\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "      output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c]) \n",
        "      # print(output_tokens)\n",
        "      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "      # print(sampled_token_index)\n",
        "      # print(sampled_token_index)\n",
        "      if (sampled_token_index != 0 ):\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_token\n",
        "      else :\n",
        "        stop_condition = True\n",
        "      if (len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "              stop_condition = True\n",
        "       # Update the target sequence (of length 1).\n",
        "      # target_seq = np.zeros((1,1))\n",
        "      target_seq = np.zeros((1, max_summary_len))\n",
        "      target_seq[0, sampled_token_index] = 1\n",
        "\n",
        "      # Update internal states\n",
        "      e_h, e_c = h, c\n",
        "      \n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STnQkiZzlhbb",
        "colab_type": "text"
      },
      "source": [
        "## Test Model Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AisRsa573_L3",
        "colab_type": "text"
      },
      "source": [
        "Note: *I think there isn't enough data being passed in and so the argmax value always is 0 - it can't learn what should be next*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC1oCOOHlgjh",
        "colab_type": "code",
        "outputId": "b840713f-25a9-49c9-80f8-fea62dbb903d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "for i in range(0,1):\n",
        "    print(\"Article:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    x_i = x_tr[i].reshape(1,max_text_len)\n",
        "    print(\"Generated summary:\",decode_sequence(x_i))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article: a prosecute attorney greet jury george zimmerman trial monday quote full expletive adversary decide appropriate tell juror knockknock joke and begin opening statement zimmermans longanticipated murder trial in case ignite national debate gun law race relation zimmerman neighborhood watch captain accuse seconddegree murder fatal shoot 17yearold trayvon martin february 2012 sanford florida prosecutor john guys first word sixwoman jury may raise eyebrow good morning fg punk get away guy quote zimmerman these word grown man mouth follow boy didnt know those word mine zimmerman guy say get car pistol two flashlight follow trayvon benjamin martin walk home 7eleven arm fruit drink bag candy eventually two become entangle ground fight a witness say martin top zimmerman guy say the defendant claim trayvon martin top say go die tonight say guy nobody heard guy told juror witness saw happen night shoot begin end witnesses saw slice happen say we confident end trial know head heart stomach george zimmerman shoot trayvon martin guy say he shot bad reason want fast fact trayvon martin shoot in first day testimony juror heard witness recount martins trip convenience store zimmermans call complain suspicious person walk neighborhood martins kill call previous august zimmerman report allege burglary police proceedings end day defense attorney mark omara object earlier call prosecutor argue necessary explain zimmermans remark burglar get away the martin family sat watch proceeding behind state attorney angela corey before witness testimony begin judge debra nelson deny defense request martins father tracy martin leave courtroom tracy martin potential witness potential witness force sit outside courtroom keep testimony taint witness but nextofkin victim allow remain court even theyre expect testify omara also accuse tracy martin use obscenity toward friend zimmermans hold door hearing two week ago the friend timothy tucholski testify hadnt want make issue i wasnt planning come i dont want sit say but nelson deny request martin remain court zimmermans parent cover rule regard potential witness sit outside benjamin crump lawyer martins parent at one point martins father begin cry guy detailed officer try save son life zimmerman mostly star straight ahead without sign emotion following guys statement defense attorney don west come forward woo jury as begin told knockknock joke but fail win laugh knock knock whos george zimmerman george zimmerman good youre jury say later west apologize no bad joke i promise told juror i convince delivery west quickly get business make case zimmerman force act selfdefense save life the evidence show sad case monster george zimmerman guilty murder he shot trayvon martin viciously attack with help powerpoint visuals west spent hour hammer home argument he broke zimmermans 911 call first report see martin told follow little george zimmerman know time less 10 minute first see travyon martin george zimmerman would suckered punch face head pound concrete wind shoot tragically kill trayvon martin west told juror west also deconstruct 911 call neighbor make possible hear scream shot background west say sound fatal bullet as dramatic record audio fill courtroom zimmerman show emotion martins mother left courtroom at moment actually become physical trayvon martin i use word trayvon martin decide confront george zimmerman west say that instead go home he plenty time this 60 70 yard plenty time he couldve go back forth four five time west quote witness name john good described fight he call ground pound martin say top zimmerman beating he saw enough serious west say zimmerman cry help look good say help but beating continued good go inside home call 911 west say there shot shortly afterward accord west zimmerman say martin beating i shot west also dispute prosecution claim martin unarmed travyon martin arm concrete sidewalk use smash george zimmermans head say west no different picked brick smash head wall that deadly weapon west show juror photo take zimmerman fight what really see picture evidence lump west say the big knot side head consistent head slam concrete allfemale jury try zimmerman among first prosecution witness call 911 dispatcher take zimmermans call shoot seat noffke testify train give general command instead direct order people when zimmerman say follow martin noffke told okay dont need noffke told prosecutor he liable direct order give someone on crossexamination defense attorney omara point noffke ask zimmerman which way run if tell somebody twice let know person theyre concerned anything else think theyre go keep eye ask omara i cant answer say noffke you tell twice let know guy anything else say omara yes sir say noffke noffke go say want location suspect officer never told zimmerman follow keep eye martin shortly court get way martins mother sybrina fulton spoke reporter ask people pray family i dont want mother experience im go judge no state expert testimony 911 call martin black zimmerman identifies hispanic in cnn poll release monday morning 62 respondent say charge zimmerman probably definitely true \n",
            "Original summary: defense lawyer apologizes telling joke opening statements \n",
            "Generated summary: \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNy_KJPb4PXc",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMRIXeuz8hYn",
        "colab_type": "text"
      },
      "source": [
        "Using ROUGE (Recall-Orientated Understanding Gisting Evaluation) to evaluate the generated summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqM1FoWQFsqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_overlapping_words(x, y):\n",
        "  num=0\n",
        "  x = nltk.word_tokenize(x)\n",
        "  y = nltk.word_tokenize(y)\n",
        "  for word in y:\n",
        "    if word in x:\n",
        "      num = num+1\n",
        "      x.remove(word)\n",
        "    else:\n",
        "      return num\n",
        "\n",
        "def precision(target, generated):\n",
        "  length = len(target)\n",
        "  for i in range (0, length):\n",
        "    num_overlapping_words = get_overlapping_words(target[i], generated[i])\n",
        "    generated_summary_len = len(generated[i])\n",
        "    if generated_summary_len == 0 :\n",
        "        return 0.0\n",
        "    else : \n",
        "      return num_overlapping_words / generated_summary_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwTD6W5kFmvk",
        "colab_type": "text"
      },
      "source": [
        "### For Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUr2YcMoDGEt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a81859a-8b35-4fa9-a952-7e51b7dbb580"
      },
      "source": [
        "print(len(x_tr))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BKXHKbaDS8G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "b6481970-1397-4aea-c804-1fac8328797b"
      },
      "source": [
        "tr_target_summary = []\n",
        "tr_generated_summary = []\n",
        "# x_tr_len = len(x_tr)\n",
        "x_tr_len = 10\n",
        "for i in range(0,x_tr_len):\n",
        "  print(i)\n",
        "  tr_target_summary.append(seq2summary(y_tr[i]))\n",
        "  x_i = x_tr[i].reshape(1,max_text_len)\n",
        "  tr_generated_summary.append(decode_sequence(x_i))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuzxQo3E4SlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07efa7aa-0f06-4436-8a9e-b821feb5d207"
      },
      "source": [
        "print(\"precision : \" + str(precision(tr_target_summary, tr_generated_summary)))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiHBkkwmFTPt",
        "colab_type": "text"
      },
      "source": [
        "### For Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2QGuitHFZD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c97e00e-d4c3-47eb-9f16-7c0b36bd36b0"
      },
      "source": [
        "val_target_summary = []\n",
        "val_generated_summary = []\n",
        "# x_val_len = len(x_val)\n",
        "x_val_len = 1\n",
        "for i in range(0,x_val_len):\n",
        "  print(i)\n",
        "  val_target_summary.append((y_val[i]))\n",
        "  x_i = x_val[i].reshape(1,max_text_len)\n",
        "  val_generated_summary.append(decode_sequence(x_i))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9n0nDG-F6KN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "b6601d4d-e1d8-4af4-e5ba-47787610d614"
      },
      "source": [
        "pre = precision(val_target_summary, val_generated_summary)\n",
        "print(pre)\n",
        "print(\"precision : \" + str(pre))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-22d0f559d8f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_target_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_generated_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-87698e18893e>\u001b[0m in \u001b[0;36mprecision\u001b[0;34m(target, generated)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mnum_overlapping_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_overlapping_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mgenerated_summary_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgenerated_summary_len\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-87698e18893e>\u001b[0m in \u001b[0;36mget_overlapping_words\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_overlapping_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[1;32m     94\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# Standard word tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \"\"\"\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \"\"\"\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \"\"\"\n\u001b[1;32m   1315\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0msl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \"\"\"\n\u001b[1;32m    311\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_tok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faHKW5pUF9KH",
        "colab_type": "text"
      },
      "source": [
        "# Inputting New Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srBPE2ZxZH72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getpos(word):\n",
        "  pos = nltk.pos_tag([word])[0][1][0]\n",
        "  wordnet_conv = {\"J\": wn.ADJ, \"N\": wn.NOUN, \"V\": wn.VERB, \"R\": wn.ADV}\n",
        "  if pos in wordnet_conv.keys():\n",
        "    return wordnet_conv.get(pos)\n",
        "  return \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5aEv4W8ZM81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lemmatization(text):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  text_tokenized = nltk.word_tokenize(text)\n",
        "  print(\"lemmatize with pos\")\n",
        "  for i in range(0,len(text_tokenized)):\n",
        "    text_lemmatized = []\n",
        "    for word in text_tokenized[i]:\n",
        "      getpos(word)\n",
        "      pos = getpos(word)\n",
        "      if pos != \"\":\n",
        "        lemma = lemmatizer.lemmatize(word, pos)\n",
        "        text_lemmatized.append(lemma)\n",
        "      else :\n",
        "        text_lemmatized.append(word)\n",
        "    text_lemmatized = ' '.join(map(str, text_lemmatized))\n",
        "    return text_lemmatized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WyRVL-DGACF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "724e5791-44a1-4c62-f0dd-08382a119374"
      },
      "source": [
        "input = [\"(CNN) — Earlier this year, Delta Air Lines announced a rethink on reclining seats. In an effort to disrupt fewer passengers' travel experiences, Delta said it'd begin revamping some of its jets to reduce the recline of coach seats from four inches to two inches and the recline of first class seats from 5.5 inches to 3.5 inches. For those who abhor the recline option, it's a small step. And for those who value it, well, it's a compromise. This seemingly innocuous topic is one where there are very much two minds on what's acceptable and what's not. Two CNN Travel staffers engage in a friendly debate about seat recline. Your seat. Your decision. Stacey Lastoe, senior editor at CNN Travel, is of above-average height and makes no apology about reclining; it's her right as a plane, train and bus passenger. She encourages the person sitting in front of her to recline as well. On the first leg of my flight to Japan for my honeymoon, my husband and I got upgraded to first class. Although it would just be a few hours in the sky en route to Dallas, I was excited about sipping Champagne, sitting back and relaxing. Flute in hand, I pushed back to recline my seat for maximum relaxation. But it would not budge; I appeared to be stuck in a dysfunctional seat. Or was I? Turns out the gentleman behind me had a dog in a crate down between his legs, positioned so the seat in front of his -- my seat -- had nowhere to go. Because we were newlyweds and loving every moment of it, I did not mind when my husband turned to the man and told him his wife wanted to recline her seat and asked if he could please rearrange his dog crate to allow for everyones comfort.\"]\n",
        "input_cleaned = re.sub(r'\\(CNN\\)|--|[^\\w\\s\\.]','',input)\n",
        "input_cleaned = re.sub(r'(\\.(?=[\\s\\r\\n]|$))','',input_cleaned)\n",
        "input_cleaned = re.sub(r'\\n',' ',input_cleaned)\n",
        "input_cleaned = re.sub(r'\\.','',input_cleaned)\n",
        "# remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "input_tokens = nltk.word_tokenize(input_cleaned)\n",
        "input_cleaned = \" \".join([word for word in input_tokens if not word in stop_words])\n",
        "#lemmatize\n",
        "input_lemmatized = lemmatization(input_cleaned)\n",
        "seq = np.array(input_lemmatized)\n",
        "seq =  x_tokenizer.texts_to_sequences(seq) \n",
        "seq = pad_sequences(seq,  maxlen=max_text_len, padding='post')\n",
        "summary = decode_sequence(deq)\n",
        "\n",
        "print(seq2text(seq))\n",
        "print(\"---\")\n",
        "print(summary)\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-1d7c171b9291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"(CNN) — Earlier this year, Delta Air Lines announced a rethink on reclining seats. In an effort to disrupt fewer passengers' travel experiences, Delta said it'd begin revamping some of its jets to reduce the recline of coach seats from four inches to two inches and the recline of first class seats from 5.5 inches to 3.5 inches. For those who abhor the recline option, it's a small step. And for those who value it, well, it's a compromise. This seemingly innocuous topic is one where there are very much two minds on what's acceptable and what's not. Two CNN Travel staffers engage in a friendly debate about seat recline. Your seat. Your decision. Stacey Lastoe, senior editor at CNN Travel, is of above-average height and makes no apology about reclining; it's her right as a plane, train and bus passenger. She encourages the person sitting in front of her to recline as well. On the first leg of my flight to Japan for my honeymoon, my husband and I got upgraded to first class. Although it would just be a few hours in the sky en route to Dallas, I was excited about sipping Champagne, sitting back and relaxing. Flute in hand, I pushed back to recline my seat for maximum relaxation. But it would not budge; I appeared to be stuck in a dysfunctional seat. Or was I? Turns out the gentleman behind me had a dog in a crate down between his legs, positioned so the seat in front of his -- my seat -- had nowhere to go. Because...\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\(CNN\\)|--|[^\\w\\s\\.]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0minput_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(\\.(?=[\\s\\r\\n]|$))'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
          ]
        }
      ]
    }
  ]
}