{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projectv4",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3814CBEDMGWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.layers import Attention\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SltBzhFNkBFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=70\n",
        "EPOCHS=80\n",
        "latent_dim=128\n",
        "embedding_dim=128\n",
        "test_train_split=0.35\n",
        "build_number=\"2\"\n",
        "# LEARNING_RATE=0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP41uqf_MiQL",
        "colab_type": "code",
        "outputId": "26140e35-3328-4c4b-f166-afc39eb2d126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "df = pd.read_csv('./data0.csv')\n",
        "df.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>file</th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0002c17436637c4fe1837c935c04de47adb18e9a.story</td>\n",
              "      <td>Los Angeles A medical doctor Vancouver British...</td>\n",
              "      <td>NEW A Canadian doctor says part team examining...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                            summary\n",
              "0           0  ...  NEW A Canadian doctor says part team examining...\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_F24WblBqov",
        "colab_type": "code",
        "outputId": "4759a426-a463-465b-e720-c220b1e57c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(df['summary'][0])\n",
        "df['summary'] = df['summary'].apply(lambda x: re.sub(r'\\..*$',' ',str(x)))\n",
        "print(df['summary'][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NEW A Canadian doctor says part team examining Harry Burkhart 2010 NEW Diagnosis autism severe anxiety posttraumatic stress disorder depression Burkhart also suspected German arson probe officials say Prosecutors believe German national set string fires Los Angeles\n",
            "NEW A Canadian doctor says part team examining Harry Burkhart 2010 NEW Diagnosis autism severe anxiety posttraumatic stress disorder depression Burkhart also suspected German arson probe officials say Prosecutors believe German national set string fires Los Angeles\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G_ytIi8Mo0R",
        "colab_type": "code",
        "outputId": "d2c9f3db-1f60-43cd-c8f8-67711e57b05f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in df['text']:\n",
        "      text_word_count.append(len(i.split(' ')))\n",
        "\n",
        "for i in df['summary']:\n",
        "      summary_word_count.append(len(i.split(' ')))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.ylabel('Documents')\n",
        "plt.xlabel('Word Count')\n",
        "plt.savefig('word_count_distro' + str(build_number) + '.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEWCAYAAAB/tMx4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gion9JsaNa32",
        "colab_type": "code",
        "outputId": "1a0f6fa3-5ca8-48a7-a7d6-23553a1fc598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cnt=0\n",
        "for i in df['summary']:\n",
        "    if(len(i.split())<=50):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(df['summary']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "036802b2-a57e-4fdf-d8d0-11632e5102e6",
        "id": "ZRV4cD1ONogl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cnt=0\n",
        "for i in df['text']:\n",
        "    if(len(i.split())<=800):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(df['text']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9541284403669725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-4Sq9mJNyCG",
        "colab_type": "code",
        "outputId": "40f2a497-1021-4270-fe8e-d113a3be62c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "max_text_len = max([len(txt) for txt in df['text']])\n",
        "max_summary_len = max([len(txt) for txt in df['summary']])\n",
        "print(max_text_len)\n",
        "print(max_summary_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7301\n",
            "330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmbBcXzvSZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(df['text'])\n",
        "Y = np.array(df['summary'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_ZKSCTyOFss",
        "colab_type": "code",
        "outputId": "8b1a2488-4425-4137-a133-d3ef9f23dcce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "x_tr,x_val,y_tr,y_val=train_test_split(X,Y,test_size=test_train_split,random_state=0,shuffle=True)\n",
        "print(x_tr.shape)\n",
        "print(x_val.shape)\n",
        "print(y_tr.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(495,)\n",
            "(268,)\n",
            "(495,)\n",
            "(268,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqDINa0yOpwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "# x_tokenizer = Tokenizer() \n",
        "# x_tokenizer.fit_on_texts(list(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUGjd9NiOYS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# thresh=10\n",
        "\n",
        "# cnt=0\n",
        "# tot_cnt=0\n",
        "# freq=0\n",
        "# tot_freq=0\n",
        "# \n",
        "# for key,value in x_tokenizer.word_counts.items():\n",
        "#     tot_cnt=tot_cnt+1\n",
        "#     tot_freq=tot_freq+value\n",
        "#     if(value<thresh):\n",
        "#         cnt=cnt+1\n",
        "#         freq=freq+value\n",
        "    \n",
        "# print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "# print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4SpRc-nMwvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_dict = {}\n",
        "text = df['text']\n",
        "\n",
        "for row in text: \n",
        "  for word in row.split(\" \"):\n",
        "    if word not in word_dict:\n",
        "      word_dict[word] = 1\n",
        "    else:\n",
        "      word_dict[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgI_aoWjOJC8",
        "colab_type": "code",
        "outputId": "1af45ec7-f9fc-4020-d0be-ad4cb6592bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# #prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=len(word_dict)) \n",
        "x_tokenizer.fit_on_texts(list(X))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "print(x_voc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7cdORwjOy6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "# y_tokenizer = Tokenizer()   \n",
        "# y_tokenizer.fit_on_texts(list(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSdu2pHCOk5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# thresh=30\n",
        "\n",
        "# cnt=0\n",
        "# tot_cnt=0\n",
        "# freq=0\n",
        "# tot_freq=0\n",
        "\n",
        "# for key,value in y_tokenizer.word_counts.items():\n",
        "#     tot_cnt=tot_cnt+1\n",
        "#     tot_freq=tot_freq+value\n",
        "#     if(value<thresh):\n",
        "#         cnt=cnt+1\n",
        "#         freq=freq+value\n",
        "    \n",
        "# print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "# print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMvhtHS0NBhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_dict = {}\n",
        "text = df['summary']\n",
        "\n",
        "for row in text: \n",
        "  for word in row.split(\" \"):\n",
        "    if word not in word_dict:\n",
        "      word_dict[word] = 1\n",
        "    else:\n",
        "      word_dict[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8B5C4G3O2JF",
        "colab_type": "code",
        "outputId": "ff73d26b-6008-4932-9bd4-4831caf68f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=len(word_dict)) \n",
        "y_tokenizer.fit_on_texts(list(Y))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1\n",
        "print(y_voc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoKBhvy8Pst3",
        "colab_type": "code",
        "outputId": "9f90bcc5-04fc-4f39-c2eb-738ae00e0b98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "#encoder lstm \n",
        "encoder_lstm = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "                                                          \n",
        "#dense layer\n",
        "decoder_dense = Dense(y_voc, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_12 (InputLayer)           (None, 7301)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_13 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 7301, 128)    3803136     input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_10 (Embedding)        (None, None, 128)    1024512     input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   [(None, 7301, 128),  131584      embedding_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_10 (LSTM)                  [(None, None, 128),  131584      embedding_10[0][0]               \n",
            "                                                                 lstm_9[0][1]                     \n",
            "                                                                 lstm_9[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, None, 8004)   1032516     lstm_10[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,123,332\n",
            "Trainable params: 6,123,332\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tnk6l_BRKsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfWjhzmcRMg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=4, restore_best_weights=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1EHMElMeY61",
        "colab_type": "code",
        "outputId": "2208bd98-c96c-43e8-f90d-116ce2add0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:], batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 495 samples, validate on 268 samples\n",
            "Epoch 1/80\n",
            "495/495 [==============================] - 129s 260ms/step - loss: 7.7796 - val_loss: 4.1837\n",
            "Epoch 2/80\n",
            "495/495 [==============================] - 126s 254ms/step - loss: 2.8477 - val_loss: 1.5067\n",
            "Epoch 3/80\n",
            "495/495 [==============================] - 128s 259ms/step - loss: 1.2713 - val_loss: 0.9959\n",
            "Epoch 4/80\n",
            "495/495 [==============================] - 130s 262ms/step - loss: 0.9206 - val_loss: 0.8197\n",
            "Epoch 5/80\n",
            "495/495 [==============================] - 126s 255ms/step - loss: 0.8025 - val_loss: 0.7445\n",
            "Epoch 6/80\n",
            "495/495 [==============================] - 125s 253ms/step - loss: 0.7445 - val_loss: 0.7096\n",
            "Epoch 7/80\n",
            "495/495 [==============================] - 121s 245ms/step - loss: 0.7119 - val_loss: 0.6855\n",
            "Epoch 8/80\n",
            "495/495 [==============================] - 121s 244ms/step - loss: 0.6819 - val_loss: 0.6743\n",
            "Epoch 9/80\n",
            "495/495 [==============================] - 121s 244ms/step - loss: 0.6690 - val_loss: 0.6642\n",
            "Epoch 10/80\n",
            "495/495 [==============================] - 120s 243ms/step - loss: 0.6496 - val_loss: 0.6662\n",
            "Epoch 11/80\n",
            "495/495 [==============================] - 121s 245ms/step - loss: 0.6420 - val_loss: 0.6544\n",
            "Epoch 12/80\n",
            "495/495 [==============================] - 121s 244ms/step - loss: 0.6322 - val_loss: 0.6576\n",
            "Epoch 13/80\n",
            "495/495 [==============================] - 122s 246ms/step - loss: 0.6266 - val_loss: 0.6601\n",
            "Epoch 14/80\n",
            "495/495 [==============================] - 124s 250ms/step - loss: 0.6226 - val_loss: 0.6689\n",
            "Epoch 15/80\n",
            "495/495 [==============================] - 124s 250ms/step - loss: 0.6184 - val_loss: 0.6756\n",
            "Epoch 16/80\n",
            "495/495 [==============================] - 124s 251ms/step - loss: 0.6155 - val_loss: 0.6701\n",
            "Epoch 17/80\n",
            "495/495 [==============================] - 124s 251ms/step - loss: 0.6110 - val_loss: 0.6775\n",
            "Epoch 18/80\n",
            "495/495 [==============================] - 125s 252ms/step - loss: 0.6080 - val_loss: 0.6824\n",
            "Epoch 19/80\n",
            "495/495 [==============================] - 125s 252ms/step - loss: 0.6044 - val_loss: 0.6954\n",
            "Epoch 20/80\n",
            "495/495 [==============================] - 125s 253ms/step - loss: 0.6026 - val_loss: 0.6961\n",
            "Epoch 21/80\n",
            "495/495 [==============================] - 125s 253ms/step - loss: 0.5995 - val_loss: 0.6956\n",
            "Epoch 22/80\n",
            "495/495 [==============================] - 126s 254ms/step - loss: 0.5968 - val_loss: 0.7093\n",
            "Epoch 23/80\n",
            "495/495 [==============================] - 126s 255ms/step - loss: 0.5938 - val_loss: 0.7121\n",
            "Epoch 24/80\n",
            "495/495 [==============================] - 126s 254ms/step - loss: 0.5916 - val_loss: 0.7145\n",
            "Epoch 25/80\n",
            "495/495 [==============================] - 125s 253ms/step - loss: 0.5889 - val_loss: 0.7079\n",
            "Epoch 26/80\n",
            "495/495 [==============================] - 125s 253ms/step - loss: 0.5863 - val_loss: 0.7238\n",
            "Epoch 27/80\n",
            "495/495 [==============================] - 126s 254ms/step - loss: 0.5839 - val_loss: 0.7272\n",
            "Epoch 28/80\n",
            "495/495 [==============================] - 126s 255ms/step - loss: 0.5817 - val_loss: 0.7310\n",
            "Epoch 29/80\n",
            "495/495 [==============================] - 126s 254ms/step - loss: 0.5788 - val_loss: 0.7347\n",
            "Epoch 30/80\n",
            "495/495 [==============================] - 126s 254ms/step - loss: 0.5768 - val_loss: 0.7279\n",
            "Epoch 31/80\n",
            "495/495 [==============================] - 126s 255ms/step - loss: 0.5740 - val_loss: 0.7236\n",
            "Epoch 32/80\n",
            "495/495 [==============================] - 125s 253ms/step - loss: 0.5715 - val_loss: 0.7316\n",
            "Epoch 33/80\n",
            "495/495 [==============================] - 125s 253ms/step - loss: 0.5699 - val_loss: 0.7414\n",
            "Epoch 34/80\n",
            "495/495 [==============================] - 126s 255ms/step - loss: 0.5667 - val_loss: 0.7478\n",
            "Epoch 35/80\n",
            "495/495 [==============================] - 126s 254ms/step - loss: 0.5648 - val_loss: 0.7424\n",
            "Epoch 36/80\n",
            "495/495 [==============================] - 127s 256ms/step - loss: 0.5619 - val_loss: 0.7384\n",
            "Epoch 37/80\n",
            "495/495 [==============================] - 127s 256ms/step - loss: 0.5595 - val_loss: 0.7512\n",
            "Epoch 38/80\n",
            "495/495 [==============================] - 127s 256ms/step - loss: 0.5576 - val_loss: 0.7460\n",
            "Epoch 39/80\n",
            "495/495 [==============================] - 129s 261ms/step - loss: 0.5543 - val_loss: 0.7551\n",
            "Epoch 40/80\n",
            "495/495 [==============================] - 129s 260ms/step - loss: 0.5521 - val_loss: 0.7514\n",
            "Epoch 41/80\n",
            "495/495 [==============================] - 126s 255ms/step - loss: 0.5493 - val_loss: 0.7554\n",
            "Epoch 42/80\n",
            "495/495 [==============================] - 126s 255ms/step - loss: 0.5480 - val_loss: 0.7580\n",
            "Epoch 43/80\n",
            "495/495 [==============================] - 126s 255ms/step - loss: 0.5445 - val_loss: 0.7548\n",
            "Epoch 44/80\n",
            "495/495 [==============================] - 127s 256ms/step - loss: 0.5419 - val_loss: 0.7646\n",
            "Epoch 45/80\n",
            "495/495 [==============================] - 126s 254ms/step - loss: 0.5401 - val_loss: 0.7594\n",
            "Epoch 46/80\n",
            "495/495 [==============================] - 126s 255ms/step - loss: 0.5376 - val_loss: 0.7573\n",
            "Epoch 47/80\n",
            "495/495 [==============================] - 127s 256ms/step - loss: 0.5345 - val_loss: 0.7615\n",
            "Epoch 48/80\n",
            "495/495 [==============================] - 131s 264ms/step - loss: 0.5328 - val_loss: 0.7586\n",
            "Epoch 49/80\n",
            "495/495 [==============================] - 129s 260ms/step - loss: 0.5302 - val_loss: 0.7659\n",
            "Epoch 50/80\n",
            "495/495 [==============================] - 127s 257ms/step - loss: 0.5281 - val_loss: 0.7633\n",
            "Epoch 51/80\n",
            "495/495 [==============================] - 127s 257ms/step - loss: 0.5255 - val_loss: 0.7639\n",
            "Epoch 52/80\n",
            "495/495 [==============================] - 127s 257ms/step - loss: 0.5228 - val_loss: 0.7683\n",
            "Epoch 53/80\n",
            "495/495 [==============================] - 128s 259ms/step - loss: 0.5207 - val_loss: 0.7709\n",
            "Epoch 54/80\n",
            "495/495 [==============================] - 127s 257ms/step - loss: 0.5192 - val_loss: 0.7707\n",
            "Epoch 55/80\n",
            "495/495 [==============================] - 127s 257ms/step - loss: 0.5166 - val_loss: 0.7700\n",
            "Epoch 56/80\n",
            "495/495 [==============================] - 128s 258ms/step - loss: 0.5149 - val_loss: 0.7679\n",
            "Epoch 57/80\n",
            "495/495 [==============================] - 126s 254ms/step - loss: 0.5126 - val_loss: 0.7710\n",
            "Epoch 58/80\n",
            "495/495 [==============================] - 124s 251ms/step - loss: 0.5109 - val_loss: 0.7732\n",
            "Epoch 59/80\n",
            "495/495 [==============================] - 122s 246ms/step - loss: 0.5080 - val_loss: 0.7706\n",
            "Epoch 60/80\n",
            "495/495 [==============================] - 121s 245ms/step - loss: 0.5057 - val_loss: 0.7777\n",
            "Epoch 61/80\n",
            "495/495 [==============================] - 121s 244ms/step - loss: 0.5052 - val_loss: 0.7773\n",
            "Epoch 62/80\n",
            "495/495 [==============================] - 121s 243ms/step - loss: 0.5019 - val_loss: 0.7768\n",
            "Epoch 63/80\n",
            "495/495 [==============================] - 124s 250ms/step - loss: 0.5003 - val_loss: 0.7780\n",
            "Epoch 64/80\n",
            "495/495 [==============================] - 122s 246ms/step - loss: 0.4986 - val_loss: 0.7790\n",
            "Epoch 65/80\n",
            "495/495 [==============================] - 121s 245ms/step - loss: 0.4963 - val_loss: 0.7812\n",
            "Epoch 66/80\n",
            "495/495 [==============================] - 121s 245ms/step - loss: 0.4944 - val_loss: 0.7828\n",
            "Epoch 67/80\n",
            "495/495 [==============================] - 120s 242ms/step - loss: 0.4926 - val_loss: 0.7840\n",
            "Epoch 68/80\n",
            "495/495 [==============================] - 121s 243ms/step - loss: 0.4909 - val_loss: 0.7842\n",
            "Epoch 69/80\n",
            "495/495 [==============================] - 120s 243ms/step - loss: 0.4885 - val_loss: 0.7864\n",
            "Epoch 70/80\n",
            "495/495 [==============================] - 121s 244ms/step - loss: 0.4869 - val_loss: 0.7859\n",
            "Epoch 71/80\n",
            "495/495 [==============================] - 120s 243ms/step - loss: 0.4854 - val_loss: 0.7885\n",
            "Epoch 72/80\n",
            "495/495 [==============================] - 121s 244ms/step - loss: 0.4828 - val_loss: 0.7891\n",
            "Epoch 73/80\n",
            "495/495 [==============================] - 121s 244ms/step - loss: 0.4807 - val_loss: 0.7901\n",
            "Epoch 74/80\n",
            "495/495 [==============================] - 121s 244ms/step - loss: 0.4800 - val_loss: 0.7909\n",
            "Epoch 75/80\n",
            "495/495 [==============================] - 121s 243ms/step - loss: 0.4776 - val_loss: 0.7920\n",
            "Epoch 76/80\n",
            "495/495 [==============================] - 121s 245ms/step - loss: 0.4759 - val_loss: 0.7926\n",
            "Epoch 77/80\n",
            "495/495 [==============================] - 120s 243ms/step - loss: 0.4737 - val_loss: 0.7951\n",
            "Epoch 78/80\n",
            "495/495 [==============================] - 121s 244ms/step - loss: 0.4721 - val_loss: 0.7954\n",
            "Epoch 79/80\n",
            "495/495 [==============================] - 120s 242ms/step - loss: 0.4698 - val_loss: 0.7972\n",
            "Epoch 80/80\n",
            "495/495 [==============================] - 120s 243ms/step - loss: 0.4685 - val_loss: 0.8001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76wrMc-cmecR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model' + str(build_number) + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqsG9m3PSDlk",
        "colab_type": "code",
        "outputId": "db0af7ae-54a7-4de1-ec4f-b08617a562d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.savefig('loss' + str(build_number) + '.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKQW8iEhKKeBFRFJKAS8iklIKeBGRlPr/IQ8LkVP/+FwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD278Ls8yL8E",
        "colab_type": "text"
      },
      "source": [
        "## Inference Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdBe5vsjSGE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UxF5XdZYGUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_inputs)\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juEcXwFOnKwo",
        "colab_type": "code",
        "outputId": "7f3b0fb8-9936-46fc-e196-ea852e9f19b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "encoder_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        (None, 7301)              0         \n",
            "_________________________________________________________________\n",
            "embedding_9 (Embedding)      (None, 7301, 128)         3803136   \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                [(None, 7301, 128), (None 131584    \n",
            "=================================================================\n",
            "Total params: 3,934,720\n",
            "Trainable params: 3,934,720\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4PESOr1pXRk",
        "colab_type": "code",
        "outputId": "5b674eda-78ac-4729-d8d5-78218e5f5b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "decoder_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_10 (Embedding)        (None, None, 128)    1024512     input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_10 (LSTM)                  [(None, None, 128),  131584      embedding_10[1][0]               \n",
            "                                                                 input_14[0][0]                   \n",
            "                                                                 input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, None, 8004)   1032516     lstm_10[1][0]                    \n",
            "==================================================================================================\n",
            "Total params: 2,188,612\n",
            "Trainable params: 2,188,612\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wvg_AhinKMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('encoder_model' + str(build_number) + '.h5')\n",
        "model.save('decoder_model' + str(build_number) + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j27_ySW5aRWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUvQlsNklUds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq): \n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, max_summary_len))\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "      output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c]) \n",
        "      print(output_tokens)\n",
        "      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "      print(sampled_token_index)\n",
        "      # print(sampled_token_index)\n",
        "      if (sampled_token_index != 0 ):\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_token\n",
        "      else :\n",
        "        stop_condition = True\n",
        "      if (len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "              stop_condition = True\n",
        "       # Update the target sequence (of length 1).\n",
        "      # target_seq = np.zeros((1,1))\n",
        "      target_seq = np.zeros((1, max_summary_len))\n",
        "      target_seq[0, sampled_token_index] = 1\n",
        "\n",
        "      # Update internal states\n",
        "      e_h, e_c = h, c\n",
        "      \n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsRB_AJHaXL7",
        "colab_type": "code",
        "outputId": "aa24fdb7-22bc-4876-eee9-83f46287fa27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(0,5):\n",
        "    print(\"Article:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    x_i = x_tr[i].reshape(1,max_text_len)   \n",
        "    print(\"Generated summary:\",decode_sequence(x_i))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article: rome amanda knoxs exboyfriend murder trial codefendant reveal new book sometimes question innocence bizarre behavior day british student found dead apartment raffaele sollecitos memoir honor bound my journey hell back amanda knox first book write anyone directly involve meredith kercher murder trial perugia italy kercher 21yearold british student found stabbed death italian apartment share knox 25 seattle sollecito knox convict kerchers murder 2009 set free appeal 2011 they face final highcourt decision march judge explains murder acquittal italian prosecutor appeal decision rudy guede ivory coast convict separately 2008 his conviction upheld appeal 2009 sollecitos book draw heavily diary kept letter write friend family hometown newspaper year prison preface say he chronicle day murder admit knox smoke marijuana afternoon say regret cloud memory happen while maintain innocence say clearly remember even knox spent night he knox make mistake morning discovery include trust police investigator writes sollecito writes time uncomfortable knoxs bizarre behavior say prosecutor use of thing amanda day nothing attract criticism failure raise alarm soon saw many thing place writes it wasnt police attack many italians include family could fathom could go ahead shower find blood tap much less put wet foot bath mat also stain drag across floor neither knox solid alibi night kerchers murder sollecito writes we real alibi night november 1 except lawyer protect us seem propensity say thing without think say sollecito describes doubt knoxs innocence time refer night two arrest when i first found amanda sign name i furious writes okay lot pressure i could invent stuff nowhere he give account life inside several italian prison befriend rapist murderer played cockroach scrubbed cell dirt mold while share family personal story saga lengthy trial book give little attention evidence present court the revelation include distrust lawyer father hire they intent get sollecito abandon knox accuse murder write foxy knoxy sex violence medium hysteria at one time first conviction sollecitos father sought help private lawyer connect case spoke perugia prosecutor giuliano mignini strike plea deal cut sollecitos sentence exchange evidence knox sollecitos lead attorney giulia bongiorno prominent parliamentarian almost walk case backroom deal mignini decline comment book case high court appeal complete sollecitos book especially hard mignini accuses concoct conspiracyladen plotline umberto eco instead normal investigation he lament star treatment knox receive say prosecution focus squarely codefendant he write believe arrest way get knox i dont think prosecution police ever seriously thought murderer write they one override reason arrest throw solitary confinement threaten life imprisonment pressure roll testify amanda sollecito condemns treatment perugia police say would give food access lawyer question even though clear treat suspect person inform fact case sollecito give several spontaneous declaration original appellate trial never take stand defense the book offer many detail behind scene four year kercher kill two release answer question happen night sollecito write believe guede act alone kill kercher in epilogue sollecito recount go visit knox seattle last fall nervous see i wasnt sure good idea i continued waver back forth even i book ticket we much perhaps owe live life leave peace guede write book publisher accord lawyer knoxs book due release spring knox sign book deal harper collins \n",
            "Original summary: raffaele sollecito wrote honor bound my journey hell back amanda knox sollecito knox convicted murder later freed appeal meredith kercher found stabbed death apartment shared knox \n",
            "[[[6.61487639e-01 2.25928295e-02 8.39317404e-03 ... 2.15317204e-08\n",
            "   2.74268892e-08 2.37958755e-08]\n",
            "  [9.60563183e-01 5.86317293e-03 2.99487147e-03 ... 1.25497646e-09\n",
            "   1.56748381e-09 1.18996590e-09]\n",
            "  [9.92238343e-01 1.69937487e-03 8.17962515e-04 ... 1.29452588e-10\n",
            "   1.58577179e-10 1.16740520e-10]\n",
            "  ...\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]]]\n",
            "0\n",
            "Generated summary: \n",
            "\n",
            "\n",
            "Article: over past week almost third americans head back classroom early learn center university student teacher accompany usual seasonal mix joy jitter or perhaps lately seem weve inundate bad news the nation report card crummy school broke fail graduate cant find job and competition resource put increase pressure standardize test score cheat scandal become practically hohum among headline resides quietly sober fact this year high school graduate first educate entirely no child left behind act in word whole generation kid whove grown emphasis multiple choice test whove taught know one right answer important process inquiry whove learn admit i dont know crime but problem isnt simply narrowly conceive educational policy pressure know right answer precisely appear know isnt limited classroom its pervasive throughout culture reality daunt hopeful daunting mean real reform require widespread change hopeful mean there something every one us maybe even start today im talk break habit fake knowledge order save face for us fear know look dumb get ingrain small reinforce throughout life way subtle overt for every time someone reassure us theres thing stupid question werent ample experience playground dinner table yes classroom convince us otherwise anyone who ever reprimand ridicule reveal ignorance know well the taste shame bitter linger well go great length avoid often without deliberate thought how many time i found nod feign recognition someone make reference person book assume i know how many time i guilty unwittingly inflict similar discomfort others in walk life present know demeanor practically job requirement one financial adviser recall early career anxious impress upon client knew hed use meeting information dump subsequently learn theyd embarrass speak confess idea talk a surgeon tell time new intern afraid admit unfamiliarity procedure ask question plunge confidently make incision four time longer patient told scar would politicians routinely face shame confess know remember rick perrys memory lapse 2011 republican primary debate it seem well forgive elect official breach ethic let admit anything less invulnerable certainty kiss vote goodbye for past several year ive make conscious effort candid limit knowledge as college teacher ive discuss intention explicitly student colleague guess im mortify report despite public resolution practice essential form academic integrity i still catch engage kind kneejerk facesaving passive dissimulation semiregular basis based i hear others im alone such behavior apparently endemic so for starter talk own instance fake knowledge initiate conversation make us less susceptible behavior youre likely hear funny story experience share vulnerability humanize make closer connection best creates environment stand grow my friend lori year high school history teacher constantly encourage student play wideopen space uncertainty one way share gap knowledge shed model comfort figure everything delight this seem convey real intellectual pleasure lay adventure explore unknown often shed assign shakespeare way get student think power status shed read one play ask whos powerful scene her student anxious deliver right answer would demand clarification what mean powerful lori would shrug unfurl finger nothing sleeve this isnt trick if student protest shed say simply thats i know and theyd force grapple answer question meaning question definition power first place authority figure hand you guy figure you decide in way learn history drama also shift power may wield classroom work society work nature right answer oppose illimitable richness interrogate question this excites i think head back school fall prospect bring generous generative energy classroom perhaps fill oval number two pencil important help us understand far achieve equity school across nation that vital project deserve urgent attention but wont ever achieve equity let alone excellence dont also work make school place feel safe say i dont know the opinion express commentary solely leah hager cohen \n",
            "Original summary: this years high school grads entirely taught no child left behind leah cohen theres much emphasis memorizing right answer rather encouraging inquiry she says people deathly afraid admitting dont know something cohen our fear ignorance keeps us learning much \n",
            "[[[6.61487639e-01 2.25928295e-02 8.39317404e-03 ... 2.15317204e-08\n",
            "   2.74268892e-08 2.37958755e-08]\n",
            "  [9.60563183e-01 5.86317293e-03 2.99487147e-03 ... 1.25497646e-09\n",
            "   1.56748381e-09 1.18996590e-09]\n",
            "  [9.92238343e-01 1.69937487e-03 8.17962515e-04 ... 1.29452588e-10\n",
            "   1.58577179e-10 1.16740520e-10]\n",
            "  ...\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]]]\n",
            "0\n",
            "Generated summary: \n",
            "\n",
            "\n",
            "Article: as one world lead financial capital hong kong dream destination business traveler with skyscraper city world fine din planet city might well leave beg flight cancellation squeeze extra day to help enjoy city highlight here guide get town eatingsleeping well buying best souvenir leave expense account youll proud easiest comfortable airport transfer forget everything know subway hong kongs airport express train service blow away even jade commuter trains clean comfortable spacious always time get city 24 minute flat faster car service ever aspire better still train easy walk procedure simple figure upon arrival there virtually stress get ticket get train exit arrival terminal at hk100 per ride train depart 10minute interval 554 1128 pm 12minute interval 1128 pm 1248 daily memorable meal theres shortage michelinstarred restaurant hong kong but find memorable local meal youll think month far challenge luk yu teahouse historic art decoinspired feel waiter stuck place decade killer cantonese food found anywhere else glamorous clientele storied past include mob hit din room youll get early breakfast old fashion dim sum duck chestnut pastry luk yu teahouse luk yu building 2426 stanley st central 852 2523 1970 centrally locate room view for true homeawayfromhome feel penthouse suite the upper house good call with 180 square meter understated elegance wraparound view hong kong spainspired bathroom ultimate city stay bonus feature chance bumping celebrity elevator the upper house pacific place 88 queensway admiralty 852 2918 1838 where get unique addition wardrobe hong kongs fashion design scene young eclectic fun a place get taste k11 mall dubbed art mall support chinese contemporary art reputable gallery basement the mall house local designer brand offer curated selection designer product k11 design store k11 18 hanoi road tsim sha tsui kowloon 852 3118 8070 where take killer photo sure could ride historic peak tram tourist snap great photo hong kong top victoria peak foolproof but could also join local hiker many walk lion rock peak incredible sweep panorama kowloon surround pristine nature experience heart city to see hong kong past present walkable nutshell head central sheung wan districts some old part city crumble colonialera tenement building decadesold shop found area gentrifying comfortably soho poho neighborhood po hing fong hollywood road area offer thoughtful eatery unpretentious boutique general direction keep walk west queens road central parallel hollywood road graham street thing start get interest classy easytopack souvenir some best memory visitor take away hong kong center food to take little bit local flavor home pick couple jar xo sauce every restaurant worth reputation secret recipe mildly spicy local condiment make dry often precious seafood well chinese ham we love one mandarin oriental cake shop 35small 45large jar mandarin oriental cake shop mf mandarin oriental hong kong 5 connaught road central 852 2825 4008 \n",
            "Original summary: hong kongs airport express gets city center 24 minutes the hike lion rock peak offers stunning panoramas kowloon across island some hong kongs oldest buildings colonialera structures found central sheung wan districts \n",
            "[[[6.61487639e-01 2.25928295e-02 8.39317404e-03 ... 2.15317204e-08\n",
            "   2.74268892e-08 2.37958755e-08]\n",
            "  [9.60563183e-01 5.86317293e-03 2.99487147e-03 ... 1.25497646e-09\n",
            "   1.56748381e-09 1.18996590e-09]\n",
            "  [9.92238343e-01 1.69937487e-03 8.17962515e-04 ... 1.29452588e-10\n",
            "   1.58577179e-10 1.16740520e-10]\n",
            "  ...\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]]]\n",
            "0\n",
            "Generated summary: \n",
            "\n",
            "\n",
            "Article: nato representative lawmaker alliance nation meet iceland thursday discus security challenge likely arise arctic circle thaw global warm opening part arctic development raise security concern the area one planet fragile pristine ecosystem sits atop bounty untapped fossil fuel and melt polar ice make arctic accessible ship several country scramble claim jurisdiction area the economic interest reflect compete claim relevant stakeholder resume military presence area nato say web site as region endure strategic importance nato allied security development high north require careful ongoing examination the us geological survey estimate 90 billion barrel oil 44 billion barrel natural gas liquid 1670 trillion cubic foot natural gas recoverable frozen region north arctic circle at time arctic water warm quickly entire region could icefree 2013 already russia canada united states denmark norway sweden iceland finland fight lay claim arctics icy real estate unlike antarctica treaty prohibits territorial claim agreement vast expanse arctic so question drilling right shipping lane somewhat murky according un convention law sea country entitle exclusive economic zone 200 mile shore but country try extend zone russian scientist want prove seabed north pole part eurasian continental shelf area call lomonosov ridge if case region would russian control moscow argue un commission 2001 ridge extension continental territory but united nations ask evidence danish scientist try prove lomonosov ridge connect greenland canadian scientist look link ridge ellesmere island canadian territory nato secretary general jaap de hoop scheffer attend twoday conference reykjavek \n",
            "Original summary: nato meeting iceland discuss arctic security challenges thawing arctic poses questions controls regions resources number countries laying claim arctic due untapped fossil fuel deposits \n",
            "[[[6.61487639e-01 2.25928295e-02 8.39317404e-03 ... 2.15317204e-08\n",
            "   2.74268892e-08 2.37958755e-08]\n",
            "  [9.60563183e-01 5.86317293e-03 2.99487147e-03 ... 1.25497646e-09\n",
            "   1.56748381e-09 1.18996590e-09]\n",
            "  [9.92238343e-01 1.69937487e-03 8.17962515e-04 ... 1.29452588e-10\n",
            "   1.58577179e-10 1.16740520e-10]\n",
            "  ...\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]]]\n",
            "0\n",
            "Generated summary: \n",
            "\n",
            "\n",
            "Article: arsenal kept slim hope win season english premier league title alive beating relegation threaten burnley 10 turf moor a first half goal welsh international aaron ramsey enough separate two side secure arsenals hold second place more importantly take north london club within four point first place chelsea two club play next week but chelsea two game hand play lowly queens park rangers sunday team struggle relegation good form arsenal superb form since start year transform look another mediocre season struggle secure fourth place champions league qualification one least shot win title after go ahead arsenal rarely look danger concede show midfield pragmatism epitomize like francis coquelin also played crucial role goal he absolutely consistent quality defensive work arsenal coach arsene wenger told sky sports game ask coquelins contribution arsenals current run they eight game row since introduce previously overlook young frenchman defensive midfield position he player us seven year 17 he 24 wenger explain sometimes patient i happy show great mental strength now eye next week clash arsenal chelsea likely decide title they game hand say wenger play club title aspiration but well keep go thats win important us today relegation dogfight meanwhile good day team bottom league aston villa continued good form since appoint coach tim sherwood 10 victory tottenham fire sherwood last season belgian international christian benteke score goal game eighth six match secure vital three point give midlands club breathing space another midlands club look shoulder west brom concede injury time goal lose 32 bottom club leicester city but awful day sunderlands former dutch international coach dick advocaat saw team lose 41 home form team crystal palace democratic republic congo international yannick bolasie score crystal palaces first ever hat trick premier league secure easy victory \n",
            "Original summary: arsenal beat burnley 10 epl a goal aaron ramsey secured three points win cuts chelseas epl lead four points \n",
            "[[[6.61487639e-01 2.25928295e-02 8.39317404e-03 ... 2.15317204e-08\n",
            "   2.74268892e-08 2.37958311e-08]\n",
            "  [9.60563183e-01 5.86317293e-03 2.99487147e-03 ... 1.25497646e-09\n",
            "   1.56748381e-09 1.18996590e-09]\n",
            "  [9.92238343e-01 1.69937487e-03 8.17962515e-04 ... 1.29452588e-10\n",
            "   1.58577179e-10 1.16740520e-10]\n",
            "  ...\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]\n",
            "  [9.99938726e-01 1.21678349e-05 3.79561538e-06 ... 1.20091576e-11\n",
            "   1.31197770e-11 1.11118033e-11]]]\n",
            "0\n",
            "Generated summary: \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq3gUakWYW_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('xtokenizer.pickle', 'wb') as handle:\n",
        "  pickle.dump(x_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('ytokenizer.pickle', 'wb') as handle:\n",
        "  pickle.dump(y_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}