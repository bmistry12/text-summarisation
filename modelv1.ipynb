{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projectv3",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3814CBEDMGWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.layers import Attention\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SltBzhFNkBFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=128\n",
        "EPOCHS=100\n",
        "latent_dim=256\n",
        "embedding_dim=100\n",
        "test_train_split=0.25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP41uqf_MiQL",
        "colab_type": "code",
        "outputId": "283c38bc-bcb9-4c1e-f5f5-8c299a72a395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "df = pd.read_csv('./data0.csv')\n",
        "df.head(1)"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>file</th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0002c17436637c4fe1837c935c04de47adb18e9a.story</td>\n",
              "      <td>Los Angeles A medical doctor Vancouver British...</td>\n",
              "      <td>NEW A Canadian doctor says she was part of a t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                            summary\n",
              "0           0  ...  NEW A Canadian doctor says she was part of a t...\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G_ytIi8Mo0R",
        "colab_type": "code",
        "outputId": "143a0a7e-77ab-47f1-bc4f-c762c6d99f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in df['text']:\n",
        "      text_word_count.append(len(i.split(' ')))\n",
        "\n",
        "for i in df['summary']:\n",
        "      summary_word_count.append(len(i.split(' ')))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gion9JsaNa32",
        "colab_type": "code",
        "outputId": "cbf2d97d-c7ca-4228-9dc6-565bf01bf518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cnt=0\n",
        "for i in df['summary']:\n",
        "    if(len(i.split())<=60):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(df['summary']))"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9777195281782438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d3f96800-77a5-45fb-d35c-db938ee3c443",
        "id": "ZRV4cD1ONogl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cnt=0\n",
        "for i in df['text']:\n",
        "    if(len(i.split())<=600):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(df['text']))"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8401048492791612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-4Sq9mJNyCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_text_len=600\n",
        "max_summary_len=60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmbBcXzvSZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(df['text'])\n",
        "Y = np.array(df['summary'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_ZKSCTyOFss",
        "colab_type": "code",
        "outputId": "403c757f-6ab1-4b02-986b-f2c0b892f9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "x_tr,x_val,y_tr,y_val=train_test_split(X,Y,test_size=test_train_split,random_state=0,shuffle=True)\n",
        "print(x_tr.shape)\n",
        "print(x_val.shape)\n",
        "print(y_tr.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(572,)\n",
            "(191,)\n",
            "(572,)\n",
            "(191,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqDINa0yOpwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUGjd9NiOYS3",
        "colab_type": "code",
        "outputId": "68d30d68-3db6-40ea-e3a6-eacba46b5bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "thresh=3\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 59.30358678984179\n",
            "Total Coverage of rare words: 6.505136067080099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgI_aoWjOJC8",
        "colab_type": "code",
        "outputId": "d2709734-2bc3-4b3c-9036-42a567a118fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt) \n",
        "x_tokenizer.fit_on_texts(list(X))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "print(x_voc)"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7cdORwjOy6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSdu2pHCOk5s",
        "colab_type": "code",
        "outputId": "3460abf7-f539-4490-8c32-29ec8ab02c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "thresh=2\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 56.56853043047996\n",
            "Total Coverage of rare words: 14.020296164576754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8B5C4G3O2JF",
        "colab_type": "code",
        "outputId": "c5753308-5d6a-4803-bfd2-0d8b312dfcc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt) \n",
        "y_tokenizer.fit_on_texts(list(Y))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1\n",
        "print(y_voc)"
      ],
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoKBhvy8Pst3",
        "colab_type": "code",
        "outputId": "3b68e5aa-b41a-4dff-9338-d9bdc18d9c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm1(enc_emb)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "                                                          \n",
        "#dense layer\n",
        "decoder_dense = Dense(y_voc, activation='softmax')\n",
        "# decoder_dense = Dense(y_voc, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_46\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_83 (InputLayer)           (None, 600)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_84 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_45 (Embedding)        (None, 600, 100)     2673800     input_83[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_46 (Embedding)        (None, None, 100)    808500      input_84[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_49 (LSTM)                  [(None, 600, 256), ( 365568      embedding_45[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_50 (LSTM)                  [(None, None, 256),  365568      embedding_46[0][0]               \n",
            "                                                                 lstm_49[0][1]                    \n",
            "                                                                 lstm_49[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, None, 8085)   2077845     lstm_50[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,291,281\n",
            "Trainable params: 6,291,281\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tnk6l_BRKsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfWjhzmcRMg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1EHMElMeY61",
        "colab_type": "code",
        "outputId": "5a8759e6-fbd0-40b2-c185-63947561bda0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 572 samples, validate on 191 samples\n",
            "Epoch 1/100\n",
            "572/572 [==============================] - 19s 33ms/step - loss: 8.5225 - val_loss: 6.4970\n",
            "Epoch 2/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 6.0860 - val_loss: 5.9572\n",
            "Epoch 3/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 5.7930 - val_loss: 5.9784\n",
            "Epoch 4/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 5.7143 - val_loss: 6.0553\n",
            "Epoch 5/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 5.7081 - val_loss: 5.9486\n",
            "Epoch 6/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 5.6107 - val_loss: 5.8541\n",
            "Epoch 7/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 5.5804 - val_loss: 6.0757\n",
            "Epoch 8/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 5.5283 - val_loss: 5.8763\n",
            "Epoch 9/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 5.4883 - val_loss: 5.8668\n",
            "Epoch 10/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 5.4329 - val_loss: 5.9328\n",
            "Epoch 11/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 5.4808 - val_loss: 5.8700\n",
            "Epoch 12/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 5.3503 - val_loss: 5.8177\n",
            "Epoch 13/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 5.3138 - val_loss: 5.8902\n",
            "Epoch 14/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 5.2663 - val_loss: 5.8357\n",
            "Epoch 15/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 5.2464 - val_loss: 5.8801\n",
            "Epoch 16/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 5.2160 - val_loss: 5.8474\n",
            "Epoch 17/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 5.1919 - val_loss: 5.8964\n",
            "Epoch 18/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 5.1655 - val_loss: 5.8971\n",
            "Epoch 19/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 5.1526 - val_loss: 5.9692\n",
            "Epoch 20/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 5.1325 - val_loss: 5.9088\n",
            "Epoch 21/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 5.1068 - val_loss: 5.9921\n",
            "Epoch 22/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 5.0972 - val_loss: 5.9836\n",
            "Epoch 23/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 5.0631 - val_loss: 6.0271\n",
            "Epoch 24/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 5.0591 - val_loss: 5.9905\n",
            "Epoch 25/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 5.0280 - val_loss: 6.0340\n",
            "Epoch 26/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 5.0112 - val_loss: 6.0140\n",
            "Epoch 27/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.9903 - val_loss: 6.0593\n",
            "Epoch 28/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 4.9738 - val_loss: 6.0397\n",
            "Epoch 29/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.9515 - val_loss: 6.0539\n",
            "Epoch 30/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.9317 - val_loss: 6.0485\n",
            "Epoch 31/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 4.9250 - val_loss: 6.0819\n",
            "Epoch 32/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.8882 - val_loss: 6.0812\n",
            "Epoch 33/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.8825 - val_loss: 6.0837\n",
            "Epoch 34/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.8547 - val_loss: 6.0960\n",
            "Epoch 35/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.8392 - val_loss: 6.0880\n",
            "Epoch 36/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 4.8264 - val_loss: 6.1054\n",
            "Epoch 37/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.8075 - val_loss: 6.1098\n",
            "Epoch 38/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 4.7810 - val_loss: 6.1154\n",
            "Epoch 39/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 4.7650 - val_loss: 6.1067\n",
            "Epoch 40/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 4.7497 - val_loss: 6.1258\n",
            "Epoch 41/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.7282 - val_loss: 6.1270\n",
            "Epoch 42/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.7111 - val_loss: 6.1365\n",
            "Epoch 43/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.6897 - val_loss: 6.1462\n",
            "Epoch 44/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 4.6734 - val_loss: 6.1512\n",
            "Epoch 45/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.6476 - val_loss: 6.1498\n",
            "Epoch 46/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.6280 - val_loss: 6.1620\n",
            "Epoch 47/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 4.6196 - val_loss: 6.1671\n",
            "Epoch 48/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.5939 - val_loss: 6.1823\n",
            "Epoch 49/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.5833 - val_loss: 6.1822\n",
            "Epoch 50/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.5584 - val_loss: 6.1935\n",
            "Epoch 51/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.5384 - val_loss: 6.1950\n",
            "Epoch 52/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.5291 - val_loss: 6.2035\n",
            "Epoch 53/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 4.5061 - val_loss: 6.2100\n",
            "Epoch 54/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 4.4868 - val_loss: 6.2172\n",
            "Epoch 55/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.4626 - val_loss: 6.2314\n",
            "Epoch 56/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.4457 - val_loss: 6.2382\n",
            "Epoch 57/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.4471 - val_loss: 6.2368\n",
            "Epoch 58/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.4067 - val_loss: 6.2530\n",
            "Epoch 59/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.3947 - val_loss: 6.2562\n",
            "Epoch 60/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.3881 - val_loss: 6.2649\n",
            "Epoch 61/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 4.3569 - val_loss: 6.2723\n",
            "Epoch 62/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.3427 - val_loss: 6.2806\n",
            "Epoch 63/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.3239 - val_loss: 6.2884\n",
            "Epoch 64/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.3048 - val_loss: 6.2958\n",
            "Epoch 65/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.2882 - val_loss: 6.3048\n",
            "Epoch 66/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.2875 - val_loss: 6.3148\n",
            "Epoch 67/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.2483 - val_loss: 6.3232\n",
            "Epoch 68/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 4.2300 - val_loss: 6.3363\n",
            "Epoch 69/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.2289 - val_loss: 6.3384\n",
            "Epoch 70/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.1961 - val_loss: 6.3482\n",
            "Epoch 71/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.1790 - val_loss: 6.3566\n",
            "Epoch 72/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.1894 - val_loss: 6.3646\n",
            "Epoch 73/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.2246 - val_loss: 6.3695\n",
            "Epoch 74/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.1992 - val_loss: 6.3788\n",
            "Epoch 75/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.1735 - val_loss: 6.3824\n",
            "Epoch 76/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.1176 - val_loss: 6.3908\n",
            "Epoch 77/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.0853 - val_loss: 6.3975\n",
            "Epoch 78/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.0955 - val_loss: 6.4076\n",
            "Epoch 79/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.0611 - val_loss: 6.4092\n",
            "Epoch 80/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.0564 - val_loss: 6.4251\n",
            "Epoch 81/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.0285 - val_loss: 6.4250\n",
            "Epoch 82/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 4.0080 - val_loss: 6.4371\n",
            "Epoch 83/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 3.9900 - val_loss: 6.4413\n",
            "Epoch 84/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 3.9715 - val_loss: 6.4502\n",
            "Epoch 85/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 3.9593 - val_loss: 6.4558\n",
            "Epoch 86/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 3.9506 - val_loss: 6.4672\n",
            "Epoch 87/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 3.9203 - val_loss: 6.4711\n",
            "Epoch 88/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 3.9285 - val_loss: 6.4794\n",
            "Epoch 89/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 3.8879 - val_loss: 6.4830\n",
            "Epoch 90/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 3.8688 - val_loss: 6.4957\n",
            "Epoch 91/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 3.8511 - val_loss: 6.5033\n",
            "Epoch 92/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 3.8348 - val_loss: 6.5104\n",
            "Epoch 93/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 3.8231 - val_loss: 6.5106\n",
            "Epoch 94/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 3.8056 - val_loss: 6.5209\n",
            "Epoch 95/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 3.7779 - val_loss: 6.5295\n",
            "Epoch 96/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 3.7665 - val_loss: 6.5389\n",
            "Epoch 97/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 3.7549 - val_loss: 6.5406\n",
            "Epoch 98/100\n",
            "572/572 [==============================] - 10s 17ms/step - loss: 3.7287 - val_loss: 6.5452\n",
            "Epoch 99/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 3.7172 - val_loss: 6.5542\n",
            "Epoch 100/100\n",
            "572/572 [==============================] - 10s 18ms/step - loss: 3.6998 - val_loss: 6.5625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqsG9m3PSDlk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3a57125b-f214-48ec-cae0-73ba89ae042a"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHvf/AcVy7Dza4NS4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD278Ls8yL8E",
        "colab_type": "text"
      },
      "source": [
        "## Inference Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdBe5vsjSGE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UxF5XdZYGUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_inputs)\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4PESOr1pXRk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "dd61bed6-28ca-4004-9bdb-5ec56dcb50b1"
      },
      "source": [
        "decoder_model.summary()"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_84 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_46 (Embedding)        (None, None, 100)    808500      input_84[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_88 (InputLayer)           (None, 256)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_89 (InputLayer)           (None, 256)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_50 (LSTM)                  [(None, None, 256),  365568      embedding_46[2][0]               \n",
            "                                                                 input_88[0][0]                   \n",
            "                                                                 input_89[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, None, 8085)   2077845     lstm_50[2][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,251,913\n",
            "Trainable params: 3,251,913\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j27_ySW5aRWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUvQlsNklUds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq): \n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    # print(e_out)\n",
        "    target_seq = np.zeros((1,1))\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c]) \n",
        "      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "      # print(sampled_token_index)\n",
        "      if (sampled_token_index != 0 ):\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_token\n",
        "      else :\n",
        "        stop_condition = True\n",
        "      if (len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "              stop_condition = True\n",
        "       # Update the target sequence (of length 1).\n",
        "      target_seq = np.zeros((1,1))\n",
        "      target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "      # Update internal states\n",
        "      e_h, e_c = h, c\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsRB_AJHaXL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "7d76e755-cff8-4051-f236-76d7c761a92c"
      },
      "source": [
        "for i in range(0,5):\n",
        "    print(\"Article:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Generated summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article: scores people without bread day kill syrian warplane bombed bakery western village halfaya opposition activist say sunday more 100 people kill opposition local coordination committees syria say the death toll could rise activist group say an activist oversaw burial many body say least 109 people die hassan alrajb told cnn 69 people identify bury 15 others laid rest without idd at least 25 body still site hospital worker say road cut unable reach bakery say the hospital handle wound say an lcc activist told cnn go scene there dozen dead thrown street the resident shock state fear it chaotic mahmoud alawy say videos post social medium purport show aftermath attack many body limb apparently blown others lay bloody street rubble strewn sidewalk uniformed free syrian army soldier civilian scramble pull survivor carnage cnn independently confirm government opposition report syria government restrict access journalist the town lack ingredient bread week aid group deliver provision saturday alawy say hundreds people line bakery sunday alrajb say town three bakery one open 1 pm workers begin distribute bread two hour later he roof 200 meter 219 yard bakery 4 pm saw plane overhead he scramble toward scene heard cry emergency emergency say the first floor collapse second floor four rocket fire say attack alawy claimed government target large gathering people artillery shell recent day since free syrian army liberate town syrian force about hour bakery attack 15 shell fire halfaya nearby town alrajb say the hama revolution command council network activist affiliate fsa hama province say mig warplane bombed bakery many syrians face food shortage need winter weather set the united nations estimate 25 million need humanitarian assistance earlier week opposition group also say rebel regime force battle near hospital halfaya twentyfive people die lcc say syria fire scud missile nato say russia syria consolidates chemical weapon cnns salma abdelaziz contribute report \n",
            "Original summary: new one resident says 84 people have been buried with more bodies still on the streets new people had been waiting for bread for almost a week activists say mig planes bombed a bakery in western syria videos posted on social media show rebel soldiers civilians rushing to scene \n",
            "Generated summary:  is the first the first cristiano ronaldo of the united cup the first the century states in the first message in the united and jean also and jean match\n",
            "\n",
            "\n",
            "Article: all 77 nato service member wound saturday attack coalition base afghanistan us troop spokeswoman international security assistance force say sunday two afghan civilian kill 25 others also wound attack occur eve 10th anniversary al qaedas attack united states 911 us army sgt lindsey kibler say none injury lifethreatening isaf say wound expect return duty shortly the truck bombing take place centraleast province wardak kill afghan laborer say shahidullah shahid wardak governor spokesman this attack highprofile attack it pretty significant suicide vehicle bomb gen john r allen commander coalition us force afghanistan told cnns suzanne malveaux sunday the taliban claimed responsibility assault natos international security assistance force confirm attack carry taliban suicide bomber allen say attack indicates much taliban unable able they eject population many place around country ability influence battlefield many occasion simply go highprofile attack and thats view particular attack say shahid say three people die nato say two nato also say 77 personnel injured provincial government say 10 people injured it uncommon local government nato vary account attack the attacker drive truck carry firewood detonate explosive entry point base isaf say statement most force explosion absorbed protective barrier outpost entrance though significant number injury none immediately life threaten statement say in video issue isaf saturday allen spoke 911 anniversary long war say still much work do fight taliban militant prevail he also praise troop 49 nation serve isaf coalition the protract war begin month al qaeda terror network shelter time ruling taliban militant attack united states september 11 2001 usled force kick operation enduring freedom october oust taliban coalition afghan troop fight tenacious taliban militant afghanpakistani region allen note september 11 mark 10th anniversary event change world ever since day say troop cripple insurgent honor victim terrorism worldwide he say coalition commit make sure afghanistan never safe al qaeda you help afghan people build nation democratic government everstrengthening security force say say afghanistan make advance security economic development governance the coalition death toll war near 2700 accord cnn count united states sustain casualty operation enduring freedom august deadliest month us force afghanistan since conflict begin seventyone american troop die august top july 2010 65 troop die accord cnn tally the surge us death come nato draw hand security control national force some 10000 us troop schedule depart year end us military personnel afghanistan end 2014 cnns joe sterling adam levine matiullah mati claudia dominguez tom evans contribute report \n",
            "Original summary: new all of the injured troops are americans an isaf official says at least two afghan civilians are killed in the attack gen john r allen the attack says more about what the taliban cannot do their only ability to influence the battlefield is often to go for a highprofile attack he says \n",
            "Generated summary:  is the first the first cristiano ronaldo of the united cup the first the century states in the first garden in the united and jean also in the rankings and the rankings and the rankings of the own match\n",
            "\n",
            "\n",
            "Article: i dont think euro exist say saxo bank coceo lars seier christensen cnns richard quest term could hardly less fractious supporter 17nation single currency bloc its quite clear lack fiscal union also clear population europe supportive goal the eurozone also pull apart competitiveness continue develop different direction say head online danish investment bank he add people eurozone particular germany monetary zone prime pillar make sacrifice weaker part eurozone greece southern european country christensens controversial comment stand stark contrast eurozone supporter say advocate austerity keep union together germany europes large economy fear greek exit eurozone could lead domino effect massivelyindebted country ireland portugal spain italy may pull common currency lead breakup eurozone in december 2012 german chancellor angela merkel support bailout fund greece in july mario draghi president european central bank promise whatever take preserve euro set rally greek spanish italian bond still saxo banks christensen believe euro disappear point future despite hit 13month high believe overall support exist im say bad thing support say christensen ability adjust currency important equilibrium different economy different development when thats go youre left completely different set problem the bank ceo decline give timeline say depends long germans hold long german population willing buy support fiscal union i tell problem go get great rather small i fear market take thing apart eventually \n",
            "Original summary: saxo coceo euro should never have existed germany fears greek exit from eurozone would spark monetary union breakup euro has risen 10 against u s dollar since july 2012 saxos christensen euro demise depends on germany \n",
            "Generated summary:  is the first the first cristiano ronaldo of the world cup the first version to the first event in the first garden in the united and jean the innuendo and jean the muppets match and the rankings and the rankings of the own match\n",
            "\n",
            "\n",
            "Article: at time like one state one city people governor patrick say the fund already raise 23 million go towards victim family affected bombing donate onefundbostonorg fbi victim assistance center the fbi assistance center activate anyone injured witness boston bombing the red cross the red cross ground mobilize mental health volunteer support affected well opening family assistance center they offering 247 free mental health support want access contact samhsa disaster distress helpline 18009855990 text talkwithus 66746 the red cross recommends people download first aid app provide information help emergency situation the red cross also valuable information deal emotional crisis donate volunteer american red cross give blood there may blood sustain basis anyone wish give blood keep check local hospital organization like red cross near future see need may donate the salvation army the salvation army establish specific fund victim boston donate boston childrens hospital ten victim take bostons childrens hospital the hospital update website news becomes available follow bostonchildrens twitter update the childrens hospital website also useful resource guidance talk child tragedy donate bostons childrens hospital adidas boston tribute tee adidas design t shirt commend boston first responder boston athletic association volunteer reaction event surround bombing 100 proceeds sale t shirt go onefundbostonorg buy adidas boston tribute tee b strong hat major league baseball major league baseball players association boston red sox join donate combine 600000 victim marathon bombing family the red sox mlb also donate 100 proceeds sale b strong hat red sox letter b the one fund create mayor menino buy b strong hat boston marathon relief fund semper fi fund create boston marathon relief fund donations raise go help injured bombing hospital staffto donate please go americas fund website select boston marathon relief fund dropdown menu donate boston marathon relief fund richard family fund the richard family fund establish help family 8 year old martin richard die bombing martins mother sister also badly injured funds help family medical expense recovery donate richard family fund sean collier memorial fund mit create memorial fund honor slain campus police office sean collier donate sean collier memorial fund celeste sydney corcoran recovery fund celeste sydney corcoran badly injured blast sydney sustain severe shrapnel injury celeste leg amputate knee anyone wish help family financial burden tragedy donate fund name donate celeste sydney recovery fund white family fund 3 member white family sustain serious injury explosion one family member lose limb a fund set website youcaringcom help family recovery rehabilitation donate white family fund jeff bauman fund waiting cheer girlfriend across finish line jeff bauman caught explosion suffer loss leg severe burn vision damage a fund set help jeff youcaringcom donate jeff bauman fund patrick downes jessica kensky fund newlywed couple patrick downes jessica kensky lose leg boston blast a fund set help recovery rehabilitation prosthetics giveforwardcom donate patrick downes jessica kensky fund adrianne hasletdavis fund dancer adrianne hasletdavis husband adam caught bombing adrianne lose left foot a fund establish help adriannes recovery donate adrianne hasletdavis fund nicole michael gross erika brannock fund the be strong stay strong fund set help nicole michael gross along nicoles sister erika severely injured bomb stood near finish line boston marathon donate be strong stay strong fund lu lingzi scholarship fund trustees boston university create scholarship fund name lu lingzi chinese graduate student tragically die attack you donate fund also post message support family dedicate website donate lu lingzi fund utilize social medium people often turn twitter quick way connect if boston area look organization seek volunteer far away want keep way help follow hashtag bostonhelp twitter you also keep us cnnimpact impact your world facebook well website \n",
            "Original summary: the city of boston has established one fund boston to raise money for victims the red cross has several programs and information about dealing with an emotional crisis the salvation army is providing food and pastoral care numerous crowdfunding campaigns for individual victims \n",
            "Generated summary: \n",
            "\n",
            "\n",
            "Article: london england irish football official lodge official complaint world ruling body fifa thierry henry confess handle ball buildup goal sent france next summer world cup television camera show henry guide ball hand twice william gallas score result cross give les bleus narrow win twolegged world cup playoff republic ireland i honest it handball i referee barcelona striker told reporter match paris the irish justice ministry confirm cnn dermot ahern ask football association ireland fai demand replay interest fair play thierry henry admit handle ball claim told ref handle millions people worldwide saw blatant double handball mention double offside put power cozy world fifa spot demand replay ahern say statement sent cnn they probably wont grant minnow world football let put spot its least owe thousand devastate young fan around country otherwise result remains reinforces view cheat win the fai later confirm take matter fifa i really believe integrity game question last night chief executive john delaney told reporter the govern body world football step plate accede call replay delaney say fai also write french football federation they need look situation henry captain wonderful footballer want like diego maradona legacy handball goal get world cup unjust manner if qualify manner i wouldnt happy say it people govern game every time i go fifa congress i hear fair play integrity this define game whole world watch fifa believe fair play integrity opportunity step forward the fai argue precedent result struck follow fifas ruling uzbekistan replay playoff bahrain 2006 world cup germany referee make mistake award penalty the football association ireland hop fifa disciplinary committee behalf football fan worldwide act similar fashion standard fair play integrity protect fai say fifa confirm receive irish request replay give timescale decision however say regulation referee decision change law 5 state decision referee regard fact connect play include whether goal score result match final say the referee may change decision realise incorrect discretion advice assistant referee fourth official provide restart play terminate match irish captain richard dunne spoke henry final whistle say felt cheat goal he admit handle doesnt make feel well go world cup final defender say fifa probably happy yet big decision go big team footballs international govern body face criticism several irish player seed system playoff draw favor powerful nation france blog when fifa see whats star face dunnes teammate robbie keane admit hard speak struggle come term result with way played certainly deserve win game kill us near end handball quote fai web site say ive see replay knew anyway handball you could see reaction player especially shay given two yard away you dont get reaction like it clear handball he henry almost caught ball actually ran net were devastate ireland team manager giovanni trapattoni told reporter referee time ask linesman henry it would first time player would ask would turn we angry italian continued it bitter even i would prefer go penalty fanzone five football famous injustice but former france international david ginola emphatic henry own you dont told cnn henry job you cant blame everything could team country get south africa but shame finish game like ireland played well referees need help pitch allow thing like obviously referee wellpositioned couldnt see english referees union chief alan leighton told cnn swedish official martin hansson clearly miss huge decision i think incident instinct deliberately attempt cheat seem ball hit hand twice therefore issue but wider issue cheat leighton say it well blame referee spot fundamentally start player i think player think game think reputation game reputation say look actually line cross \n",
            "Original summary: of ireland officials lodge official complaint with world ruling body fifa new fai also writes to french counterparts asking for world cup playoff to be replayed cameras showed frances thierry henry guiding ball with his hand twice before william gallas scored exfrance player david ginola said henry was only doing his job for his country and should not be blamed \n",
            "Generated summary:  is the first the first cristiano ronaldo of the world cup the m and the francisco of the francisco and the francisco and economies and jean price in the united and jean the team and alltime casals in the own match\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}