{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV27LCvjfwkR",
        "colab_type": "code",
        "outputId": "a04607a8-4104-4fac-f7a9-bcf188644af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "!python -m nltk.downloader stopwords wordnet punkt averaged_perceptron_tagger\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.layers import Attention\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2feqtBEHiaS4",
        "colab_type": "text"
      },
      "source": [
        "### Env Vars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omclwb_CiEZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=70\n",
        "EPOCHS=50\n",
        "latent_dim=128\n",
        "embedding_dim=128\n",
        "test_train_split=0.20\n",
        "build_number=\"1\"\n",
        "# LEARNING_RATE=0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNPOLXNLiiX5",
        "colab_type": "text"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cchT-sW8kGP4",
        "colab_type": "text"
      },
      "source": [
        "Read In Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LLVyg34iLP5",
        "colab_type": "code",
        "outputId": "5c7f9c18-8095-4ea8-a1ed-96d81e0494a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Op7xyUiHSv",
        "colab_type": "code",
        "outputId": "4ede3aaf-b804-4c17-ec67-da51ca0ab2c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "df = pd.read_csv('./drive/My Drive/originals-l.csv')\n",
        "df.head(1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>file</th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01.story</td>\n",
              "      <td>Its official US President Barack Obama want la...</td>\n",
              "      <td>Syrian official Obama climbed top tree doesnt ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                            summary\n",
              "0           0  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptOkktH2CLqg",
        "colab_type": "code",
        "outputId": "b18d889a-8154-4e55-bb8c-c8777b968dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "df.count"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.count of       Unnamed: 0  ...                                            summary\n",
              "0              0  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "1              1  ...  Usain Bolt wins third gold world championship ...\n",
              "2              2  ...  The employee agencys Kansas City office among ...\n",
              "3              3  ...  NEW A Canadian doctor says part team examining...\n",
              "4              4  ...  Another arrest made gang rape outside Californ...\n",
              "...          ...  ...                                                ...\n",
              "3995        3995  ...  A friend China sees woman attacked Toronto apa...\n",
              "3996        3996  ...  Jeff Pearlman says Mark McGwire owed delivered...\n",
              "3997        3997  ...  John Cossman battling cancer eight years He tu...\n",
              "3998        3998  ...  Riders must 54 inches tall ride without superv...\n",
              "3999        3999  ...  Fire affects 3000 acres North Washoe Valley At...\n",
              "\n",
              "[4000 rows x 4 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogB1RqsqreG2",
        "colab_type": "text"
      },
      "source": [
        "Split for now so we are only aiming for one summary per text (This is now in dataprocessing.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e3a1UjziN5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(df['summary'][0])\n",
        "# df['summary'] = df['summary'].apply(lambda x: re.sub(r'\\..*$',' ',str(x)))\n",
        "# print(df['summary'][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZzZjP4vFzVw",
        "colab_type": "text"
      },
      "source": [
        "Remove .'s that appear in stuff like U.S.A and U.N - Eventually need to move this to dataprocessing.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60CqA1Km6PvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "97d25b7d-2550-4b2b-922c-dbdb103f520b"
      },
      "source": [
        "print(df['summary'][0])\n",
        "df['summary'] = df['summary'].apply(lambda x: re.sub(r'\\.','',str(x)))\n",
        "print(df['summary'][0])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Syrian official Obama climbed top tree doesnt know get Obama sends letter heads House Senate Obama seek congressional approval military action Syria Aim determine whether CW used says U.N. spokesman\n",
            "Syrian official Obama climbed top tree doesnt know get Obama sends letter heads House Senate Obama seek congressional approval military action Syria Aim determine whether CW used says UN spokesman\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmYf4I1bGA8N",
        "colab_type": "text"
      },
      "source": [
        "Check for rows with null values in them, and copy these into a new dataframe (df1). Drop any rows in df1 from df to ensure no NaN valued rows are present/\n",
        "\n",
        "*Note. using simply dropna(how='any') does not seem to drop any of the rows*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ws0uSZv8Xnw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "1fd60887-8a8d-45f4-8058-461451510fdd"
      },
      "source": [
        "print(df.isnull().values.any())\n",
        "print(df.shape)\n",
        "\n",
        "df1 = df[df.isna().any(axis=1)]\n",
        "print(df1.shape)\n",
        "\n",
        "df.drop(df1.index, axis=0,inplace=True)\n",
        "print(df.shape)\n",
        "print(df.isnull().values.any())"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "      Unnamed: 0  ...                                            summary\n",
            "0              0  ...  Syrian official Obama climbed top tree doesnt ...\n",
            "1              1  ...  Usain Bolt wins third gold world championship ...\n",
            "2              2  ...  The employee agencys Kansas City office among ...\n",
            "3              3  ...  NEW A Canadian doctor says part team examining...\n",
            "4              4  ...  Another arrest made gang rape outside Californ...\n",
            "...          ...  ...                                                ...\n",
            "3995        3995  ...  A friend China sees woman attacked Toronto apa...\n",
            "3996        3996  ...  Jeff Pearlman says Mark McGwire owed delivered...\n",
            "3997        3997  ...  John Cossman battling cancer eight years He tu...\n",
            "3998        3998  ...  Riders must 54 inches tall ride without superv...\n",
            "3999        3999  ...  Fire affects 3000 acres North Washoe Valley At...\n",
            "\n",
            "[3997 rows x 4 columns]\n",
            "(4000, 4)\n",
            "92      NaN\n",
            "2713    NaN\n",
            "3448    NaN\n",
            "Name: text, dtype: object\n",
            "(3, 4)\n",
            "(3997, 4)\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSVW1P-Ji_7R",
        "colab_type": "text"
      },
      "source": [
        "Word Count Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M72pGpsDjCrc",
        "colab_type": "code",
        "outputId": "a0a964c6-2199-4af9-bcca-483858455fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in df['text']:\n",
        "      text_word_count.append(len(i.split(' ')))\n",
        "\n",
        "for i in df['summary']:\n",
        "      summary_word_count.append(len(i.split(' ')))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.ylabel('Documents')\n",
        "plt.xlabel('Word Count')\n",
        "plt.savefig('word_count_distro' + str(build_number) + '.png')\n",
        "plt.show()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEWCAYAAACdaNcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3M3MMuTgbmaWIQd3M7MM/X+V+F1uc1HocAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNZ2tVpljHTc",
        "colab_type": "text"
      },
      "source": [
        "Max Text Lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T01Jf-XjGKO",
        "colab_type": "code",
        "outputId": "9391bff2-c725-4c04-be4b-1787052d38a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "max_text_len = max([len(txt) for txt in df['text']])\n",
        "max_summary_len = max([len(txt) for txt in df['summary']])\n",
        "print(max_text_len)\n",
        "print(max_summary_len)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7823\n",
            "333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGl1z0OFjTsr",
        "colab_type": "text"
      },
      "source": [
        "### Training-Validation Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwmBST04juu6",
        "colab_type": "text"
      },
      "source": [
        "X - Articles text </br>\n",
        "Y - Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1_YrHcDjN6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to numpy array\n",
        "X = np.array(df['text'])\n",
        "Y = np.array(df['summary'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGHJXwaojYAV",
        "colab_type": "code",
        "outputId": "b7e01904-a40c-48aa-c9dd-e8edbdc72303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "x_tr,x_val,y_tr,y_val=train_test_split(X,Y,test_size=test_train_split,random_state=0,shuffle=True)\n",
        "print(x_tr.shape)\n",
        "print(x_val.shape)\n",
        "print(y_tr.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3197,)\n",
            "(800,)\n",
            "(3197,)\n",
            "(800,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzWpoc9OjjdV",
        "colab_type": "text"
      },
      "source": [
        "### Word Embeddings - Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLVdVklnjq1i",
        "colab_type": "text"
      },
      "source": [
        "X Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7qUrNpbjpI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_dict = {}\n",
        "text = df['text']\n",
        "\n",
        "for row in text: \n",
        "  for word in row.split(\" \"):\n",
        "    if word not in word_dict:\n",
        "      word_dict[word] = 1\n",
        "    else:\n",
        "      word_dict[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qbg_6TKj4HK",
        "colab_type": "code",
        "outputId": "87fc2439-5039-480b-a9d3-0a23b4020b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# #prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=len(word_dict)) \n",
        "x_tokenizer.fit_on_texts(list(X))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "print(x_voc)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdwGLWiRloV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('xtokenizer.pickle', 'wb') as handle:\n",
        "  pickle.dump(x_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NsdijM3j6RJ",
        "colab_type": "text"
      },
      "source": [
        "Y Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG6Q2G-Wj79A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_dict = {}\n",
        "text = df['summary']\n",
        "\n",
        "for row in text: \n",
        "  for word in row.split(\" \"):\n",
        "    if word not in word_dict:\n",
        "      word_dict[word] = 1\n",
        "    else:\n",
        "      word_dict[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5ugAAnIj91g",
        "colab_type": "code",
        "outputId": "7dba3458-13b0-4c88-f300-e120ac7a024d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=len(word_dict)) \n",
        "y_tokenizer.fit_on_texts(list(Y))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1\n",
        "print(y_voc)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzpeT5fXlp3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('ytokenizer.pickle', 'wb') as handle:\n",
        "  pickle.dump(y_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zntqptcwj_lh",
        "colab_type": "text"
      },
      "source": [
        "## Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc0JOUvqkWUL",
        "colab_type": "text"
      },
      "source": [
        "#### Encoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dx-9BT6kZMw",
        "colab_type": "code",
        "outputId": "d63bb2a5-6f96-475a-ed30-62bc910b40f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "#encoder lstm \n",
        "encoder_lstm = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JJUPBdfkdlb",
        "colab_type": "text"
      },
      "source": [
        "#### Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLgYfdF3kb1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "                                                          \n",
        "#dense layer\n",
        "decoder_dense = Dense(y_voc, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIpBF_fAkfuG",
        "colab_type": "text"
      },
      "source": [
        "#### Combined LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASIlTOT_khrn",
        "colab_type": "code",
        "outputId": "2040df81-aa4a-46d0-d333-3ca27ae0e22a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 7823)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 7823, 128)    9241472     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 128)    2969856     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 7823, 128),  131584      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 128),  131584      embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 23202)  2993058     lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 15,467,554\n",
            "Trainable params: 15,467,554\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMQ1ZrF0ksMT",
        "colab_type": "code",
        "outputId": "b9e0f087-6ffe-4e9c-bf9a-9cd44cb5183a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o12XRjJykuA-",
        "colab_type": "text"
      },
      "source": [
        "Early Stopping Callback to ensure we stop when Validation Loss is lowest - minimises risk of overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R-qwZoNkspo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=4, restore_best_weights=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbnxf9ZWk4I0",
        "colab_type": "code",
        "outputId": "75fa86fc-41d5-40f5-b8be-adc5e841ea69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        }
      },
      "source": [
        "history = model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:], batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[es], validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 3197 samples, validate on 800 samples\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-6b0efda4aff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[70,332,23202] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node dense_1/sub}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss/mul/_97]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[70,332,23202] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node dense_1/sub}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEkRn71fk7up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model' + str(build_number) + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N52zaYcKlAXE",
        "colab_type": "code",
        "outputId": "ecb37c11-d7b1-4dd6-b2f6-818668982686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.savefig('loss' + str(build_number) + '.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngMKcBgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxSFAxiWlDad",
        "colab_type": "text"
      },
      "source": [
        "## Inference Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm1b46qtlFnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1Q7SWH_lGxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_inputs)\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c], [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biBjzpLQlPhf",
        "colab_type": "code",
        "outputId": "2860850a-d076-4102-9f76-e0f1b63899bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "encoder_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 7301)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 7301, 128)         3803136   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                [(None, 7301, 128), (None 131584    \n",
            "=================================================================\n",
            "Total params: 3,934,720\n",
            "Trainable params: 3,934,720\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmvKd7pNlQXs",
        "colab_type": "code",
        "outputId": "ae6d08b1-ccca-421d-9597-40e81cb9ea2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "decoder_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 128)    489728      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 128),  131584      embedding_2[1][0]                \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 3826)   493554      lstm_2[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,114,866\n",
            "Trainable params: 1,114,866\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywir6L6wlUE-",
        "colab_type": "text"
      },
      "source": [
        "### Methhods for Reversing Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoKuk0dElZZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSR-0MHclb0G",
        "colab_type": "text"
      },
      "source": [
        "### Summarisation Method "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WYZgAXelbLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq): \n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, max_summary_len))\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "      output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c]) \n",
        "      # print(output_tokens)\n",
        "      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "      # print(sampled_token_index)\n",
        "      # print(sampled_token_index)\n",
        "      if (sampled_token_index != 0 ):\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_token\n",
        "      else :\n",
        "        stop_condition = True\n",
        "      if (len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "              stop_condition = True\n",
        "       # Update the target sequence (of length 1).\n",
        "      # target_seq = np.zeros((1,1))\n",
        "      target_seq = np.zeros((1, max_summary_len))\n",
        "      target_seq[0, sampled_token_index] = 1\n",
        "\n",
        "      # Update internal states\n",
        "      e_h, e_c = h, c\n",
        "      \n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STnQkiZzlhbb",
        "colab_type": "text"
      },
      "source": [
        "## Test Model Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AisRsa573_L3",
        "colab_type": "text"
      },
      "source": [
        "Note: *I think there isn't enough data being passed in and so the argmax value always is 0 - it can't learn what should be next*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC1oCOOHlgjh",
        "colab_type": "code",
        "outputId": "c93bf6f0-f462-4ff3-b0c2-9ac79671518a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "for i in range(0,1):\n",
        "    print(\"Article:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    x_i = x_tr[i].reshape(1,max_text_len)\n",
        "    print(\"Generated summary:\",decode_sequence(x_i))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article: a prosecute attorney greet jury george zimmerman trial monday quote full expletive adversary decide appropriate tell juror knockknock joke and begin opening statement zimmermans longanticipated murder trial in case ignite national debate gun law race relation zimmerman neighborhood watch captain accuse seconddegree murder fatal shoot 17yearold trayvon martin february 2012 sanford florida prosecutor john guys first word sixwoman jury may raise eyebrow good morning fg punk get away guy quote zimmerman these word grown man mouth follow boy didnt know those word mine zimmerman guy say get car pistol two flashlight follow trayvon benjamin martin walk home 7eleven arm fruit drink bag candy eventually two become entangle ground fight a witness say martin top zimmerman guy say the defendant claim trayvon martin top say go die tonight say guy nobody heard guy told juror witness saw happen night shoot begin end witnesses saw slice happen say we confident end trial know head heart stomach george zimmerman shoot trayvon martin guy say he shot bad reason want fast fact trayvon martin shoot in first day testimony juror heard witness recount martins trip convenience store zimmermans call complain suspicious person walk neighborhood martins kill call previous august zimmerman report allege burglary police proceedings end day defense attorney mark omara object earlier call prosecutor argue necessary explain zimmermans remark burglar get away the martin family sat watch proceeding behind state attorney angela corey before witness testimony begin judge debra nelson deny defense request martins father tracy martin leave courtroom tracy martin potential witness potential witness force sit outside courtroom keep testimony taint witness but nextofkin victim allow remain court even theyre expect testify omara also accuse tracy martin use obscenity toward friend zimmermans hold door hearing two week ago the friend timothy tucholski testify hadnt want make issue i wasnt planning come i dont want sit say but nelson deny request martin remain court zimmermans parent cover rule regard potential witness sit outside benjamin crump lawyer martins parent at one point martins father begin cry guy detailed officer try save son life zimmerman mostly star straight ahead without sign emotion following guys statement defense attorney don west come forward woo jury as begin told knockknock joke but fail win laugh knock knock whos george zimmerman george zimmerman good youre jury say later west apologize no bad joke i promise told juror i convince delivery west quickly get business make case zimmerman force act selfdefense save life the evidence show sad case monster george zimmerman guilty murder he shot trayvon martin viciously attack with help powerpoint visuals west spent hour hammer home argument he broke zimmermans 911 call first report see martin told follow little george zimmerman know time less 10 minute first see travyon martin george zimmerman would suckered punch face head pound concrete wind shoot tragically kill trayvon martin west told juror west also deconstruct 911 call neighbor make possible hear scream shot background west say sound fatal bullet as dramatic record audio fill courtroom zimmerman show emotion martins mother left courtroom at moment actually become physical trayvon martin i use word trayvon martin decide confront george zimmerman west say that instead go home he plenty time this 60 70 yard plenty time he couldve go back forth four five time west quote witness name john good described fight he call ground pound martin say top zimmerman beating he saw enough serious west say zimmerman cry help look good say help but beating continued good go inside home call 911 west say there shot shortly afterward accord west zimmerman say martin beating i shot west also dispute prosecution claim martin unarmed travyon martin arm concrete sidewalk use smash george zimmermans head say west no different picked brick smash head wall that deadly weapon west show juror photo take zimmerman fight what really see picture evidence lump west say the big knot side head consistent head slam concrete allfemale jury try zimmerman among first prosecution witness call 911 dispatcher take zimmermans call shoot seat noffke testify train give general command instead direct order people when zimmerman say follow martin noffke told okay dont need noffke told prosecutor he liable direct order give someone on crossexamination defense attorney omara point noffke ask zimmerman which way run if tell somebody twice let know person theyre concerned anything else think theyre go keep eye ask omara i cant answer say noffke you tell twice let know guy anything else say omara yes sir say noffke noffke go say want location suspect officer never told zimmerman follow keep eye martin shortly court get way martins mother sybrina fulton spoke reporter ask people pray family i dont want mother experience im go judge no state expert testimony 911 call martin black zimmerman identifies hispanic in cnn poll release monday morning 62 respondent say charge zimmerman probably definitely true \n",
            "Original summary: defense lawyer apologizes telling joke opening statements \n",
            "Generated summary: \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNy_KJPb4PXc",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMRIXeuz8hYn",
        "colab_type": "text"
      },
      "source": [
        "Using ROUGE (Recall-Orientated Understanding Gisting Evaluation) to evaluate the generated summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqM1FoWQFsqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_overlapping_words(x, y):\n",
        "  num=0\n",
        "  x = nltk.word_tokenize(x)\n",
        "  y = nltk.word_tokenize(y)\n",
        "  for word in y:\n",
        "    if word in x:\n",
        "      num = num+1\n",
        "      x.remove(word)\n",
        "    else:\n",
        "      return num\n",
        "\n",
        "def precision(target, generated):\n",
        "  length = len(target)\n",
        "  for i in range (0, length):\n",
        "    num_overlapping_words = get_overlapping_words(target[i], generated[i])\n",
        "    generated_summary_len = len(generated[i])\n",
        "    if generated_summary_len == 0 :\n",
        "        return 0.0\n",
        "    else : \n",
        "      return num_overlapping_words / generated_summary_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwTD6W5kFmvk",
        "colab_type": "text"
      },
      "source": [
        "### For Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUr2YcMoDGEt",
        "colab_type": "code",
        "outputId": "975bec9a-bdd2-4ead-aa41-9a8eb4bb44bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(len(x_tr))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BKXHKbaDS8G",
        "colab_type": "code",
        "outputId": "e57e5de1-e341-4d9e-d5ff-eeee0baa7d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "tr_target_summary = []\n",
        "tr_generated_summary = []\n",
        "# x_tr_len = len(x_tr)\n",
        "x_tr_len = 10\n",
        "for i in range(0,x_tr_len):\n",
        "  print(i)\n",
        "  tr_target_summary.append(seq2summary(y_tr[i]))\n",
        "  x_i = x_tr[i].reshape(1,max_text_len)\n",
        "  tr_generated_summary.append(decode_sequence(x_i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuzxQo3E4SlK",
        "colab_type": "code",
        "outputId": "2f3d240c-5169-4bef-8800-3c85b2530cfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(\"precision : \" + str(precision(tr_target_summary, tr_generated_summary)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiHBkkwmFTPt",
        "colab_type": "text"
      },
      "source": [
        "### For Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2QGuitHFZD1",
        "colab_type": "code",
        "outputId": "5d8559aa-68b2-4492-c879-57b5a2e2e1ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "val_target_summary = []\n",
        "val_generated_summary = []\n",
        "# x_val_len = len(x_val)\n",
        "x_val_len = 1\n",
        "for i in range(0,x_val_len):\n",
        "  print(i)\n",
        "  val_target_summary.append((y_val[i]))\n",
        "  x_i = x_val[i].reshape(1,max_text_len)\n",
        "  val_generated_summary.append(decode_sequence(x_i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9n0nDG-F6KN",
        "colab_type": "code",
        "outputId": "b31a3a45-9b75-410a-83c5-f75a3cea0dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "pre = precision(val_target_summary, val_generated_summary)\n",
        "print(pre)\n",
        "print(\"precision : \" + str(pre))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-22d0f559d8f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_target_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_generated_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-87698e18893e>\u001b[0m in \u001b[0;36mprecision\u001b[0;34m(target, generated)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mnum_overlapping_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_overlapping_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mgenerated_summary_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgenerated_summary_len\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-87698e18893e>\u001b[0m in \u001b[0;36mget_overlapping_words\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_overlapping_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[1;32m     94\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# Standard word tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \"\"\"\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \"\"\"\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \"\"\"\n\u001b[1;32m   1315\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0msl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \"\"\"\n\u001b[1;32m    311\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_tok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faHKW5pUF9KH",
        "colab_type": "text"
      },
      "source": [
        "# Inputting New Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srBPE2ZxZH72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getpos(word):\n",
        "  pos = nltk.pos_tag([word])[0][1][0]\n",
        "  wordnet_conv = {\"J\": wn.ADJ, \"N\": wn.NOUN, \"V\": wn.VERB, \"R\": wn.ADV}\n",
        "  if pos in wordnet_conv.keys():\n",
        "    return wordnet_conv.get(pos)\n",
        "  return \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5aEv4W8ZM81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lemmatization(text):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  text_tokenized = inp_df['text'].apply(lambda x: nltk.word_tokenize(x))\n",
        "  print(\"lemmatize with pos\")\n",
        "  for i in range(0,len(text_tokenized)):\n",
        "    text_lemmatized = []\n",
        "    for word in text_tokenized[i]:\n",
        "      pos = getpos(word)\n",
        "      if pos != \"\":\n",
        "        lemma = lemmatizer.lemmatize(word, pos)\n",
        "        text_lemmatized.append(lemma)\n",
        "      else :\n",
        "        text_lemmatized.append(word)\n",
        "    text_lemmatized = ' '.join(map(str, text_lemmatized))\n",
        "    inp_df['text'][i] = text_lemmatized\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tlZ-4XXuctn",
        "colab_type": "code",
        "outputId": "06fd2777-a9d5-4479-c8a6-3fbf3bc7d9f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "input1 = \"(CNN) — Earlier this year, Delta Air Lines announced a rethink on reclining seats. In an effort to disrupt fewer passengers' travel experiences, Delta said it'd begin revamping some of its jets to reduce the recline of coach seats from four inches to two inches and the recline of first class seats from 5.5 inches to 3.5 inches. For those who abhor the recline option, it's a small step. And for those who value it, well, it's a compromise. This seemingly innocuous topic is one where there are very much two minds on what's acceptable and what's not. Two CNN Travel staffers engage in a friendly debate about seat recline. Your seat. Your decision. Stacey Lastoe, senior editor at CNN Travel, is of above-average height and makes no apology about reclining; it's her right as a plane, train and bus passenger. She encourages the person sitting in front of her to recline as well. On the first leg of my flight to Japan for my honeymoon, my husband and I got upgraded to first class. Although it would just be a few hours in the sky en route to Dallas, I was excited about sipping Champagne, sitting back and relaxing. Flute in hand, I pushed back to recline my seat for maximum relaxation. But it would not budge; I appeared to be stuck in a dysfunctional seat. Or was I? Turns out the gentleman behind me had a dog in a crate down between his legs, positioned so the seat in front of his -- my seat -- had nowhere to go. Because we were newlyweds and loving every moment of it, I did not mind when my husband turned to the man and told him his wife wanted to recline her seat and asked if he could please rearrange his dog crate to allow for everyones comfort.\"\n",
        "inp_df = pd.DataFrame(columns=['text', 'summary'])\n",
        "inp_df = inp_df.append({'text': str(input1), 'summary': \"\"}, ignore_index=True)\n",
        "inp_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(CNN) — Earlier this year, Delta Air Lines ann...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text summary\n",
              "0  (CNN) — Earlier this year, Delta Air Lines ann...        "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyDVNd3pvxIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp_df['text'] = inp_df['text'].apply(lambda x: re.sub(r'\\(CNN\\)|--|[^\\w\\s\\.]','',x)).apply(lambda x: re.sub(r'(\\.(?=[\\s\\r\\n]|$))','',x)).apply(lambda x: re.sub(r'\\n',' ',x)).apply(lambda x: re.sub(r'\\.','',x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WyRVL-DGACF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "inp_df['text'] = inp_df['text'].apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: \" \".join([word for word in x if not word in stop_words]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd2C6wFAxU3K",
        "colab_type": "code",
        "outputId": "b376cba2-7e6d-4bec-bb18-4728cfe5e1d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "#lemmatize\n",
        "lemmatization(inp_df['text'])\n",
        "print(inp_df['text'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lemmatize with pos\n",
            "0    Earlier year Delta Air Lines announce rethink ...\n",
            "Name: text, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwj2UIuQ20Hl",
        "colab_type": "code",
        "outputId": "635efab9-66ef-4d2b-ec07-a69b07d0ed39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "seq = np.array(inp_df['text'])\n",
        "print(seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Earlier year Delta Air Lines announce rethink recline seat In effort disrupt few passenger travel experience Delta say itd begin revamp jet reduce recline coach seat four inch two inch recline first class seat 55 inch 35 inch For abhor recline option small step And value well compromise This seemingly innocuous topic one much two mind whats acceptable whats Two CNN Travel staffer engage friendly debate seat recline Your seat Your decision Stacey Lastoe senior editor CNN Travel aboveaverage height make apology recline right plane train bus passenger She encourages person sit front recline well On first leg flight Japan honeymoon husband I get upgraded first class Although would hour sky en route Dallas I excite sip Champagne sit back relax Flute hand I push back recline seat maximum relaxation But would budge I appear stuck dysfunctional seat Or I Turns gentleman behind dog crate leg position seat front seat nowhere go Because newlywed love every moment I mind husband turn man told wife want recline seat ask could please rearrange dog crate allow everyones comfort']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx7fUFkZ0aAr",
        "colab_type": "code",
        "outputId": "209a9b33-800e-43c9-bfcb-8e7de055e165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "seq_tokenizer = x_tokenizer.texts_to_sequences(seq)\n",
        "#padding zero upto maximum length\n",
        "seq_tokenizer_padded = pad_sequences(seq_tokenizer,  maxlen=max_text_len, padding='post')\n",
        "\n",
        "summary = decode_sequence(seq_tokenizer_padded)\n",
        "\n",
        "# print(seq2text(seq))\n",
        "print(\"---\")\n",
        "print(\"Summary: \" + summary)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---\n",
            "Summary: \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}