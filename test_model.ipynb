{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "test-model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bV27LCvjfwkR",
        "outputId": "f4be295e-dc72-41a0-e395-0c8f57e467d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "!python -m nltk.downloader stopwords wordnet punkt averaged_perceptron_tagger\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.layers import Attention\n",
        "from keras.models import Model, load_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import RMSprop\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install rouge\n",
        "from rouge import Rouge\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.6/dist-packages (0.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2feqtBEHiaS4"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "omclwb_CiEZr",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=1\n",
        "EPOCHS=200\n",
        "latent_dim=256\n",
        "embedding_dim=100\n",
        "test_train_split=0.15\n",
        "build_number=\"1\"\n",
        "LEARNING_RATE=0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L1hVy0J07Gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create rouge object for evaluation\n",
        "rouge = Rouge()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gNPOLXNLiiX5"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cchT-sW8kGP4"
      },
      "source": [
        "Read In Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1LLVyg34iLP5",
        "outputId": "00da0997-9019-4d6b-80e3-8f67e360e2ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Only needed if running on Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vtGVB1bR9KHT",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('./drive/My Drive/repeat.csv')\n",
        "# df = pd.read_csv('./Reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b8a47fbc-8c51-4aaa-ea4b-85e04694383d",
        "id": "9GeVXWUS9JRL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "df.count"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.count of       Unnamed: 0  ...                                            summary\n",
              "0              0  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "1              1  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "2              2  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "3              3  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "4              4  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "...          ...  ...                                                ...\n",
              "3096        3096  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "3097        3097  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "3098        3098  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "3099        3099  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "3100        3100  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "\n",
              "[3101 rows x 4 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "71309965-2acf-4914-fb79-8f3ca29b0c5a",
        "id": "PYplzyHC9I_c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>file</th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01.story</td>\n",
              "      <td>Its official US President Barack Obama want la...</td>\n",
              "      <td>Syrian official Obama climbed top tree doesnt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef.story</td>\n",
              "      <td>Its official US President Barack Obama want la...</td>\n",
              "      <td>Syrian official Obama climbed top tree doesnt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>00027e965c8264c35cc1bc55556db388da82b07f.story</td>\n",
              "      <td>Its official US President Barack Obama want la...</td>\n",
              "      <td>Syrian official Obama climbed top tree doesnt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0002c17436637c4fe1837c935c04de47adb18e9a.story</td>\n",
              "      <td>Its official US President Barack Obama want la...</td>\n",
              "      <td>Syrian official Obama climbed top tree doesnt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0003ad6ef0c37534f80b55b4235108024b407f0b.story</td>\n",
              "      <td>Its official US President Barack Obama want la...</td>\n",
              "      <td>Syrian official Obama climbed top tree doesnt ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                            summary\n",
              "0           0  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "1           1  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "2           2  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "3           3  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "4           4  ...  Syrian official Obama climbed top tree doesnt ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QZzZjP4vFzVw"
      },
      "source": [
        "Remove .'s that appear in stuff like U.S.A and U.N - Eventually need to move this to dataprocessing.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4e3a1UjziN5g",
        "colab": {}
      },
      "source": [
        "# print(df['summary'][0])\n",
        "# df['summary'] = df['summary'].apply(lambda x: re.sub(r'\\..*$',' ',str(x)))\n",
        "# print(df['summary'][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "60CqA1Km6PvJ",
        "outputId": "442c4e0e-9f87-41b9-dd0a-ff6d50cf8c70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(df['summary'][0])\n",
        "df['summary'] = df['summary'].apply(lambda x: re.sub(r'\\.','',str(x)))\n",
        "print(df['summary'][0])"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Syrian official Obama climbed top tree doesnt know get Obama sends letter heads House Senate Obama seek congressional approval military action Syria Aim determine whether CW used says U.N. spokesman\n",
            "Syrian official Obama climbed top tree doesnt know get Obama sends letter heads House Senate Obama seek congressional approval military action Syria Aim determine whether CW used says UN spokesman\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jmYf4I1bGA8N"
      },
      "source": [
        "Check for rows with null values in them, and copy these into a new dataframe (df1). Drop any rows in df1 from df to ensure no NaN valued rows are present/\n",
        "\n",
        "*Note. using simply dropna(how='any') does not seem to drop any of the rows*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Ws0uSZv8Xnw",
        "outputId": "6ffe275a-8ad1-42e9-ea5a-5b70542853b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(df.isnull().values.any())\n",
        "print(df.shape)\n",
        "\n",
        "df1 = df[df.isna().any(axis=1)]\n",
        "print(df1.shape)\n",
        "\n",
        "df.drop(df1.index, axis=0,inplace=True)\n",
        "print(df.shape)\n",
        "print(df.isnull().values.any())"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "(3101, 4)\n",
            "(0, 4)\n",
            "(3101, 4)\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AECubdYP9dsc",
        "colab_type": "text"
      },
      "source": [
        "Cut down text to 20 words, and summaries to 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0W-le6ofi74",
        "colab_type": "code",
        "outputId": "a4f45bb3-0d64-49d7-8f8d-62a195aa93b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(df['text'][0])\n",
        "df['text'] = df['text'].apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: \" \".join(x[:20]))\n",
        "print(df['text'][0])"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Its official US President Barack Obama want lawmaker weigh whether use military force Syria Obama sent letter head House Senate Saturday night hour announce believe military action Syrian target right step take allege use chemical weapon The propose legislation Obama asks Congress approve use military force deter disrupt prevent degrade potential future us chemical weapon weapon mass destruction Its step set turn international crisis fierce domestic political battle There key question loom debate What UN weapon inspector find Syria What happens Congress vote And Syrian government react In televise address White House Rose Garden earlier Saturday president say would take case Congress want While I believe I authority carry military action without specific congressional authorization I know country strong take course action even effective say We debate issue big business usual Obama say top congressional leader agree schedule debate body return Washington September 9 The Senate Foreign Relations Committee hold hearing matter Tuesday Sen Robert Menendez say Transcript Read Obamas full remark Syrian crisis Latest development UN inspector leave Syria Obamas remark come shortly UN inspector left Syria carry evidence determine whether chemical weapon use attack early last week Damascus suburb The aim game mandate clear ascertain whether chemical weapon use UN spokesman Martin Nesirky told reporter Saturday But use weapon report toxic gas attack Damascus suburb August 21 key point global debate Syrian crisis Top US official say there doubt Syrian government behind Syrian official deny responsibility blame jihadist fight rebel British US intelligence report say attack involve chemical weapon UN official stress importance wait official report inspector The inspector share finding UN SecretaryGeneral Ban Kimoon Ban say want wait UN team final report complete present UN Security Council The Organization Prohibition Chemical Weapons nine inspector belong say Saturday could take three week analyze evidence collect It need time able analyze information sample Nesirky say He note Ban repeatedly say alternative political solution crisis Syria military solution option Bergen Syria problem hell US Obama This menace must confront Obamas senior adviser debate next step take president comment Saturday come amid mount political pressure situation Syria Some US lawmaker call immediate action others warn step could become quagmire Some global leader express support British Parliaments vote military action earlier week blow Obamas hope get strong backing key NATO ally On Saturday Obama propose say would limited military action Syrian President Bashar alAssad Any military attack would openended include US ground force say Syrias allege use chemical weapon earlier month assault human dignity president say A failure respond force Obama argue could lead escalate use chemical weapon proliferation terrorist group would people harm In world many danger menace must confront Syria missile strike What would happen next Map US allied asset around Syria Obama decision come Friday night On Friday night president make lastminute decision consult lawmaker What happen vote Its unclear A senior administration official told CNN Obama authority act without Congress even Congress reject request authorization use force Obama Saturday continued shore support strike alAssad government He spoke phone French President Francois Hollande Rose Garden speech The two leader agree international community must deliver resolute message Assad regime others would consider use chemical weapon crime unacceptable violate international norm held accountable world White House say Meanwhile uncertainty loom Congress would weigh US military official say remain ready 5 key assertion US intelligence report Syria Syria Who want chemical weapon horror Reactions mixed Obamas speech A spokesman Syrian National Coalition say opposition group disappointed Obamas announcement Our fear lack action could embolden regime repeat attack serious way say spokesman Louay Safi So quite concerned Some member Congress applaud Obamas decision House Speaker John Boehner Majority Leader Eric Cantor Majority Whip Kevin McCarthy Conference Chair Cathy McMorris Rodgers issue statement Saturday praise president Under Constitution responsibility declare war lie Congress Republican lawmaker say We glad president seek authorization military action Syria response serious substantive question raise More 160 legislator include 63 Obamas fellow Democrats sign letter call either vote least full debate US action British Prime Minister David Cameron whose attempt get lawmaker country support military action Syria fail earlier week respond Obamas speech Twitter post Saturday I understand support Barack Obamas position Syria Cameron say An influential lawmaker Russia stood Syria criticize United States theory The main reason Obama turn Congress military operation get enough support either world among ally US United States Alexei Pushkov chairman internationalaffairs committee Russian State Duma say Twitter post In United States scatter group antiwar protester around country take street Saturday Like many Americanswere tire United States get involve invade bombing country say Robin Rosecrans among hundred Los Angeles demonstration What Syrias neighbor think Why Russia China Iran stand Assad Syrias government unfazed After Obamas speech military political analyst Syrian state TV say Obama embarrass Russia opposes military action Syria cry help someone come rescue face two defeat political military level Syrias prime minister appear unfazed saberrattling The Syrian Armys status maximum readiness finger trigger confront challenge Wael Nader alHalqi say meeting delegation Syrian expatriate Italy accord banner Syria State TV broadcast prior Obamas address An anchor Syrian state television say Obama appear prepare aggression Syria base repeat lie A top Syrian diplomat told state television network Obama face pressure take military action Israel Turkey Arabs rightwing extremist United States I think do well Cameron term take issue Parliament say Bashar Jaafari Syrias ambassador United Nations Both Obama Cameron say climbed top tree dont know get The Syrian government deny use chemical weapon August 21 attack say jihadist fight rebel use effort turn global sentiment British intelligence put number people kill attack 350 On Saturday Obama say told well 1000 people murder US Secretary State John Kerry Friday cite death toll 1429 400 child No explanation offer discrepancy Iran US military action Syria would spark disaster Opinion Why strike Syria bad idea\n",
            "Its official US President Barack Obama want lawmaker weigh whether use military force Syria Obama sent letter head House Senate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNwMSyzZgexI",
        "colab_type": "code",
        "outputId": "9b1c0cb3-93fa-4b9d-d5ad-69fc4de247d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(df['summary'][0])\n",
        "df['summary'] = df['summary'].apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: \" \".join(x[:10]))\n",
        "print(df['summary'][0])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Syrian official Obama climbed top tree doesnt know get Obama sends letter heads House Senate Obama seek congressional approval military action Syria Aim determine whether CW used says UN spokesman\n",
            "Syrian official Obama climbed top tree doesnt know get Obama\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nSVW1P-Ji_7R"
      },
      "source": [
        "Word Count Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M72pGpsDjCrc",
        "outputId": "952c1f10-a3ee-43d3-ba8d-0d5c095499a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in df['text']:\n",
        "      text_word_count.append(len(i.split(' ')))\n",
        "\n",
        "for i in df['summary']:\n",
        "      summary_word_count.append(len(i.split(' ')))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.ylabel('Documents')\n",
        "plt.xlabel('Word Count')\n",
        "# plt.savefig('word_count_distro' + str(build_number) + '.png')\n",
        "plt.show()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEWCAYAAACAOivfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAeO0lEQVR4nO3de5hcVZnv8e+PSwCDQDDaQogkaHQG\n4QChB1FxbGUMgTMMzEUFGQmXc6LnwBw5ZHSCcwmKjKBcjjCIE4Y8BCaCjIqJGoRwaUEUCMGEkCDQ\nQjxJJiRCQkJHQRLf+WOvpitNVbrSXV1VXev3eZ791N5rr71r7d1v9Vv7UmsrIjAzszzt1OgGmJlZ\n4zgJmJllzEnAzCxjTgJmZhlzEjAzy5iTgJlZxpwEzMwy5iRgZk1B0gpJf1KD9dwg6Uu1aFMOnARs\nG5J2aXQbzKx+nASGgKS/k7Ra0kuSnpR0bN9vJ5I6JK0qmV4h6bOSHpO0WdL1ktok3Z7Wc5ekUanu\nOEkh6UxJKyVtkPRpSX+Uln9R0r+UrPvtku6R9IKk5yXNkbRPn/f+O0mPAZtTO77TZ5uukvS1Id1x\nli1JNwFvA74vqVvS5yQdLemnKZ6XSOpIdfeVtErSiWl6T0ldkk6XNBU4DfhcWs/3G7ZRw0VEeKjh\nALwLWAnsn6bHAW8HbgC+VFKvA1hVMr0CeBBoA8YA64BHgSOA3YF7gBkl6wzgG2neJOBl4HvAW0qW\n/2Cq/w7gI8BuwJuB+4D/1+e9FwNjgT2A/YDNwD5p/i5pfUc2ev96aN0hxeGfpPExwAvACRRfVj+S\npt+c5k8Cnkvxfh3w7ZL1bPNZ87D9wUcCtbeV4p/twZJ2jYgVEfHLKpe9OiLWRsRq4H7goYj4eUS8\nDNxGkRBKXRQRL0fEnRT/tG+OiHUlyx8BEBFdEbEgIl6JiF8DVwAf7LOuqyJiZUT8NiLWUCSKj6Z5\nk4HnI2LRDu0Js4H7a2B+RMyPiN9HxALgEYqkQIr5/wDuTmWfalhLhzkngRqLiC7gPOBCYJ2kWyTt\nX+Xia0vGf1tmes+B1E+nlW5Jp6g2Af8OjO6zrpV9pmdTfBBJrzdVuQ1mtXAg8NF0KuhFSS8Cx1Ac\npfaYCRwC3BARLzSika3ASWAIRMQ3I+IYikAO4FKKb+pvKKn21jo26Z9TOw6NiL0o/qmrT52+3cl+\nD/hvkg4B/hSYM+SttNyVxuBK4KaI2KdkGBkRlwBI2pkiCdwI/G9J76iwHuuHk0CNSXqXpA9L2o3i\nPP1vgd9TnHM/IV3UeivF0UK9vBHoBjZKGgN8tr8F0imobwPfBB6OiP8/tE00Yy1wUBr/d+BEScdJ\n2lnS7ulmigPS/M9T/LM/C/gqcGNKDH3XY/1wEqi93YBLgOfpvXB1AcXplCUUF7/uBL5VxzZ9AZgI\nbAR+CHy3yuVmA4fiU0FWH18G/iGd+vk4cBLFP/tfUxwZfBbYSdKRwPnA6RGxleJIO4DpaT3XU1yT\ne1HS9+q8DcOO0tV0s9eR9DbgF8BbI2JTo9tjZrXnIwErS9JOFN+2bnECMGtd/nWovY6kkRTnVX9F\ncXuombUonw4yM8uYTweZmWWsqU8HjR49OsaNG1d23ubNmxk5cmR9G9SEvB8K29sPixYtej4i3lzn\nJg1Ypbj337rg/dCr0r7YkZhv6iQwbtw4HnnkkbLzOjs76ejoqG+DmpD3Q2F7+0HSr+rbmsGpFPf+\nWxe8H3pV2hc7EvM+HWRmljEnATOzjDkJmJllzEnAzCxjTgJmZhlzEjAzy5iTgJlZxpwEzMwy5iRg\nZpaxpv7FsPVv6eqNnDH9h9uUrbjkvzeoNWZDzzFfWz4SMDPLmJOAmVnG+k0C6QHPD0taImmZpC+k\n8vGSHpLUJelbkkak8t3SdFeaP65kXRek8iclHTdUG2U2GI55y0k1RwKvAB+OiMOAw4HJko6meLjz\nlRHxDmADcHaqfzawIZVfmeoh6WDgFODdFE+r+rqknWu5MWY14pi3bPSbBKLQnSZ3TUMAHwa+ncpn\nAyen8ZPSNGn+sZKUym+JiFci4lmgCziqJlthVkOOectJVXcHpW8vi4B3ANcAvwRejIgtqcoqYEwa\nHwOsBIiILZI2Am9K5Q+WrLZ0mdL3mgpMBWhra6Ozs7Nsm7q7uyvOy0nbHjDt0C3blOW4X2odD/WM\n+fR+/ca9Y77gmO9Vi5ioKglExFbgcEn7ALcBfzCod93+e80EZgK0t7dHpYdH+MEShavnzOXypdv+\nGVec1tGYxjRQreOhnjGf3q/fuHfMFxzzvWoREzt0d1BEvAjcC7wX2EdSz1/iAGB1Gl8NjAVI8/cG\nXigtL7OMWVNyzFurq+buoDenb0NI2gP4CPAExQfjr1K1KcDcND4vTZPm3xMRkcpPSXdSjAcmAA/X\nakPMasUxbzmp5nTQfsDsdI50J+DWiPiBpOXALZK+BPwcuD7Vvx64SVIXsJ7i7ggiYpmkW4HlwBbg\nnHTIbdZsHPOWjX6TQEQ8BhxRpvwZytzpEBEvAx+tsK6LgYt3vJlm9eOYt5z4F8NmZhlzEjAzy5iT\ngJlZxpwEzMwy5iRgZpYxJwEzs4w5CZiZZcxJwMwsY04CZmYZcxIwM8uYk4CZWcacBMzMMuYkYGaW\nMScBM7OMOQmYmWXMScDMLGNOAmZmGXMSMDPLmJOAmVnGnATMzDLmJGBmljEnATOzjDkJmJllzEnA\nzCxjTgJmZhnrNwlIGivpXknLJS2T9JlUfqGk1ZIWp+GEkmUukNQl6UlJx5WUT05lXZKmD80mmQ2O\nY95ysksVdbYA0yLiUUlvBBZJWpDmXRkRl5VWlnQwcArwbmB/4C5J70yzrwE+AqwCFkqaFxHLa7Eh\nZjXkmLds9JsEImINsCaNvyTpCWDMdhY5CbglIl4BnpXUBRyV5nVFxDMAkm5Jdf2BsKbimLecVHMk\n8BpJ44AjgIeA9wPnSjodeITim9MGig/LgyWLraL3A7SyT/l7yrzHVGAqQFtbG52dnWXb0t3dXXFe\nTtr2gGmHbtmmLMf9MlTxUI+YT+/Tb9w75guO+V61iImqk4CkPYHvAOdFxCZJ1wIXAZFeLwfOGlRr\ngIiYCcwEaG9vj46OjrL1Ojs7qTQvJ1fPmcvlS7f9M644raMxjWmgoYiHesU8VBf3jvmCY75XLWKi\nqiQgaVeKD8OciPguQESsLZl/HfCDNLkaGFuy+AGpjO2UmzUVx7zlopq7gwRcDzwREVeUlO9XUu3P\ngcfT+DzgFEm7SRoPTAAeBhYCEySNlzSC4kLavNpshlntOOYtJ9UcCbwf+CSwVNLiVPZ54FRJh1Mc\nGq8APgUQEcsk3Upx8WsLcE5EbAWQdC5wB7AzMCsiltVwW8xqxTFv2ajm7qCfACoza/52lrkYuLhM\n+fztLWfWDBzzlhP/YtjMLGNOAmZmGXMSMDPLmJOAmVnGnATMzDLmJGBmljEnATOzjDkJmJllzEnA\nzCxjTgJmZhlzEjAzy5iTgJlZxpwEzMwy5iRgZpYxJwEzs4w5CZiZZcxJwMwsY04CZmYZcxIwM8uY\nk4CZWcacBMzMMuYkYGaWMScBM7OMOQmYmWWs3yQgaaykeyUtl7RM0mdS+b6SFkh6Or2OSuWSdJWk\nLkmPSZpYsq4pqf7TkqYM3WaZDZxj3nJSzZHAFmBaRBwMHA2cI+lgYDpwd0RMAO5O0wDHAxPSMBW4\nFooPEDADeA9wFDCj50Nk1mQc85aNfpNARKyJiEfT+EvAE8AY4CRgdqo2Gzg5jZ8E3BiFB4F9JO0H\nHAcsiIj1EbEBWABMrunWmPWxefPm18YlvVPSn0nadXvLOOYtJ7vsSGVJ44AjgIeAtohYk2Y9B7Sl\n8THAypLFVqWySuV932Mqxbcp2tra6OzsLNuW7u7uivNy0rYHTDt0yzZlOe6XSvEwdepUgJ0kjQHu\nBBYCHwdOq2a99Yj59D79xr1jvuCY71WLmKg6CUjaE/gOcF5EbJL02ryICEkxqJb0rmsmMBOgvb09\nOjo6ytbr7Oyk0rycXD1nLpcv3fbPuOK0jsY0poEqxcOee+4J8HvgL4CvR8RXJC2uZp31ivm0vn7j\n3jFfcMz3qkVMVHV3UDp8/g4wJyK+m4rXpkNe0uu6VL4aGFuy+AGprFK52ZCJCICRFN/8f5iKd+5v\nOce85aKau4MEXA88ERFXlMyaB/Tc7TAFmFtSfnq6Y+JoYGM6hL4DmCRpVLo4NimVmQ2Zr33tawD7\nAbdFxDJJBwH3bm8Zx7zlpJrTQe8HPgksLTmM/jxwCXCrpLOBXwEfS/PmAycAXcBvgDMBImK9pIso\nzskCfDEi1tdkK8wqWLt2LUBXRFwKEBHPSLq/n8Uc85aNfpNARPwEUIXZx5apH8A5FdY1C5i1Iw00\nG4wvf/nL5YovAP6j0jKOecvJDt0dZDZc3H777cyfP5/Vq1cDjJV0VZq1F8XvAMwMdxthLWr//fen\nvb2d3XffHYpTNIvSMI/i/n0zw0cC1qIOO+wwDjvsMD7xiU8wYsSIFyJidv9LmeXHScBa2sMPPwww\nQdJTFPEuitP4BzW0YWZNwknAWtrZZ58NsBY4Btja2NaYNR8nAWtpe++9N8CmiFjXX12zHPnCsLW0\nD33oQwAHSHqvpIk9Q6PbZdYsfCRgLe2hhx4CeAPwzyXFAXy4IQ0yazJOAtbS7r33XiQ9FREfanRb\nzJqRTwdZS0vdRhwo6XYASQenbh/MDCcBa3FnnHEGwCZg/1T0FHBeo9pj1mycBKylPf/88wAbKJ4p\nQERswbeKmr3GScBa2siRI6F4fkAA9HT13Mg2mTUTJwFraVdccQUUD4B/u6QHgBuBv2loo8yaiO8O\nspY2ceJEgF9QPARGwJMR8WpDG2XWRJwErKVt3boVYG+K5wDsQvGkL/o8McwsW04C1tJOPPFEgNHA\nm0gXh82sl5OAtbRVq1YB/DIiZjS6LWbNyBeGraUdf/zxUDxNzMzK8JGAtbSjjz4aijuDfgu8Su/z\nBJwYzHASsBZ3/vnnQ3F30CHpgfBmVsKng6yljR07FuC3TgBm5flIwFraQQcdxP333/8uSRcAr/SU\n+xZRs4KTgLW08ePHQ9GB3Ig0mFmJfk8HSZolaZ2kx0vKLpS0WtLiNJxQMu8CSV2SnpR0XEn55FTW\nJWl67TfF7PVmzJgBsCYivlA69Lec495yUc2RwA3Av1D0uVLqyoi4rLRA0sHAKcC7KbruvUvSO9Ps\na4CPAKuAhZLmRcTyQbTdrF/p8ZLvlHRPaXlE9PdksRtw3FsG+j0SiIj7gPVVru8k4JaIeCUingW6\ngKPS0BURz0TE74BbUl2zIXXZZZdB8Q/4s8A/AouBR/pbznFvuRjM3UHnSnosHTaPSmVjgJUldVal\nskrlZkPqyCOPBPhNRCyKiAci4nygYxCrdNxbSxnoheFrgYso+mi/CLgcOKsWDZI0FZgK0NbWRmdn\nZ9l63d3dFeflpG0PmHbolm3KctwvleJh06ZNADtL2pfiS8+RFB3KDURD494xX3DM96pFTAwoCUTE\n2p5xSdcBP0iTq4GxJVUPSGVsp7zvumcCMwHa29ujo6OjbBs6OzupNC8nV8+Zy+VLt/0zrjitozGN\naaBK8ZDuDjoYWARsAZ4FBvSM4UbHvWO+4JjvVYuYGNDpIEn7lUz+OdBzB8U84BRJu0kaT/Ewj4eB\nhcAESeMljaC4iDZv4M02q86zzz4LsDQixkfEhIiYFBE/Gci6HPfWivo9EpB0M8U51NGSVgEzgA5J\nh1McFq8APgUQEcsk3Qosp/jWdU5EbE3rORe4g+JRf7MiYlnNt8asj2uuuQaKmAMgncc/NSK+vr3l\nHPeWi36TQEScWqb4+u3Uvxi4uEz5fGD+DrXObJCuu+46KHmwfERskPQ/ge0mAce95cJ9B1lLS08W\ne42knfEvh81e4yRgLW3y5MkAB0k6VtKxwM3AjxrbKrPm4SRgLe3SSy8FeAn4X2m4G/hcI9tk1kzc\ngZy1tJ122gngeeALFBd0n+y5aGtmTgLW4tIPaQ6h6AdIwFhJU1K3EGbZcxKwljZt2jSApyLigwCp\nY7ebKX45bJY9XxOwlvbqq6/Ctg+TeQrYtWENMmsyTgLW0trb2wEOlNSRhuuoohdRs1w4CVhLu/ba\nawFeBv5PGpZT3CVkZviagLW43XbbDeAF4FMR8esGN8es6fhIwFpSRHDhhRcyevRoKO4OelLSryX9\nU4ObZtZUnASsJV155ZU88MADLFy4EGBxROwLvAd4v6T/29jWmTUPnw6ylnTTTTexYMGCniMBACLi\nGUl/DdwJXNmwxpk1ER8JWEt69dVXt0kAPdJ1Ad8iapY4CVhLGjFiux2F/q5e7TBrdj4dZC1pyZIl\n7LXXXj2TR0jalMYF7N6YVpk1HycBa0mlzxGQ9POIaG9gc8yalk8HmZllzEnAzCxjTgJmZhlzEjAz\ny5iTgJlZxpwEzMwy5iRgZpYxJwEzs4z1mwQkzZK0TtLjJWX7Slog6en0OiqVS9JVkrokPSZpYsky\nU1L9pyVNGZrNMasNx73lopojgRuAyX3KpgN3R8QE4O40DXA8MCENU4FrofjwADMouvI9CpjR8wEy\na1I34Li3DPSbBCLiPmB9n+KTgNlpfDZwckn5jVF4ENhH0n7AccCCiFgfERuABbz+A2bWNBz3louB\n9h3UFhFr0vhzQFsaHwOsLKm3KpVVKn8dSVMpvk3R1tZGZ2dn2QZ0d3dXnJeTtj1g2qFbtinLcb/U\nKR4aGveO+YJjvlctYmLQHchFREiKwa6nZH0zgZkA7e3t0dHRUbZeZ2cnlebl5Oo5c7l86bZ/xhWn\ndTSmMQ1U73hoRNw75guO+V61iImB3h20Nh3ukl7XpfLVwNiSegekskrlZsOJ495azkCTwDyg506H\nKcDckvLT090SRwMb0+HzHcAkSaPShbFJqcxsOHHcW8vp93SQpJuBDmC0pFUUdztcAtwq6WzgV8DH\nUvX5wAlAF/Ab4EyAiFgv6SJgYar3xYjoe9HNrGk47i0X/SaBiDi1wqxjy9QN4JwK65kFzNqh1pk1\niOPecuFfDJuZZcxJwMwsY04CZmYZcxIwM8uYk4CZWcacBMzMMuYkYGaWMScBM7OMOQmYmWXMScDM\nLGNOAmZmGXMSMDPLmJOAmVnGnATMzDLmJGBmljEnATOzjDkJmJllzEnAzCxjTgJmZhlzEjAzy5iT\ngJlZxpwEzMwy5iRgZpYxJwEzs4wNKglIWiFpqaTFkh5JZftKWiDp6fQ6KpVL0lWSuiQ9JmliLTbA\nrN4c99ZKanEk8KGIODwi2tP0dODuiJgA3J2mAY4HJqRhKnBtDd7brFEc99YShuJ00EnA7DQ+Gzi5\npPzGKDwI7CNpvyF4f7NGcNzbsLTLIJcP4E5JAfxrRMwE2iJiTZr/HNCWxscAK0uWXZXK1pSUIWkq\nxTcm2tra6OzsLPvG3d3dFeflpG0PmHbolm3KctwvdY6HhsS9Y77gmO9Vi5gYbBI4JiJWS3oLsEDS\nL0pnRkSkD0rV0gdqJkB7e3t0dHSUrdfZ2UmleTm5es5cLl+67Z9xxWkdjWlMA9U5HhoS9475gmO+\nVy1iYlCngyJidXpdB9wGHAWs7TncTa/rUvXVwNiSxQ9IZWbDiuPeWsmAk4CkkZLe2DMOTAIeB+YB\nU1K1KcDcND4POD3dLXE0sLHk8NlsWHDcW6sZzOmgNuA2ST3r+WZE/EjSQuBWSWcDvwI+lurPB04A\nuoDfAGcO4r3NGsVxby1lwEkgIp4BDitT/gJwbJnyAM4Z6PuZNQPHvbUa/2LYzCxjTgJmZhlzEjAz\ny5iTgJlZxpwEzMwy5iRgZpYxJwEzs4w5CZiZZcxJwMwsY04CZmYZcxIwM8uYk4CZWcacBMzMMuYk\nYGaWMScBM7OMOQmYmWXMScDMLGNOAmZmGXMSMDPLmJOAmVnGnATMzDLmJGBmljEnATOzjDkJmJll\nzEnAzCxjdU8CkiZLelJSl6Tp9X5/s3pzzFszq2sSkLQzcA1wPHAwcKqkg+vZBrN6csxbs6v3kcBR\nQFdEPBMRvwNuAU6qcxvM6skxb01tlzq/3xhgZcn0KuA9pRUkTQWmpsluSU9WWNdo4Pmat3D4ed1+\n0KUNakljbS8eDqxnQ/roN+ah6rh3zBcc870qxUTVMV/vJNCviJgJzOyvnqRHIqK9Dk1qat4PheG+\nH6qJ++G+jbXi/dCrFvui3qeDVgNjS6YPSGVmrcoxb02t3klgITBB0nhJI4BTgHl1boNZPTnmranV\n9XRQRGyRdC5wB7AzMCsilg1wdf2eMsqE90OhKfeDY35IeD/0GvS+UETUoiFmZjYM+RfDZmYZcxIw\nM8tY0ycBSZ+R9LikZZLOKzO/Q9JGSYvT8E+NaGetSZolaZ2kx0vK9pW0QNLT6XVUhWWnpDpPS5pS\nv1bX3iD3w9aSuGjai7EVtvEwST+TtFTS9yXtVWHZFanOYkmP1K/VtSdprKR7JS1Pn/fPpPKs4r4G\n+2HH4j4imnYADgEeB95AcRH7LuAdfep0AD9odFuHYNv/GJgIPF5S9hVgehqfDlxaZrl9gWfS66g0\nPqrR21Pv/ZDmdTe6/YPYxoXAB9P4WcBFFZZdAYxu9DbUaD/sB0xM428EnqLoaiOruB/Mfkjzdiju\nm/1I4A+BhyLiNxGxBfgx8BcNblNdRMR9wPo+xScBs9P4bODkMoseByyIiPURsQFYAEwesoYOsUHs\nh2Gjwja+E7gvjS8A/rKujWqAiFgTEY+m8ZeAJyh+cZ1V3A9yP+ywZk8CjwMfkPQmSW8ATmDbH970\neK+kJZJul/Tu+jaxrtoiYk0afw5oK1OnXDcFY4a6YXVWzX4A2F3SI5IelDTcEsUyevsY+ijl4x4g\ngDslLUpdT7QESeOAI4CHyDjuB7AfYAfjvum6jSgVEU9IuhS4E9gMLAa29qn2KHBgRHRLOgH4HjCh\nvi2tv4gISdnf39vPfjgwIlZLOgi4R9LSiPhlPds3CGcBV0n6R4ofl/2uQr1j0ja+BVgg6RfpyGLY\nkrQn8B3gvIjYJOm1eTnF/SD2ww7FfbMfCRAR10fEkRHxx8AGivNjpfM3RUR3Gp8P7CppdAOaWg9r\nJe0HkF7XlamTQzcF1ewHImJ1en0G6KT4RjUsRMQvImJSRBwJ3AyU/RCXbOM64DaKXkuHLUm7Uvzj\nmxMR303F2cX9IPbDDsd90yeB9A0HSW+juB7wzT7z36qUIiUdRbFNL9S7nXUyD+i562EKMLdMnTuA\nSZJGpbsHJqWyVtLvfkjbv1saHw28H1hetxYOUknc7wT8A/CNMnVGSnpjzzjF3/rxvvWGi/Q5vh54\nIiKuKJmVVdwPZj8MKO4bfSW8iivl96eNWAIcm8o+DXw6jZ9Lcf50CfAg8L5Gt7lG230zsAZ4leL8\n5tnAm4C7gacp7pTaN9VtB/6tZNmzgK40nNnobWnEfgDeByxNcbEUOLvR27KD2/gZiqPep4BL6P11\n//7A/DR+UNq+Jekz8PeN3pZB7odjKK5xPEZx6ncxxXXArOJ+MPthIHHvbiPMzDLW9KeDzMxs6DgJ\nmJllzEnAzCxjTgJmZhlzEjAzy5iTgJkNmKQrVdK7r6Q7JP1byfTlks4fxPovlPS3FeadrqKH4aWS\nfl6p3mBI+nyt19lsnATMbDAeoLg3veeHbaOB0v673gf8tJoVSaq6GxtJxwPnAZMi4lDgaGBjtcvv\nACcBM7Pt+Cnw3jT+bopfLL9U8svVPwQeVeGrJd/cPw6vPQ/k/tTv/fJU9veSnpL0E+BdFd73AuBv\nI+I/ASLilYi4Li1/eOo87TFJt/X0uy+pU1J7Gh8taUUaP0PSdyX9KPXV/5VUfgmwR+qXf05td1vz\naOoO5MysuUXEf0rakrp1eR/wM4reO99L8c18aUT8TtJfAocDh1EcLSyU1NPR3UTgkIh4VtKRwCmp\n7i4UHUQuKvPWh1QoB7gR+JuI+LGkLwIzKI4atudwij52XgGelHR1REyXdG5EHF7Frhi2fCRgZoP1\nU4oE0JMEflYy/UCqcwxwc0RsjYi1FM8G+aM07+GIeDaNfwC4LYpniGyi6C+napL2BvaJiB+notkU\nD+3pz90RsTEiXqY4IjlwR953OHMSMLPB6rkucCjF6aAHKY4Eqr0esHkA77kMOHIHl9lC7/+83fvM\ne6VkfCsZnSVxEjCzwfop8KfA+vRNfz2wD0Ui6EkC9wMfl7SzpDdTfDt/uMy67gNOlrRH6iH1xArv\n+WXgq5LeCiBphKT/EREbgQ2SPpDqfZLiqAOKR3H2JI6/qnLbXk3dOresbLKdmQ2ZpRTn+b/Zp2zP\niHg+Td9GkRSWUPSQ+bmIeE7SH5SuKCIelfStVG8dxbOWXyci5ktqA+5KXS8HMCvNngJ8Q8XTCJ8B\nzkzllwG3qngC2w+r3LaZwGOSHo2I06pcZlhxL6JmZhnz6SAzs4w5CZiZZcxJwMwsY04CZmYZcxIw\nM8uYk4CZWcacBMzMMvZfBCLosyrzgBIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s89eZTkH8YrD",
        "colab_type": "code",
        "outputId": "c3be13d9-81d0-4c7c-c795-690586c37d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "word_dict = {}\n",
        "text = df['text'].apply(lambda x: nltk.word_tokenize(x))\n",
        "\n",
        "for index, row in text.iteritems():\n",
        "  for word in row:\n",
        "    if word not in word_dict.keys():\n",
        "      word_dict[word] = 1\n",
        "    else:\n",
        "      word_dict[word] += 1\n",
        "\n",
        "print(len(word_dict))\n",
        "sorted_dict = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "print(sorted_dict)\n",
        "x, y = zip(*sorted_dict)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n",
            "[('Obama', 6202), ('Its', 3101), ('official', 3101), ('US', 3101), ('President', 3101), ('Barack', 3101), ('want', 3101), ('lawmaker', 3101), ('weigh', 3101), ('whether', 3101), ('use', 3101), ('military', 3101), ('force', 3101), ('Syria', 3101), ('sent', 3101), ('letter', 3101), ('head', 3101), ('House', 3101), ('Senate', 3101)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BylQYAlHFbNb",
        "colab_type": "code",
        "outputId": "16493887-df79-433e-d1ae-190e9ede5397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# accept_words = list(x[3:])\n",
        "accept_words = list(x)\n",
        "accept_words = [x.lower() for x in accept_words]\n",
        "print(accept_words)\n",
        "print(df['text'][2])\n",
        "# print(df['text'][451])\n",
        "df['text'] = df['text'].apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: \" \".join([word for word in x if word.lower() in accept_words]))\n",
        "print(df['text'][2])\n",
        "# print(df['text'][451])"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['obama', 'its', 'official', 'us', 'president', 'barack', 'want', 'lawmaker', 'weigh', 'whether', 'use', 'military', 'force', 'syria', 'sent', 'letter', 'head', 'house', 'senate']\n",
            "Its official US President Barack Obama want lawmaker weigh whether use military force Syria Obama sent letter head House Senate\n",
            "Its official US President Barack Obama want lawmaker weigh whether use military force Syria Obama sent letter head House Senate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhk5FT8jLtds",
        "colab_type": "code",
        "outputId": "f04c9dad-ac2c-4eb7-db0e-737f9bc362a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "word_dict = {}\n",
        "text = df['summary'].apply(lambda x: nltk.word_tokenize(x))\n",
        "\n",
        "for index, row in text.iteritems():\n",
        "  for word in row:\n",
        "    if word not in word_dict.keys():\n",
        "      word_dict[word] = 1\n",
        "    else:\n",
        "      word_dict[word] += 1\n",
        "\n",
        "print(len(word_dict))\n",
        "sorted_dict = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "print(sorted_dict)\n",
        "x, y = zip(*sorted_dict)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[('Obama', 6202), ('Syrian', 3101), ('official', 3101), ('climbed', 3101), ('top', 3101), ('tree', 3101), ('doesnt', 3101), ('know', 3101), ('get', 3101)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS67k2PkLuzc",
        "colab_type": "code",
        "outputId": "e7f4cb26-0134-41cd-9286-555b825d5506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# accept_words = list(x[4:])\n",
        "accept_words = list(x)\n",
        "accept_words = [x.lower() for x in accept_words]\n",
        "print(accept_words)\n",
        "print(df['summary'][2])\n",
        "# print(df['summary'][451])\n",
        "df['summary'] = df['summary'].apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: \" \".join([word for word in x if word.lower() in accept_words]))\n",
        "print(df['summary'][2])\n",
        "# print(df['summary'][451])"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['obama', 'syrian', 'official', 'climbed', 'top', 'tree', 'doesnt', 'know', 'get']\n",
            "Syrian official Obama climbed top tree doesnt know get Obama\n",
            "Syrian official Obama climbed top tree doesnt know get Obama\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbpPDk83ZSXI",
        "colab_type": "code",
        "outputId": "ab791d2f-ed08-4378-be07-6f57ca0b2e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in df['text']:\n",
        "      text_word_count.append(len(i.split(' ')))\n",
        "\n",
        "for i in df['summary']:\n",
        "      summary_word_count.append(len(i.split(' ')))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.ylabel('Documents')\n",
        "plt.xlabel('Word Count')\n",
        "# plt.savefig('word_count_distro' + str(build_number) + '.png')\n",
        "plt.show()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEWCAYAAACAOivfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM8uYk4CZWcacBMzMMvZfBCLosyrzgBIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nNZ2tVpljHTc"
      },
      "source": [
        "Max Text Lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3T01Jf-XjGKO",
        "outputId": "db8dbf0a-07ea-4ca4-b6a0-8b30b4e168e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "max_text_len = max([len(txt.split(' ')) for txt in df['text']])\n",
        "max_summary_len = max([len(txt.split(' ')) for txt in df['summary']])\n",
        "print(max_text_len)\n",
        "print(max_summary_len)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CGl1z0OFjTsr"
      },
      "source": [
        "### Training-Validation Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SwmBST04juu6"
      },
      "source": [
        "X - Articles text </br>\n",
        "Y - Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f1_YrHcDjN6e",
        "colab": {}
      },
      "source": [
        "# convert to numpy array\n",
        "X = np.array(df['text'])\n",
        "Y = np.array(df['summary'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XGHJXwaojYAV",
        "outputId": "06a36a00-4284-4571-d917-d365d4be108c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "x_tr,x_val,y_tr,y_val=train_test_split(X,Y,test_size=test_train_split,random_state=0,shuffle=True)\n",
        "print(x_tr.shape)\n",
        "print(x_val.shape)\n",
        "print(y_tr.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2635,)\n",
            "(466,)\n",
            "(2635,)\n",
            "(466,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F9BaBUY0YaQ",
        "colab_type": "text"
      },
      "source": [
        "## GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymiCWKv90X7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_index = {}\n",
        "with open('./drive/My Drive/glove/glove.6B.' + str(embedding_dim) + 'd.txt') as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embedding_index[word] = coefs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIZvswoZmlCb",
        "colab_type": "code",
        "outputId": "450c113d-4b9d-487b-b970-7a54c7078790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(embedding_index))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbjgCoOmmwb6",
        "colab_type": "code",
        "outputId": "6abfd3e1-5be0-4848-c787-bf920149ab80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "print(embedding_index.get(\"us\"))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3.3090e-01  1.0111e+00  1.5401e+00 -3.7205e-03 -1.6854e-01 -3.6448e-01\n",
            " -4.9264e-01 -2.7382e-01  4.2796e-02 -1.0149e-01  8.2923e-01 -2.1641e-01\n",
            "  1.8006e-01  2.2698e-01  1.4333e-02  2.6679e-01 -1.7742e-01 -3.5467e-01\n",
            " -6.1956e-01  8.1431e-01  1.2080e+00 -6.4785e-02  1.1816e-01  1.9243e-01\n",
            " -2.6561e-02  2.8291e-01  1.8635e-01 -6.3154e-01  1.0080e+00 -3.3754e-01\n",
            "  3.1217e-02  5.5929e-01 -3.4031e-01 -3.8397e-02 -8.6859e-02  7.0105e-01\n",
            " -4.7500e-01  1.2132e-01  3.8364e-01  3.1194e-01 -7.7032e-01 -8.4787e-01\n",
            "  1.2489e-04  2.3546e-01  3.7578e-01 -1.7466e-01 -6.8517e-01 -3.4409e-01\n",
            " -6.0872e-01 -1.6763e+00  1.5370e-01 -6.7015e-02  7.4586e-01  1.1758e+00\n",
            " -5.2170e-01 -2.4951e+00  3.1104e-01 -4.2603e-01  2.1117e+00  1.8723e-02\n",
            "  4.0115e-01  4.1757e-01 -2.1425e-01 -1.9927e-01 -5.3570e-01  9.3413e-02\n",
            " -4.2322e-02  1.0767e+00  1.0693e-01  3.8199e-01  3.4468e-01 -4.3743e-01\n",
            " -7.7398e-01 -4.2631e-01  2.3625e-01 -7.5068e-02  5.1797e-01  4.3557e-01\n",
            " -1.4849e+00  1.4530e-01  1.0455e+00 -1.5742e-01 -9.4204e-02  5.2510e-01\n",
            " -1.1266e+00  2.0811e-01  2.2303e-01  2.3587e-01  8.1314e-02 -8.0265e-01\n",
            "  3.7458e-02  2.5518e-01 -3.6446e-01 -8.1031e-01 -4.9818e-01  3.7837e-02\n",
            "  2.5238e-01  3.0629e-02  5.9237e-01  4.1334e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SzWpoc9OjjdV"
      },
      "source": [
        "### Word Embeddings - Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iLVdVklnjq1i"
      },
      "source": [
        "X Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z7qUrNpbjpI2",
        "outputId": "be356353-e83b-4ceb-ea79-c0568ca7175f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_dict = {}\n",
        "text = df['text']\n",
        "\n",
        "for row in text: \n",
        "  for word in row.split(\" \"):\n",
        "    if word not in word_dict:\n",
        "      word_dict[word] = 1\n",
        "    else:\n",
        "      word_dict[word] += 1\n",
        "\n",
        "print(len(word_dict))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnrYczEn19K8",
        "colab_type": "code",
        "outputId": "a1def6ea-1f35-4823-f990-8157ca19367e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=len(word_dict), split=\" \") \n",
        "x_tokenizer.fit_on_texts(list(X))\n",
        "\n",
        "x_embedding_matrix = np.zeros(((x_tokenizer.num_words)+1, embedding_dim),dtype='float32')\n",
        "print(x_embedding_matrix.shape)\n",
        "for word,i in x_tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in glove will be zeros\n",
        "        x_embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6qbg_6TKj4HK",
        "outputId": "8c1c847c-64c4-4ab1-ae9a-d9406119f395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# # #prepare a tokenizer for reviews on training data\n",
        "# x_tokenizer = Tokenizer(num_words=len(word_dict), split=\" \") \n",
        "# x_tokenizer.fit_on_texts(list(X))\n",
        "\n",
        "# #convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=x_voc, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=x_voc, padding='post')\n",
        "\n",
        "print(x_voc)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7HbKly2Ld64",
        "colab_type": "code",
        "outputId": "aa4c74cf-64b6-4d84-a57c-8637179099c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(x_tokenizer.num_words)\n",
        "print(x_voc)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6NsdijM3j6RJ"
      },
      "source": [
        "Y Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CG6Q2G-Wj79A",
        "outputId": "705097d1-9129-479e-f2f3-c9ec21958ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_word_dict = {}\n",
        "summ = df['summary']\n",
        "\n",
        "for row in summ: \n",
        "  for word in row.split(\" \"):\n",
        "    if word not in y_word_dict:\n",
        "      y_word_dict[word] = 1\n",
        "    else:\n",
        "      y_word_dict[word] += 1\n",
        "\n",
        "print(len(y_word_dict))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJg5DOHaVFR2",
        "colab_type": "code",
        "outputId": "b7b1e8a5-ba83-4fda-fe12-0f0bcc59df8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=len(y_word_dict), split=\" \") \n",
        "y_tokenizer.fit_on_texts(list(Y))\n",
        "\n",
        "y_embedding_matrix = np.zeros((x_tokenizer.num_words +1, embedding_dim),dtype='float32')\n",
        "print(y_embedding_matrix.shape)\n",
        "print(len( y_tokenizer.word_index))\n",
        "for word,i in y_tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "    # Words not found in glove will be zeros\n",
        "        y_embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 100)\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C5ugAAnIj91g",
        "outputId": "ac6a4bbc-63e9-4853-a403-6270affd94b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "# y_tokenizer = Tokenizer(num_words=len(y_word_dict), split=\" \") \n",
        "# y_tokenizer.fit_on_texts(list(Y))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words + 1\n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=x_voc, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=x_voc, padding='post')\n",
        "\n",
        "print(y_voc)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zntqptcwj_lh"
      },
      "source": [
        "## Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uc0JOUvqkWUL"
      },
      "source": [
        "#### Encoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9dx-9BT6kZMw",
        "colab": {}
      },
      "source": [
        "# bidirectional encoder\n",
        "encoder_inputs = Input(shape=(x_voc,))\n",
        "#embedding layer\n",
        "# changed trainable to false\n",
        "# enc_emb_layer =  Embedding(x_voc,embedding_dim,trainable=True)\n",
        "enc_emb_layer = Embedding(x_voc, embedding_dim, weights=[x_embedding_matrix], \n",
        "                          input_length=x_voc, trainable=False)\n",
        "enc_emb = enc_emb_layer(encoder_inputs)\n",
        "\n",
        "#encoder lstm \n",
        "encoder_lstm = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True))\n",
        "encoder_outputs, fw_state_h, fw_state_c, bw_state_h, bw_state_c = encoder_lstm(enc_emb)\n",
        "\n",
        "state_h = Concatenate()([fw_state_h, bw_state_h])\n",
        "state_c = Concatenate()([fw_state_c, bw_state_c])\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8JJUPBdfkdlb"
      },
      "source": [
        "#### Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VLgYfdF3kb1A",
        "colab": {}
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(x_voc,))\n",
        "\n",
        "#embedding layer\n",
        "#changed trainable to false\n",
        "# dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=False)\n",
        "dec_emb_layer = Embedding(x_voc, embedding_dim,\n",
        "                          weights=[y_embedding_matrix], input_length=x_voc, \n",
        "                          trainable=False)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim*2, return_sequences=True, return_state=True)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(\n",
        "    dec_emb, initial_state=encoder_states)\n",
        "                                                          \n",
        "#dense layer\n",
        "decoder_dense = Dense(y_voc, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rIpBF_fAkfuG"
      },
      "source": [
        "#### Combined LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ASIlTOT_khrn",
        "outputId": "75d7e628-1dcf-410f-a21c-e9570679eda5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 20, 100)      2000        input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) [(None, 20, 512), (N 731136      embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 20, 100)      2000        input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 512)          0           bidirectional_2[0][1]            \n",
            "                                                                 bidirectional_2[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 512)          0           bidirectional_2[0][2]            \n",
            "                                                                 bidirectional_2[0][4]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, 20, 512), (N 1255424     embedding_4[0][0]                \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20, 10)       5130        lstm_4[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,995,690\n",
            "Trainable params: 1,991,690\n",
            "Non-trainable params: 4,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi9_HXvVwS1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = RMSprop(lr=LEARNING_RATE, rho=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gMQ1ZrF0ksMT",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o12XRjJykuA-"
      },
      "source": [
        "- Early Stopping Callback to ensure we stop when Validation Loss is lowest - minimises risk of overfitting\n",
        "- Model Checkpoint saves the model after each epoch so that we can load the model with the best weights later on. Alternatively, it allows us to continue training the model at a later data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6R-qwZoNkspo",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3, restore_best_weights=False)\n",
        "filepath = \"./drive/My Drive/project-model/saved-model-{epoch:02d}.hdf5\"\n",
        "mc = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02-CPYWhXiYz",
        "colab_type": "text"
      },
      "source": [
        "#### Use this method to train a new model. To continue training a previously trained model see below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Yil8ApSM-sK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# history = model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:], batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[es], validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4ScM7ZQNZwy",
        "colab_type": "code",
        "outputId": "5cd432ea-4bb7-484b-91d2-461eadf46b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(x_tr.shape)\n",
        "print(y_tr.shape)\n",
        "print(y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1).shape)\n",
        "print(y_val.reshape(y_val.shape[0],y_val.shape[1], 1).shape)\n",
        "y_tr_3d = y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)\n",
        "y_val_3d = y_val.reshape(y_val.shape[0],y_val.shape[1], 1)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2635, 20)\n",
            "(2635, 20)\n",
            "(2635, 20, 1)\n",
            "(466, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pbnxf9ZWk4I0",
        "outputId": "b8c4ce72-cf71-4542-c685-b8ee5ea847ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "history = model.fit([x_tr,y_tr], y_tr_3d, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[es],\n",
        "                    validation_data=([x_val,y_val], y_val_3d))"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2635 samples, validate on 466 samples\n",
            "Epoch 1/200\n",
            "2635/2635 [==============================] - 191s 73ms/step - loss: 0.0185 - val_loss: 1.0431e-06\n",
            "Epoch 2/200\n",
            "2635/2635 [==============================] - 189s 72ms/step - loss: 1.0431e-06 - val_loss: 1.0431e-06\n",
            "Epoch 3/200\n",
            "2635/2635 [==============================] - 188s 71ms/step - loss: 1.0431e-06 - val_loss: 1.0431e-06\n",
            "Epoch 4/200\n",
            "2635/2635 [==============================] - 188s 71ms/step - loss: 1.0431e-06 - val_loss: 1.0431e-06\n",
            "Epoch 00004: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N52zaYcKlAXE",
        "outputId": "97434ed8-406f-4dbd-9488-e6fc3a2c66db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='validation')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "# plt.savefig('loss' + str(build_number) + '.png')\n",
        "plt.show()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXRV5b3/8fc3A0RmCGEMmACJMogM\nEWkVBRGKthe0oqIdpLWl10od8PZ36b23w3W162pbwVqHlqottlakWFs6WIoMKq0iwSIyCIRJAgIh\nMs8J398fZ4PHeCAhnJN9TvJ5rXUW++z97Cffh6P58Oy9z97m7oiIiMRDWtgFiIhI/aFQERGRuFGo\niIhI3ChUREQkbhQqIiISNxlhFxCmtm3bel5eXthliIiklKVLl+5y95xY2xp0qOTl5VFcXBx2GSIi\nKcXMNp9umw5/iYhI3ChUREQkbhQqIiISNw36nIqI1C/Hjx+ntLSUI0eOhF1KvZCVlUVubi6ZmZk1\n3kehIiL1RmlpKc2bNycvLw8zC7uclObulJeXU1paSn5+fo330+EvEak3jhw5QnZ2tgIlDsyM7Ozs\ns571KVREpF5RoMRPbf4uFSq1sGLrXh7827vosQEiIh+lUKmFt97bzRML1/OPkvKwSxGRJLJnzx4e\nf/zxs97v2muvZc+ePQmoqO4pVGrh5ku60KllFg/NXaPZioiccrpQqaioOON+f/3rX2nVqlWiyqpT\nCpVaaJyRzjeGF/Cv9/awYM3OsMsRkSQxefJk1q9fT79+/bjkkksYMmQIo0ePplevXgBcd911DBw4\nkN69ezNt2rRT++Xl5bFr1y42bdpEz549+epXv0rv3r0ZOXIkhw8fDms4taJLimtp7MBcnli4nof+\nvpZhF7TTyUGRJPO/f1rJqm374tpnr04t+O6/9T7t9gceeIAVK1awbNkyFi5cyKc//WlWrFhx6pLc\np59+mjZt2nD48GEuueQSbrjhBrKzsz/Sx7p163juuef4xS9+wU033cQLL7zA5z//+biOI5E0U6ml\nzPQ07h5ewMpt+5izcnvY5YhIEho0aNBHvuPxyCOPcPHFFzN48GC2bNnCunXrPrZPfn4+/fr1A2Dg\nwIFs2rSprsqNC81UzsF1/Tvz+MISps5dx8heHUhL02xFJFmcaUZRV5o2bXpqeeHChbz88su8/vrr\nNGnShKFDh8b8Dkjjxo1PLaenp6fc4S/NVM5Beppxz9WFrNmxnz+/837Y5YhIyJo3b87+/ftjbtu7\ndy+tW7emSZMmvPvuu7zxxht1XF3dUKico09f1JELOzTn4blrqag8EXY5IhKi7OxsLrvsMvr06cM3\nv/nNj2wbNWoUFRUV9OzZk8mTJzN48OCQqkwsS+QlsWY2CvgJkA486e4PVNneGHgGGAiUAze7+yYz\nywZmAZcAv3L3iUH75sBrUV3kAr9x93vMbDzwI2BrsO1Rd3/yTPUVFRV5PB7SNWfldr7266X8+MaL\nGTsw95z7E5HaWb16NT179gy7jHol1t+pmS1196JY7RM2UzGzdOAx4BqgF3CLmfWq0ux2YLe79wCm\nAg8G648A3wb+I7qxu+93934nX8Bm4PdRTZ6P2n7GQImnkb3ac1Hnlvxk3lqOa7YiIg1YIg9/DQJK\n3H2Dux8DZgBjqrQZA0wPlmcBw83M3P2guy8iEi4xmVkh0I6PzlxCYWZMGlnIlg8O87vi0rDLEREJ\nTSJDpTOwJep9abAuZht3rwD2AtnUzDgiM5Po43c3mNlyM5tlZl1i7WRmE8ys2MyKy8rKavijqje0\nMIcBXVvx0/nrOHK8Mm79ioikklQ+UT8OeC7q/Z+APHfvC8zlwxnQR7j7NHcvcveinJycuBVjZtw3\n8gLe33uEGW++F7d+RURSSSJDZSsQPVvI5cOT6B9rY2YZQEsiJ+zPyMwuBjLcfenJde5e7u5Hg7dP\nEjn5X6c+2T2bwd3a8NjC9Rw+ptmKiDQ8iQyVJUCBmeWbWSMiM4vZVdrMBm4LlscC871ml6Pdwkdn\nKZhZx6i3o4HVtar6HJycrZTtP8qv39hU1z9eRCR0CQuV4BzJRGAOkV/wM919pZndb2ajg2ZPAdlm\nVgJMAiaf3N/MNgFTgPFmVlrlyrGbqBIqwF1mttLM3gbuAsYnYFjVuiSvDVcU5vCzVzZw4OiZ70wq\nIg1bs2bNANi2bRtjx46N2Wbo0KFU99WHhx9+mEOHDp16H+at9BN6TsXd/+ruhe7e3d1/EKz7jrvP\nDpaPuPuN7t7D3Qe5+4aoffPcvY27N3P3XHdfFbWtm7u/W+Vnfcvde7v7xe4+rOr2ujRpRCEfHDzG\n9H9uCqsEEUkhnTp1YtasWbXev2qohHkr/VQ+UZ+0+nVpxdU92/HzV9az9/DxsMsRkToyefJkHnvs\nsVPvv/e97/H973+f4cOHM2DAAC666CL++Mc/fmy/TZs20adPHwAOHz7MuHHj6NmzJ9dff/1H7v11\nxx13UFRURO/evfnud78LRG5SuW3bNoYNG8awYcOAD2+lDzBlyhT69OlDnz59ePjhh0/9vETdYl83\nlEyQe0cU8ulHFvHUoo1MGlEYdjkiDc9Lk2H7O/Hts8NFcM0Dp9188803c88993DnnXcCMHPmTObM\nmcNdd91FixYt2LVrF4MHD2b06NGnfVzGE088QZMmTVi9ejXLly9nwIABp7b94Ac/oE2bNlRWVjJ8\n+HCWL1/OXXfdxZQpU1iwYAFt27b9SF9Lly7ll7/8JYsXL8bdufTSS7nyyitp3bp1wm6xr5lKgvTu\n1JJrL+rA04s2svvgsbDLEZE60L9/f3bu3Mm2bdt4++23ad26NR06dOC//uu/6Nu3L1dffTVbt25l\nx44dp+3j1VdfPfXLvW/fvvTt2/fUtpkzZzJgwAD69+/PypUrWbVq1em6AWDRokVcf/31NG3alGbN\nmvHZz36W116LfF88UbfY10wlge65upCXVmzn569uYPI1F4ZdjkjDcoYZRSLdeOONzJo1i+3bt3Pz\nzTfz7LPPUlZWxtKlS8nMzCQvLy/mLe+rs3HjRn784x+zZMkSWrduzfjx42vVz0mJusW+ZioJVNi+\nOWMu7sT0f26ibP/R6ncQkZR38803M2PGDGbNmsWNN97I3r17adeuHZmZmSxYsIDNmzefcf8rrriC\n3/72twCsWLGC5cuXA7Bv3z6aNm1Ky5Yt2bFjBy+99NKpfU53y/0hQ4bwhz/8gUOHDnHw4EFefPFF\nhgwZEsfRfpxCJcHuvrqQY5UneGLh+rBLEZE60Lt3b/bv30/nzp3p2LEjn/vc5yguLuaiiy7imWee\n4cILz3zU4o477uDAgQP07NmT73znOwwcGPke98UXX0z//v258MILufXWW7nssstO7TNhwgRGjRp1\n6kT9SQMGDGD8+PEMGjSISy+9lK985Sv0798//oOOktBb3ye7eN36vjr/b9bb/GHZNl795jA6tMxK\n+M8Taah06/v4S5pb38uHvnFVAe7Oows+/jxqEZH6RKFSB7q0acJNRV14fskWSncfqn4HEZEUpVCp\nIxOv6oGZ8dN5JWGXIlKvNeRD+vFWm79LhUod6djyPD53aVdmvVXKpl0Hwy5HpF7KysqivLxcwRIH\n7k55eTlZWWd3HljfU6lDdwztzow3t/CTeeuYenO/sMsRqXdyc3MpLS0lng/ga8iysrLIzc09q30U\nKnWoXfMsvvjJ85n26ga+PrQ7Be2bh12SSL2SmZlJfn5+2GU0aDr8Vce+dkV3mmSm8/DLuhJMROof\nhUoda9O0Ebdfns9f3nmfVdv2hV2OiEhcKVRCcPuQbrTIymDK3LVhlyIiElcKlRC0PC+TCVd04+XV\nO3h7SzhPZxMRSQSFSkjGX5ZP6yaZmq2ISL2S0FAxs1FmtsbMSsxscoztjc3s+WD7YjPLC9Znm9kC\nMztgZo9W2Wdh0Oey4NXuTH0lq2aNM/j3K7vzytoyijd9EHY5IiJxkbBQMbN04DHgGqAXcIuZ9arS\n7HZgt7v3AKYCDwbrjwDfBv7jNN1/zt37Ba+d1fSVtL74iTzaNmvMQ3/XbEVE6odEzlQGASXuvsHd\njwEzgDFV2owBpgfLs4DhZmbuftDdFxEJl5qK2Vfty0+88xqlc+ew7ry+oZx/luwKuxwRkXOWyFDp\nDGyJel8arIvZxt0rgL1Adg36/mVw6OvbUcFRo77MbIKZFZtZcTJ86/aWQV3p2DKLh+au1a0lRCTl\npeKJ+s+5+0XAkOD1hbPZ2d2nuXuRuxfl5OQkpMCzkZWZzsSrerB0825eWRt+yImInItEhspWoEvU\n+9xgXcw2ZpYBtATKz9Spu28N/twP/JbIYbZa9ZUsbhzYhdzW5zFFsxURSXGJDJUlQIGZ5ZtZI2Ac\nMLtKm9nAbcHyWGC+n+G3qpllmFnbYDkT+AywojZ9JZNGGWncPbyA5aV7mbtqR9jliIjUWsJCJTiv\nMRGYA6wGZrr7SjO738xGB82eArLNrASYBJy67NjMNgFTgPFmVhpcOdYYmGNmy4FlRGYnv6iur1Rw\nff/OdGvblClz13LiREpkoYjIx+gZ9XXwjPqa+uOyrdw9YxmP3tqfz/TtFHY5IiIx6Rn1KeIzfTtR\n2L4ZU+eupVKzFRFJQQqVJJKeZtx7dSHryw7yx2VVr2kQEUl+CpUk86neHejdqQU/mbeO45Unwi5H\nROSsKFSSTFqaMWlEIZvLD/HC0tKwyxEROSsKlSR01YXt6NelFT+dX8LRisqwyxERqTGFShIyM+4b\nWcjWPYeZuWRL9TuIiCQJhUqSurxHWwblteGn80s4clyzFRFJDQqVJHVytrJz/1F+88bmsMsREakR\nhUoSu7RbNpf3aMsTC9dz8GhF2OWIiFRLoZLkJo0spPzgMaa/vinsUkREqqVQSXIDurbmqgvb8fNX\nNrDvyPGwyxEROSOFSgqYNKKQvYeP8/SijWGXIiJyRgqVFNCnc0tG9e7AU69tZM+hY2GXIyJyWgqV\nFHHviEIOHKvgF69tCLsUEZHTUqikiAs6NOczfTvxy39sovzA0bDLERGJSaGSQu65uoAjxyv52Svr\nwy5FRCQmhUoK6Z7TjOv75/LM65vZse9I2OWIiHxMQkPFzEaZ2RozKzGzjz3e18wam9nzwfbFZpYX\nrM82swVmdsDMHo1q38TM/mJm75rZSjN7IGrbeDMrM7NlwesriRxbWO4eXkDlCefxBSVhlyIi8jEJ\nCxUzSwceA64BegG3BM+Zj3Y7sNvdewBTgQeD9UeAbwP/EaPrH7v7hUB/4DIzuyZq2/Pu3i94PRnH\n4SSNrtlNuLGoC8+9uYWtew6HXY6IyEckcqYyCChx9w3ufgyYAYyp0mYMMD1YngUMNzNz94PuvohI\nuJzi7ofcfUGwfAx4C8hN4BiS0jeu6gHAo/PXhVyJiMhHJTJUOgPR920vDdbFbOPuFcBeILsmnZtZ\nK+DfgHlRq28ws+VmNsvMutS28GTXqdV53HppV35XXMrm8oNhlyMickpKnqg3swzgOeARdz/5xY0/\nAXnu3heYy4czoKr7TjCzYjMrLisrq5uCE+DrQ7uTnmb8ZJ5mKyKSPBIZKluB6NlCbrAuZpsgKFoC\n5TXoexqwzt0fPrnC3cvd/eQXOJ4EBsba0d2nuXuRuxfl5OTUaCDJqF2LLL74ifP5w7+2UrLzQNjl\niIgAiQ2VJUCBmeWbWSNgHDC7SpvZwG3B8lhgvrv7mTo1s+8TCZ97qqzvGPV2NLD6HGpPCf9+ZXey\nMtM1WxGRpJGwUAnOkUwE5hD5BT/T3Vea2f1mNjpo9hSQbWYlwCTg1GXHZrYJmAKMN7NSM+tlZrnA\nfxO5muytKpcO3xVcZvw2cBcwPlFjSxbZzRrzpcvy+NPb23h3+76wyxERwaqZGNRrRUVFXlxcHHYZ\n52TvoeNc/sP5fLJ7Nj//QlHY5YhIA2BmS9095i+clDxRLx9q2SSTr1zejTkrd/BO6d6wyxGRBk6h\nUg98+fI8WjXJZMrcNWGXIiINnEKlHmielcnXrujOgjVlLN28O+xyRKQBU6jUE7d98nzaNmuk2YqI\nhEqhUk80aZTBHUN78I+Scl5fX5Ov+oiIxJ9CpR753KVdad+iMVPmrqEhX9UnIuFRqNQjWZnpTBzW\ngyWbdvPaul1hlyMiDZBCpZ656ZIudG51Hg/NXavZiojUOYVKPdM4I527hvfg7S17mLd6Z9jliEgD\no1Cphz47IJe87CZMmbuWEyc0WxGRuqNQqYcy09O4++oCVr2/j7+t3B52OSLSgChU6qnRF3emR7tm\nTJ27lkrNVkSkjihU6qn0NOPeqwtZt/MAf16+LexyRKSBUKjUY9f06cCFHZrz8MvrqKg8EXY5ItIA\nKFTqsbQ0Y9KIQjbuOsjv/1X1oZsiIvGnUKnnRvRqT9/cljwybx3HKjRbEZHEUqjUc2aR2Urp7sPM\nLN4SdjkiUs8pVBqAKwtzKDq/NY/OL+HI8cqwyxGReiyhoWJmo8xsjZmVmNnkGNsbm9nzwfbFZpYX\nrM82swVmdsDMHq2yz0AzeyfY5xEzs2B9GzOba2brgj9bJ3JsqcTMmDSykO37jvDbxe+FXY6I1GMJ\nCxUzSwceA64BegG3mFmvKs1uB3a7ew9gKvBgsP4I8G3gP2J0/QTwVaAgeI0K1k8G5rl7ATAveC+B\nT3Zvyye6ZfP4wvUcPqbZiogkRiJnKoOAEnff4O7HgBnAmCptxgDTg+VZwHAzM3c/6O6LiITLKWbW\nEWjh7m945G6JzwDXxehretR6Cdw3spBdB47yzOubwi5FROqpRIZKZyD6zHBpsC5mG3evAPYC2dX0\nWXqaPtu7+/vB8nagfawOzGyCmRWbWXFZWVlNxlFvFOW14crCHH72ynoOHK0IuxwRqYfq5Yn6YBYT\n894k7j7N3YvcvSgnJ6eOKwvffSML2X3oOL9ctDHsUkSkHqpRqJjZ3WbWwiKeMrO3zGxkNbttBbpE\nvc8N1sVsY2YZQEvgTM/C3Rr0E6vPHcHhsZOHyXTf9xj65rZiRK/2THttA3sPHQ+7HBGpZ2o6U/my\nu+8DRgKtgS8AD1SzzxKgwMzyzawRMA6YXaXNbOC2YHksMN/P8GSp4PDWPjMbHFz19UXgjzH6ui1q\nvVQxaUQh+49U8OSiDWGXIiL1TE1DxYI/rwV+7e4ro9bFFJwjmQjMAVYDM919pZndb2ajg2ZPAdlm\nVgJMIuqKLTPbBEwBxptZadSVY18HngRKgPXAS8H6B4ARZrYOuJrqQ6/B6tmxBZ/u25GnF23kg4PH\nwi5HROoRq8kjZ83sl0ROiOcDFwPpwEJ3H5jY8hKrqKjIi4uLwy4jFCU79zNy6qt8dUg3vnVtz7DL\nEZEUYmZL3b0o1raazlRuJzKLuMTdDwGZwJfiVJ+EoEe75lzXrzPTX9/Ezv1Hqm0vIlITNQ2VTwBr\n3H2PmX0e+B8il/9KCrtreAHHK53HF6wPuxQRqSdqGipPAIfM7GLgPiLnMp5JWFVSJ/LaNmXsgFx+\nu/g93t97OOxyRKQeqGmoVARXZY0BHnX3x4DmiStL6so3hvfAcR6dXxJ2KSJSD9Q0VPab2beIXEr8\nFzNLI3JeRVJcbusmjLukK88v2cKWDw6FXY6IpLiahsrNwFEi31fZTuRLhz9KWFVSpyZe1YP0NOOR\neevCLkVEUlyNQiUIkmeBlmb2GeCIu+ucSj3RvkUWnx98Pi+8VcqGsgNhlyMiKaymt2m5CXgTuBG4\nCVhsZmMTWZjUrTuGdqdxRjo/0WxFRM5BTQ9//TeR76jc5u5fJHJb+28nriypa22bNWb8ZXnMfnsb\na3fsD7scEUlRNQ2VNHePvkFj+VnsKyliwpBuNG2UwdS5a8MuRURSVE2D4W9mNsfMxpvZeOAvwF8T\nV5aEoXXTRnz58nxeWrGdldv03VYROXs1PVH/TWAa0Dd4TXP3/0xkYRKO2y/Pp+V5mZqtiEitZNS0\nobu/ALyQwFokCbQ8L5MJV3TjR3PW8K/3dtO/a+uwSxKRFHLGmYqZ7TezfTFe+81sX10VKXVr/Cfz\naNO0EVM0WxGRs3TGUHH35u7eIsarubu3qKsipW41bZzBHVd257V1u3hz4wdhlyMiKURXcElMnx98\nPjnNG/PQ39dQk2fuiIiAQkVO47xG6Uwc1oPFGz/gn+vLwy5HRFKEQkVOa9ygLnRqmcWPNVsRkRpK\naKiY2SgzW2NmJWY2Ocb2xmb2fLB9sZnlRW37VrB+jZl9Klh3gZkti3rtM7N7gm3fM7OtUduuTeTY\nGoLGGel8Y3gB/3pvDwvXlIVdjoikgISFipmlA48B1wC9gFvMrFeVZrcDu929BzAVeDDYtxcwDugN\njAIeN7N0d1/j7v3cvR8wEDgEvBjV39ST291dX86Mg7EDc+napgkPzdVsRUSql8iZyiCgxN03uPsx\nYAaRh3xFGwNMD5ZnAcPNzIL1M9z9qLtvBEqC/qINB9a7++aEjUDITE/jruEFrNi6jzkrd4Rdjogk\nuUSGSmdgS9T70mBdzDbuXkHkuffZNdx3HPBclXUTzWy5mT1tZjG/tWdmE8ys2MyKy8p0SKcmruvX\niW45TZk6dy0nTmi2IiKnl5In6s2sETAa+F3U6ieA7kA/4H3goVj7uvs0dy9y96KcnJyE11ofZKSn\ncc/VhazZsZ8/v/N+2OWISBJLZKhsBbpEvc8N1sVsY2YZQEsid0Cubt9rgLfc/dTxGHff4e6V7n4C\n+AUfP1wm5+AzF3XkgvbNefjltVRUngi7HBFJUokMlSVAgZnlBzOLccDsKm1mA7cFy2OB+R45Gzwb\nGBdcHZYPFBB5SNhJt1Dl0JeZdYx6ez2wIm4jEdLSjHtHFLKh7CB/WLYt7HJEJEnV+IaSZ8vdK8xs\nIjAHSAeedveVZnY/UOzus4GngF+bWQnwAZHgIWg3E1gFVAB3unslgJk1BUYAX6vyI39oZv0ABzbF\n2C7n6FO929OncwsembeOMf06kZmekkdPRSSBrCFfJlpUVOTFxcVhl5FSFry7ky/9agn/99mLuGVQ\n17DLEZEQmNlSdy+KtU3/1JSzMvSCHPp3bcVP563jaEVl2OWISJJRqMhZMTPuG3EB2/YeYcabW6rf\nQUQaFIWKnLXLemRzaX4bHl1QwuFjmq2IyIcUKnLWzIz7Rl5A2f6j/OYN3dBARD6kUJFaGZTfhiEF\nbXnilfUcPFoRdjkikiQUKlJr9428gA8OHuNX/9wUdikikiQUKlJr/bq0YviF7fj5K+vZe/h42OWI\nSBJQqMg5uXdEIfuOVPDUoo1hlyIiSUChIuekT+eWXNOnA08v2sjug8fCLkdEQqZQkXN274hCDh6r\nYNprG8IuRURCplCRc1bYvjmjL+7Er/6xibL9R8MuR0RCpFCRuLh7eAFHKyr52Svrwy5FREKkUJG4\n6JbTjBsG5PKbNzazfe+RsMsRkZAoVCRu7hpeQOUJ57EFJWGXIiIhUahI3HRp04SbL+nCjCXvUbr7\nUNjliEgIFCoSVxOv6oGZ8dN5mq2INEQKFYmrji3P49ZBXZn1Vimbdh0MuxwRqWMJDRUzG2Vma8ys\nxMwmx9je2MyeD7YvNrO8qG3fCtavMbNPRa3fZGbvmNkyMyuOWt/GzOaa2brgz9aJHJuc3teHdScz\n3Xhk3rqwSxGROpawUDGzdOAx4BqgF3CLmfWq0ux2YLe79wCmAg8G+/Yi8rz63sAo4PGgv5OGuXu/\nKo+znAzMc/cCYF7wXkLQrnkWt30ijxeXbaVk5/6wyxGROpTImcogoMTdN7j7MWAGMKZKmzHA9GB5\nFjDczCxYP8Pdj7r7RqAk6O9MovuaDlwXhzFILX3tyu40yUxn6suarYg0JIkMlc5A9PNmS4N1Mdu4\newWwF8iuZl8H/m5mS81sQlSb9u7+frC8HWgfj0FI7bRp2ogvX57PX5a/z6pt+8IuR0TqSCqeqL/c\n3QcQOax2p5ldUbWBuzuR8PkYM5tgZsVmVlxWVpbgUhu2r1zejeZZGUx9eW3YpYhIHUlkqGwFukS9\nzw3WxWxjZhlAS6D8TPu6+8k/dwIv8uFhsR1m1jHoqyOwM1ZR7j7N3YvcvSgnJ6fWg5PqtWySyYQh\n3Zi7agfLS/eEXY6I1IFEhsoSoMDM8s2sEZET77OrtJkN3BYsjwXmB7OM2cC44OqwfKAAeNPMmppZ\ncwAzawqMBFbE6Os24I8JGpechS9dnk/rJpk89HfNVkQagoSFSnCOZCIwB1gNzHT3lWZ2v5mNDpo9\nBWSbWQkwieCKLXdfCcwEVgF/A+5090oi50kWmdnbwJvAX9z9b0FfDwAjzGwdcHXwXkLWrHEGX7uy\nO6+sLaN40wdhlyMiCWaRiUHDVFRU5MXFxdU3lHNy6FgFV/xwIQXtmvHchMFhlyMi58jMllb5Sscp\nqXiiXlJMk0YZfH1od17fUM4/1+8KuxwRSSCFitSJWy/tSocWWUz5+1oa8uxYpL5TqEidyMpMZ+JV\nPSjevJtX1upSbpH6SqEideamoi7ktj6PKXM1WxGprxQqUmcaZaRx1/AClpfuZe6qHWGXIyIJoFCR\nOvXZ/p3Jb9uUKXPXcuKEZisi9Y1CRepURnoa91xdwLvb9/PSiu1hlyMicaZQkTr3mb6dKGjXjKkv\nr6VSsxWRekWhInUuPc24d0QhJTsPMPvtqreDE5FUplCRUIzq3YFeHVvw8MvrOF55IuxyRCROFCoS\nirQ0Y9KIQjaXH+L3b5WGXY6IxIlCRUIzvGc7Lu7SikfmlXC0ojLsckQkDhQqEhoz474RhWzdc5iZ\nS7ZUv4OIJD2FioRqSEFbLslrzaMLSjhyXLMVkVSnUJFQmRn3jbyAHfuO8uzi98IuR0TOkUJFQje4\nWzaX9cjmiYUlHDpWEXY5InIOFCqSFCaNuIBdB44x/Z+bwy5FRM6BQkWSwsDzWzPsghx+/up69h85\nHnY5IlJLCQ0VMxtlZmvMrMTMJsfY3tjMng+2LzazvKht3wrWrzGzTwXrupjZAjNbZWYrzezuqPbf\nM7OtZrYseF2byLFJ/E0acQF7Dh3n6UWbwi5FRGopYaFiZunAY8A1QC/gFjPrVaXZ7cBud+8BTAUe\nDPbtBYwDegOjgMeD/iqA+17S62UAAAtTSURBVNy9FzAYuLNKn1PdvV/w+muixiaJcVFuSz7Vuz1P\nvraBPYeOhV2OiNRCImcqg4ASd9/g7seAGcCYKm3GANOD5VnAcDOzYP0Mdz/q7huBEmCQu7/v7m8B\nuPt+YDXQOYFjkDp274hCDhyr4BevbQi7FBGphUSGSmcg+httpXw8AE61cfcKYC+QXZN9g0Nl/YHF\nUasnmtlyM3vazFrHKsrMJphZsZkVl5XpsbbJ5sIOLfj0RR355T82UX7gaNjliMhZSskT9WbWDHgB\nuMfd9wWrnwC6A/2A94GHYu3r7tPcvcjdi3JycuqkXjk791xdyJHjlfzslfVhlyIiZymRobIV6BL1\nPjdYF7ONmWUALYHyM+1rZplEAuVZd//9yQbuvsPdK939BPALIoffJAX1aNeM6/p35pnXN7Nz35Gw\nyxGRs5DIUFkCFJhZvpk1InLifXaVNrOB24LlscB8d/dg/bjg6rB8oAB4Mzjf8hSw2t2nRHdkZh2j\n3l4PrIj7iKTO3D28gMoTzuMLNVsRSSUJC5XgHMlEYA6RE+oz3X2lmd1vZqODZk8B2WZWAkwCJgf7\nrgRmAquAvwF3unslcBnwBeCqGJcO/9DM3jGz5cAw4N5EjU0S7/zsptxYlMtvF7/H1j2Hwy5HRGrI\nIhODhqmoqMiLi4vDLkNOY+uewwz70UJuGJjL/332orDLEZGAmS1196JY21LyRL00DJ1bncctg7rw\nu+ItvFd+KOxyRKQGFCqS1O4c1oP0NOMn89aFXYqI1IBCRZJauxZZfPET5/Piv0pZX3Yg7HJEpBoK\nFUl6/35ld7Iy03n4Zc1WRJKdQkWSXnazxoz/ZB5/Xr6Nd7fvq34HEQmNQkVSwoQrutGsUQZT564N\nuxQROQOFiqSEVk0acfuQfOas3MGKrXvDLkdETkOhIinjy5fn06pJJlM0WxFJWgoVSRktsjKZcEU3\n5r+7k6Wbd4ddjojEoFCRlHLbJ/LIbtpI51ZEkpRCRVJK08YZ3DG0O4tKdvHGhvKwyxGRKhQqknI+\nP/h82rdozJS/r6Uh37tOJBkpVCTlZGWmM3FYD97c9AGLSnaFXY6IRFGoSEq66ZIudG51Hj/WbEUk\nqShUJCU1zkjnG1f14O0te5j/7s6wyxGRgEJFUtYNA3M5P7sJU+au5cQJzVZEkoFCRVJWZnoadw8v\nYOW2fcxZuT3sckQEhYqkuDH9OtM9pylTX15LpWYrIqFLaKiY2SgzW2NmJWY2Ocb2xmb2fLB9sZnl\nRW37VrB+jZl9qro+zSw/6KMk6LNRIscmySE9zbh3RCFrdxzgz8u3hV2OSIOXsFAxs3TgMeAaoBdw\ni5n1qtLsdmC3u/cApgIPBvv2AsYBvYFRwONmll5Nnw8CU4O+dgd9SwNwbZ+OXNihOQ+/vI6KyhNh\nlyPSoGUksO9BQIm7bwAwsxnAGGBVVJsxwPeC5VnAo2ZmwfoZ7n4U2GhmJUF/xOrTzFYDVwG3Bm2m\nB/0+kZCRvTQZtr+TkK7l7KUBv808xtoP9vPOD9JIMwu7JJGk1zyvP92+8Gjc+01kqHQGtkS9LwUu\nPV0bd68ws71AdrD+jSr7dg6WY/WZDexx94oY7T/CzCYAEwC6du16diOSpNW6SSYdW2ZxtEIzFZGa\naJSRnpB+ExkqScndpwHTAIqKimp3ZveaB+JZksSBAeeHXYSIJPRE/VagS9T73GBdzDZmlgG0BMrP\nsO/p1pcDrYI+TvezREQkwRIZKkuAguCqrEZETrzPrtJmNnBbsDwWmO+Re27MBsYFV4flAwXAm6fr\nM9hnQdAHQZ9/TODYREQkhoQd/grOkUwE5gDpwNPuvtLM7geK3X028BTw6+BE/AdEQoKg3UwiJ/Ur\ngDvdvRIgVp/Bj/xPYIaZfR/4V9C3iIjUIWvIN+MrKiry4uLisMsQEUkpZrbU3YtibdM36kVEJG4U\nKiIiEjcKFRERiRuFioiIxE2DPlFvZmXA5lru3haoL8+y1ViST30ZB2gsyepcxnK+u+fE2tCgQ+Vc\nmFnx6a5+SDUaS/KpL+MAjSVZJWosOvwlIiJxo1AREZG4UajU3rSwC4gjjSX51JdxgMaSrBIyFp1T\nERGRuNFMRURE4kahIiIicaNQqYaZjTKzNWZWYmaTY2xvbGbPB9sXm1le3VdZMzUYy3gzKzOzZcHr\nK2HUWR0ze9rMdprZitNsNzN7JBjncjMbUNc11lQNxjLUzPZGfSbfqesaa8LMupjZAjNbZWYrzezu\nGG1S4nOp4VhS5XPJMrM3zeztYCz/G6NNfH+Hubtep3kRub3+eqAb0Ah4G+hVpc3XgZ8Fy+OA58Ou\n+xzGMh54NOxaazCWK4ABwIrTbL8WeInIAyEHA4vDrvkcxjIU+HPYddZgHB2BAcFyc2BtjP++UuJz\nqeFYUuVzMaBZsJwJLAYGV2kT199hmqmc2SCgxN03uPsxYAYwpkqbMcD0YHkWMNzMrA5rrKmajCUl\nuPurRJ6/czpjgGc84g0iTwXtWDfVnZ0ajCUluPv77v5WsLwfWA10rtIsJT6XGo4lJQR/1weCt5nB\nq+rVWXH9HaZQObPOwJao96V8/D+uU23cvQLYC2TXSXVnpyZjAbghODQxy8y6xNieCmo61lTxieDw\nxUtm1jvsYqoTHD7pT+RfxdFS7nM5w1ggRT4XM0s3s2XATmCuu5/2c4nH7zCFikT7E5Dn7n2BuXz4\nrxcJz1tE7rN0MfBT4A8h13NGZtYMeAG4x933hV3PuahmLCnzubh7pbv3A3KBQWbWJ5E/T6FyZluB\n6H+t5wbrYrYxswygJVBeJ9WdnWrH4u7l7n40ePskMLCOaou3mnxuKcHd9508fOHufwUyzaxtyGXF\nZGaZRH4JP+vuv4/RJGU+l+rGkkqfy0nuvgdYAIyqsimuv8MUKme2BCgws3wza0TkJNbsKm1mA7cF\ny2OB+R6c8Uoy1Y6lyvHt0USOJaei2cAXg6uNBgN73f39sIuqDTPrcPL4tpkNIvL/bNL9oyWo8Slg\ntbtPOU2zlPhcajKWFPpccsysVbB8HjACeLdKs7j+Dsuo7Y4NgbtXmNlEYA6Rq6eedveVZnY/UOzu\ns4n8x/drMyshcsJ1XHgVn14Nx3KXmY0GKoiMZXxoBZ+BmT1H5OqbtmZWCnyXyAlI3P1nwF+JXGlU\nAhwCvhROpdWrwVjGAneYWQVwGBiXpP9ouQz4AvBOcPwe4L+ArpByn0tNxpIqn0tHYLqZpRMJvpnu\n/udE/g7TbVpERCRudPhLRETiRqEiIiJxo1AREZG4UaiIiEjcKFRERCRuFCoiKSq4U+6fw65DJJpC\nRURE4kahIpJgZvb54JkWy8zs58EN/g6Y2dTgGRfzzCwnaNvPzN4Ibur5opm1Dtb3MLOXgxsYvmVm\n3YPumwU3/3zXzJ5N0jtkSwOiUBFJIDPrCdwMXBbc1K8S+BzQlMg3mnsDrxD5Jj3AM8B/Bjf1fCdq\n/bPAY8ENDD8JnLy9SX/gHqAXkWflXJbwQYmcgW7TIpJYw4ncmHNJMIk4j8gtyE8AzwdtfgP83sxa\nAq3c/ZVg/XTgd2bWHOjs7i8CuPsRgKC/N929NHi/DMgDFiV+WCKxKVREEsuA6e7+rY+sNPt2lXa1\nvV/S0ajlSvT/tIRMh79EEmseMNbM2gGYWRszO5/I/3tjgza3AovcfS+w28yGBOu/ALwSPH2w1Myu\nC/pobGZN6nQUIjWkf9WIJJC7rzKz/wH+bmZpwHHgTuAgkQcm/Q+Rw2E3B7vcBvwsCI0NfHgn3y8A\nPw/uLnscuLEOhyFSY7pLsUgIzOyAuzcLuw6ReNPhLxERiRvNVEREJG40UxERkbhRqIiISNwoVERE\nJG4UKiIiEjcKFRERiZv/D81AwD+wnrTyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJpq28ZhJXaF",
        "colab_type": "code",
        "outputId": "c0090e60-439f-4717-894a-44b57575818a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "print(reverse_source_word_index)\n",
        "print(reverse_target_word_index)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 'obama', 2: 'its', 3: 'official', 4: 'us', 5: 'president', 6: 'barack', 7: 'want', 8: 'lawmaker', 9: 'weigh', 10: 'whether', 11: 'use', 12: 'military', 13: 'force', 14: 'syria', 15: 'sent', 16: 'letter', 17: 'head', 18: 'house', 19: 'senate'}\n",
            "{1: 'obama', 2: 'syrian', 3: 'official', 4: 'climbed', 5: 'top', 6: 'tree', 7: 'doesnt', 8: 'know', 9: 'get'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r1Q7SWH_lGxE",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "biBjzpLQlPhf",
        "outputId": "c753c569-8d54-45ce-c110-b3027d6c21f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "encoder_model.summary()"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 20, 100)      2000        input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) [(None, 20, 512), (N 731136      embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 512)          0           bidirectional_2[0][1]            \n",
            "                                                                 bidirectional_2[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 512)          0           bidirectional_2[0][2]            \n",
            "                                                                 bidirectional_2[0][4]            \n",
            "==================================================================================================\n",
            "Total params: 733,136\n",
            "Trainable params: 731,136\n",
            "Non-trainable params: 2,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAvDUaSWaqYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim*2,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim*2,))\n",
        "decoder_hidden_state_input = Input(shape=(x_voc,latent_dim*2))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_inputs)\n",
        "decoder_states = [state_h2, state_c2]\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c], [decoder_outputs2] + decoder_states)\n",
        "# decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs2] + decoder_states)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wmvKd7pNlQXs",
        "outputId": "4dee784a-b30f-4197-f67e-9bbfe87403c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "decoder_model.summary()"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 20, 100)      2000        input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           (None, 512)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           (None, 512)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, 20, 512), (N 1255424     embedding_4[2][0]                \n",
            "                                                                 input_11[0][0]                   \n",
            "                                                                 input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20, 10)       5130        lstm_4[2][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,262,554\n",
            "Trainable params: 1,260,554\n",
            "Non-trainable params: 2,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ywir6L6wlUE-"
      },
      "source": [
        "### Methods for Reversing Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qoKuk0dElZZm",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jSR-0MHclb0G"
      },
      "source": [
        "### Summarisation Method "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7WYZgAXelbLU",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq): \n",
        "    # Encode the input as state vectors.\n",
        "    print(input_seq)\n",
        "    print(input_seq.shape)\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    print(e_out)\n",
        "    # target = [0,0,0....n] where n = y_voc\n",
        "    target_seq = np.zeros((1, x_voc))\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "      # Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs2] + decoder_states)\n",
        "      # print(target_seq)\n",
        "      output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c]) \n",
        "      print(output_tokens.shape)\n",
        "      print(output_tokens)\n",
        "      print(\"output tokens\")\n",
        "      print(output_tokens[0,-1,:])\n",
        "      print(\"output tokens\")\n",
        "      print(output_tokens[0,-1,:][1:])\n",
        "      sampled_token_index = np.argmax(output_tokens[0, -1, :][1:])\n",
        "      print(sampled_token_index)\n",
        "      if (sampled_token_index != 0 ):\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        # print(sampled_token)\n",
        "        decoded_sentence += ' '+sampled_token\n",
        "      else :\n",
        "        print(\"sadface\")\n",
        "        stop_condition = True\n",
        "      if (len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "              stop_condition = True\n",
        "       # Update the target sequence (of length 1).\n",
        "      # target_seq = np.zeros((1,1))\n",
        "      # target_seq = np.zeros((1, x_voc))\n",
        "      target_seq[0, sampled_token_index] = 1\n",
        "\n",
        "      # Update internal states\n",
        "      e_h, e_c = h, c\n",
        "      \n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "STnQkiZzlhbb"
      },
      "source": [
        "## Test Model Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d_RFVVqxfmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getRouge(gt, pred):\n",
        "  return rouge.get_scores(pred, gt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IC1oCOOHlgjh",
        "outputId": "b977feea-589c-49e6-b1ba-aca4a78734c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(0,1):\n",
        "    print(\"Article:\",seq2text(x_tr[i]))\n",
        "    original = seq2summary(y_tr[i])\n",
        "    print(\"Original summary:\",original)\n",
        "    x_tr_i_reshaped = x_tr[i].reshape(1,x_voc)\n",
        "    summary = decode_sequence(x_tr_i_reshaped)\n",
        "    print(\"Generated summary:\",summary)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    if summary != \"\":    \n",
        "      print(\"ROUGE score: \")\n",
        "      score = getRouge(str(summary), str(original))\n",
        "      print(score)\n",
        "      print(score[0].get('rouge-1').get('f'))\n",
        "      print(score[0].get('rouge-1').get('p'))\n",
        "      print(score[0].get('rouge-1').get('r'))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article: its official us president barack obama want lawmaker weigh whether use military force syria obama sent letter head house \n",
            "Original summary: syrian official obama climbed top tree doesnt know obama \n",
            "[[ 2  3  4  5  6  1  7  8  9 10 11 12 13 14  1 15 16 17 18  0]]\n",
            "(1, 20)\n",
            "[[[ 4.1656800e-02  1.0902033e-02 -7.2615750e-02 ...  7.7172351e-01\n",
            "   -6.7435265e-01  1.5189697e-01]\n",
            "  [ 1.3945213e-01 -4.5042783e-02  2.5325678e-02 ...  7.7451581e-01\n",
            "   -6.7368346e-01  5.3700652e-02]\n",
            "  [ 2.9121146e-01 -1.1370844e-01  6.8969657e-03 ...  8.2819051e-01\n",
            "   -5.6722373e-01  8.5950434e-02]\n",
            "  ...\n",
            "  [ 9.3707448e-01 -7.0112735e-01 -1.4408523e-01 ...  6.7345262e-02\n",
            "    4.8367284e-02 -2.2426569e-01]\n",
            "  [ 9.0694654e-01 -7.1426046e-01 -1.9990830e-01 ...  5.1457468e-02\n",
            "    2.3265777e-02 -1.7249219e-01]\n",
            "  [ 8.6897141e-01 -6.1195588e-01 -2.3943530e-01 ...  8.9212495e-04\n",
            "   -1.0112840e-03  6.5416803e-05]]]\n",
            "(1, 20, 10)\n",
            "[[[6.26644917e-11 1.31391458e-08 9.99999046e-01 1.01045975e-06\n",
            "   1.29495803e-09 1.31506903e-10 6.05223760e-10 6.85315360e-10\n",
            "   4.87376972e-10 2.27523538e-11]\n",
            "  [3.98337974e-10 5.31076057e-06 4.14799142e-05 9.99952674e-01\n",
            "   4.56986726e-07 4.71908246e-09 1.76178965e-08 3.97376922e-08\n",
            "   4.50566029e-09 8.51994086e-10]\n",
            "  [6.40770681e-09 9.95041966e-01 3.68149881e-06 4.26568231e-03\n",
            "   6.82630169e-04 2.95839027e-06 3.29732586e-07 2.67264727e-06\n",
            "   8.85388758e-08 5.40347465e-08]\n",
            "  [4.51802329e-09 3.08334408e-03 1.16452803e-07 1.40781121e-05\n",
            "   9.96711016e-01 1.89282524e-04 9.48652257e-07 1.11235988e-06\n",
            "   6.24225791e-08 6.31374419e-08]\n",
            "  [1.13674030e-08 4.46298691e-05 4.94914580e-08 1.19337562e-06\n",
            "   8.05093255e-03 9.91838396e-01 5.70296907e-05 7.64928518e-06\n",
            "   6.40162980e-08 9.75744783e-08]\n",
            "  [3.38663256e-07 1.45390532e-05 4.06204521e-07 5.20450749e-06\n",
            "   5.61688677e-04 1.94012284e-01 8.01086843e-01 4.31263540e-03\n",
            "   5.44813702e-06 5.94472340e-07]\n",
            "  [3.16818557e-07 1.58329533e-06 8.23762818e-08 3.60964123e-07\n",
            "   3.31330762e-06 3.24825742e-05 3.65918106e-03 9.96180892e-01\n",
            "   1.21822384e-04 4.34517524e-08]\n",
            "  [1.39680897e-05 7.58406677e-05 6.59130023e-07 5.04109437e-07\n",
            "   3.05941739e-06 5.93848745e-06 5.24534953e-05 1.28672108e-01\n",
            "   8.71175230e-01 1.77904610e-07]\n",
            "  [1.75498892e-02 9.98656452e-02 5.51744233e-06 8.91495745e-07\n",
            "   9.57235989e-06 1.87226542e-05 3.19637875e-05 2.63155950e-03\n",
            "   8.79883587e-01 2.57759939e-06]\n",
            "  [9.99924421e-01 6.35046454e-05 1.03043071e-07 8.46949355e-09\n",
            "   9.84337802e-08 1.11459272e-07 1.87724567e-07 1.56902627e-06\n",
            "   9.99836902e-06 4.72340886e-08]\n",
            "  [9.99999881e-01 7.32516412e-08 5.94292171e-09 4.88846463e-10\n",
            "   3.71044062e-09 3.48956752e-09 4.74248596e-09 1.64039253e-08\n",
            "   2.84045978e-08 2.59013189e-09]\n",
            "  [1.00000000e+00 1.89261975e-08 5.22753263e-09 4.75013417e-10\n",
            "   2.84408541e-09 2.46554199e-09 2.82958967e-09 7.53485807e-09\n",
            "   9.98600669e-09 2.27605179e-09]\n",
            "  [1.00000000e+00 1.16177805e-08 5.66444136e-09 5.42143053e-10\n",
            "   2.83749113e-09 2.22793717e-09 2.42420328e-09 5.57381474e-09\n",
            "   7.11589498e-09 2.35604936e-09]\n",
            "  [1.00000000e+00 9.00590802e-09 6.26054852e-09 6.28021968e-10\n",
            "   3.01254799e-09 2.11998863e-09 2.26185692e-09 4.48635529e-09\n",
            "   6.10685102e-09 2.50963827e-09]\n",
            "  [1.00000000e+00 8.00357647e-09 7.23614724e-09 7.71183228e-10\n",
            "   3.43108653e-09 2.17514007e-09 2.31590147e-09 3.96500610e-09\n",
            "   5.86948579e-09 2.84072410e-09]\n",
            "  [1.00000000e+00 7.84247334e-09 8.74851036e-09 9.96440708e-10\n",
            "   4.09958600e-09 2.38219000e-09 2.54371435e-09 3.85902821e-09\n",
            "   6.06130346e-09 3.40916784e-09]\n",
            "  [1.00000000e+00 8.24690272e-09 1.09372555e-08 1.32700406e-09\n",
            "   5.02196951e-09 2.72541789e-09 2.92317170e-09 4.06113188e-09\n",
            "   6.53369980e-09 4.26199254e-09]\n",
            "  [1.00000000e+00 9.12291931e-09 1.39839216e-08 1.79589554e-09\n",
            "   6.23660501e-09 3.20175575e-09 3.46258378e-09 4.51807658e-09\n",
            "   7.23431182e-09 5.46121415e-09]\n",
            "  [1.00000000e+00 1.04873852e-08 1.81636928e-08 2.45686205e-09\n",
            "   7.82852982e-09 3.83272347e-09 4.19542046e-09 5.22358556e-09\n",
            "   8.17649948e-09 7.10878645e-09]\n",
            "  [1.00000000e+00 1.24344970e-08 2.38753604e-08 3.39530049e-09\n",
            "   9.92066251e-09 4.66818673e-09 5.17241761e-09 6.20092599e-09\n",
            "   9.42152845e-09 9.35820044e-09]]]\n",
            "output tokens\n",
            "[1.0000000e+00 1.2434497e-08 2.3875360e-08 3.3953005e-09 9.9206625e-09\n",
            " 4.6681867e-09 5.1724176e-09 6.2009260e-09 9.4215284e-09 9.3582004e-09]\n",
            "output tokens\n",
            "[1.2434497e-08 2.3875360e-08 3.3953005e-09 9.9206625e-09 4.6681867e-09\n",
            " 5.1724176e-09 6.2009260e-09 9.4215284e-09 9.3582004e-09]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[1.00000000e+00 1.51134483e-08 3.16505933e-08 4.73668305e-09\n",
            "   1.26642528e-08 5.78309667e-09 6.45730847e-09 7.49173790e-09\n",
            "   1.10538396e-08 1.24172184e-08]\n",
            "  [9.99999046e-01 8.85116322e-07 4.41120811e-08 8.97999897e-09\n",
            "   2.14485461e-08 3.18372244e-08 1.63295208e-08 1.25593127e-08\n",
            "   5.54859669e-09 5.24851096e-08]\n",
            "  [1.00000000e+00 3.54863552e-08 3.12234363e-08 5.45257528e-09\n",
            "   1.54243551e-08 1.00678035e-08 1.14310339e-08 8.67774741e-09\n",
            "   9.03355524e-09 1.64327378e-08]\n",
            "  [1.00000000e+00 2.72716658e-08 3.47013582e-08 5.48128165e-09\n",
            "   1.55598059e-08 8.38321412e-09 8.68567973e-09 8.62078320e-09\n",
            "   9.73393988e-09 1.61539528e-08]\n",
            "  [1.00000000e+00 2.77124421e-08 4.71669850e-08 7.54570184e-09\n",
            "   1.99250323e-08 9.98311300e-09 1.02427062e-08 1.05144240e-08\n",
            "   1.27156863e-08 2.09990390e-08]\n",
            "  [9.99999762e-01 3.22322080e-08 6.54577548e-08 1.08559481e-08\n",
            "   2.60067239e-08 1.24887105e-08 1.28063968e-08 1.32052058e-08\n",
            "   1.65347576e-08 2.81340284e-08]\n",
            "  [9.99999762e-01 3.93052844e-08 9.01944048e-08 1.56595110e-08\n",
            "   3.38800419e-08 1.58762283e-08 1.62902740e-08 1.65271263e-08\n",
            "   2.11415010e-08 3.76806781e-08]\n",
            "  [9.99999642e-01 4.90843455e-08 1.23299699e-07 2.24994707e-08\n",
            "   4.40906618e-08 2.03385628e-08 2.08817266e-08 2.06188133e-08\n",
            "   2.67426437e-08 5.02065802e-08]\n",
            "  [9.99999404e-01 6.20920986e-08 1.67334164e-07 3.21298721e-08\n",
            "   5.73724890e-08 2.61801585e-08 2.68875855e-08 2.56714383e-08\n",
            "   3.36154109e-08 6.65136497e-08]\n",
            "  [9.99999404e-01 7.91247388e-08 2.25611231e-07 4.55747404e-08\n",
            "   7.46842517e-08 3.38076021e-08 3.47213316e-08 3.19291296e-08\n",
            "   4.20999307e-08 8.76427677e-08]\n",
            "  [9.99999166e-01 1.01248013e-07 3.02367312e-07 6.42134452e-08\n",
            "   9.72682841e-08 4.37511147e-08 4.49239899e-08 3.97003710e-08\n",
            "   5.26109005e-08 1.14924070e-07]\n",
            "  [9.99998927e-01 1.29837346e-07 4.02987382e-07 8.98970285e-08\n",
            "   1.26733312e-07 5.66988589e-08 5.81977453e-08 4.93765278e-08\n",
            "   6.56572610e-08 1.50052244e-07]\n",
            "  [9.99998569e-01 1.66641740e-07 5.34282435e-07 1.25104918e-07\n",
            "   1.65162433e-07 7.35417416e-08 7.54513394e-08 6.14561557e-08\n",
            "   8.18669790e-08 1.95183787e-07]\n",
            "  [9.99998093e-01 2.13867892e-07 7.04827471e-07 1.73153069e-07\n",
            "   2.15250296e-07 9.54345225e-08 9.78595622e-08 7.65750485e-08\n",
            "   1.02017871e-07 2.53063661e-07]\n",
            "  [9.99997497e-01 2.74289221e-07 9.25370330e-07 2.38469596e-07\n",
            "   2.80477138e-07 1.23874827e-07 1.26939497e-07 9.55461132e-08\n",
            "   1.27076476e-07 3.27186939e-07]\n",
            "  [9.99996662e-01 3.51384472e-07 1.20934396e-06 3.26964880e-07\n",
            "   3.65334984e-07 1.60810487e-07 1.64650842e-07 1.19411013e-07\n",
            "   1.58248213e-07 4.22011340e-07]\n",
            "  [9.99995708e-01 4.49511163e-07 1.57348688e-06 4.46515230e-07\n",
            "   4.75616787e-07 2.08779923e-07 2.13526036e-07 1.49508395e-07\n",
            "   1.97040592e-07 5.43230954e-07]\n",
            "  [9.99994516e-01 5.74121941e-07 2.03860736e-06 6.07595950e-07\n",
            "   6.18783702e-07 2.71098514e-07 2.76834072e-07 1.87561625e-07\n",
            "   2.45341880e-07 6.98122562e-07]\n",
            "  [9.99992847e-01 7.32038075e-07 2.63054494e-06 8.24109691e-07\n",
            "   8.04439821e-07 3.52105673e-07 3.58799781e-07 2.35794559e-07\n",
            "   3.05525788e-07 8.95995356e-07]\n",
            "  [9.99990702e-01 9.31779027e-07 3.38135987e-06 1.11444388e-06\n",
            "   1.04493222e-06 4.57483765e-07 4.64875114e-07 2.97079765e-07\n",
            "   3.80581128e-07 1.14874706e-06]]]\n",
            "output tokens\n",
            "[9.9999070e-01 9.3177903e-07 3.3813599e-06 1.1144439e-06 1.0449322e-06\n",
            " 4.5748376e-07 4.6487511e-07 2.9707977e-07 3.8058113e-07 1.1487471e-06]\n",
            "output tokens\n",
            "[9.3177903e-07 3.3813599e-06 1.1144439e-06 1.0449322e-06 4.5748376e-07\n",
            " 4.6487511e-07 2.9707977e-07 3.8058113e-07 1.1487471e-06]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[9.99988079e-01 1.18395974e-06 4.33071546e-06 1.50279686e-06\n",
            "   1.35609798e-06 5.94667824e-07 6.02088619e-07 3.75126376e-07\n",
            "   4.74270649e-07 1.47154765e-06]\n",
            "  [9.99934435e-01 5.06871074e-05 3.56409896e-06 1.37420045e-06\n",
            "   1.88392266e-06 2.60260663e-06 1.07962148e-06 5.65285632e-07\n",
            "   2.34414244e-07 3.66767085e-06]\n",
            "  [9.99989510e-01 2.68456074e-06 2.32122306e-06 8.49631419e-07\n",
            "   1.17976970e-06 8.45538864e-07 6.75310218e-07 3.26234954e-07\n",
            "   2.84414511e-07 1.26584814e-06]\n",
            "  [9.99991536e-01 1.53353869e-06 2.35197399e-06 7.50889171e-07\n",
            "   1.07608639e-06 6.28508872e-07 5.32341858e-07 3.09839294e-07\n",
            "   2.87537233e-07 1.06752805e-06]\n",
            "  [9.99990702e-01 1.26008990e-06 2.78153152e-06 8.58694762e-07\n",
            "   1.16060789e-06 6.25473206e-07 5.60312344e-07 3.44852623e-07\n",
            "   3.44022880e-07 1.15485886e-06]\n",
            "  [9.99989271e-01 1.26377313e-06 3.43908414e-06 1.06932498e-06\n",
            "   1.32795026e-06 6.82945313e-07 6.36173240e-07 4.02145389e-07\n",
            "   4.20908520e-07 1.34909658e-06]\n",
            "  [9.99987125e-01 1.39866358e-06 4.32468596e-06 1.38765472e-06\n",
            "   1.57397164e-06 7.87217346e-07 7.52831113e-07 4.79473272e-07\n",
            "   5.17863498e-07 1.63534685e-06]\n",
            "  [9.99984145e-01 1.63580216e-06 5.47935861e-06 1.84078567e-06\n",
            "   1.91361232e-06 9.39940151e-07 9.13927749e-07 5.80260576e-07\n",
            "   6.38710503e-07 2.02305750e-06]\n",
            "  [9.99979854e-01 1.97557620e-06 6.96239704e-06 2.46973650e-06\n",
            "   2.37076392e-06 1.15045486e-06 1.12888324e-06 7.10225322e-07\n",
            "   7.89291732e-07 2.53310759e-06]\n",
            "  [9.99974608e-01 2.43183308e-06 8.85105328e-06 3.33040111e-06\n",
            "   2.97851557e-06 1.43383238e-06 1.41173211e-06 8.77281025e-07\n",
            "   9.77374725e-07 3.19556307e-06]\n",
            "  [9.99967575e-01 3.02743956e-06 1.12425123e-05 4.49643630e-06\n",
            "   3.78065283e-06 1.81122505e-06 1.78156210e-06 1.09191853e-06\n",
            "   1.21295750e-06 4.05021956e-06]\n",
            "  [9.99958515e-01 3.79345056e-06 1.42573781e-05 6.06350113e-06\n",
            "   4.83403710e-06 2.31108311e-06 2.26358793e-06 1.36787503e-06\n",
            "   1.50880089e-06 5.14830890e-06]\n",
            "  [9.99946713e-01 4.76979085e-06 1.80445913e-05 8.15479416e-06\n",
            "   6.21180880e-06 2.97104816e-06 2.89073841e-06 1.72307284e-06\n",
            "   1.88117735e-06 6.55507392e-06]\n",
            "  [9.99931812e-01 6.00666044e-06 2.27872024e-05 1.09279572e-05\n",
            "   8.00734870e-06 3.84044779e-06 3.70570956e-06 2.18081482e-06\n",
            "   2.35081325e-06 8.35304854e-06]\n",
            "  [9.99912739e-01 7.56680993e-06 2.87103358e-05 1.45840313e-05\n",
            "   1.03394859e-05 4.98364398e-06 4.76374225e-06 2.77144386e-06\n",
            "   2.94419419e-06 1.06464049e-05]\n",
            "  [9.99888182e-01 9.52840037e-06 3.60902195e-05 1.93782234e-05\n",
            "   1.33586564e-05 6.48419154e-06 6.13606562e-06 3.53438190e-06\n",
            "   3.69515533e-06 1.35662549e-05]\n",
            "  [9.99856949e-01 1.19887591e-05 4.52659078e-05 2.56337935e-05\n",
            "   1.72548589e-05 8.45022623e-06 7.91432012e-06 4.52085078e-06\n",
            "   4.64697951e-06 1.72773671e-05]\n",
            "  [9.99817312e-01 1.50693068e-05 5.66535746e-05 3.37589408e-05\n",
            "   2.22673807e-05 1.10212395e-05 1.02162294e-05 5.79734888e-06\n",
            "   5.85508405e-06 2.19865815e-05]\n",
            "  [9.99766886e-01 1.89214552e-05 7.07633080e-05 4.42677665e-05\n",
            "   2.86966479e-05 1.43765747e-05 1.31926618e-05 7.45006582e-06\n",
            "   7.39042571e-06 2.79530595e-05]\n",
            "  [9.99703109e-01 2.37343411e-05 8.82203676e-05 5.78057006e-05\n",
            "   3.69190202e-05 1.87461756e-05 1.70365493e-05 9.59058343e-06\n",
            "   9.34388027e-06 3.55011543e-05]]]\n",
            "output tokens\n",
            "[9.9970311e-01 2.3734341e-05 8.8220368e-05 5.7805701e-05 3.6919020e-05\n",
            " 1.8746176e-05 1.7036549e-05 9.5905834e-06 9.3438803e-06 3.5501154e-05]\n",
            "output tokens\n",
            "[2.3734341e-05 8.8220368e-05 5.7805701e-05 3.6919020e-05 1.8746176e-05\n",
            " 1.7036549e-05 9.5905834e-06 9.3438803e-06 3.5501154e-05]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[9.99622226e-01 2.97442530e-05 1.09789420e-04 7.51805419e-05\n",
            "   4.74046574e-05 2.44236853e-05 2.19940794e-05 1.23631062e-05\n",
            "   1.18316948e-05 4.50359221e-05]\n",
            "  [9.98156726e-01 1.41491042e-03 7.32292901e-05 4.63980105e-05\n",
            "   5.43780407e-05 1.06182510e-04 3.26041663e-05 1.79113449e-05\n",
            "   6.18074000e-06 9.15335550e-05]\n",
            "  [9.99749124e-01 6.10852876e-05 4.16990733e-05 2.55155483e-05\n",
            "   3.19147366e-05 2.89541003e-05 1.82457861e-05 8.36296749e-06\n",
            "   5.33196089e-06 2.96630678e-05]\n",
            "  [9.99818385e-01 2.73585465e-05 3.94284034e-05 2.08900419e-05\n",
            "   2.55741052e-05 1.90418341e-05 1.40464608e-05 7.57166072e-06\n",
            "   5.10287873e-06 2.25868735e-05]\n",
            "  [9.99829412e-01 1.91541494e-05 4.27004888e-05 2.12641171e-05\n",
            "   2.34637246e-05 1.59831470e-05 1.30526560e-05 7.64381093e-06\n",
            "   5.61109937e-06 2.15437249e-05]\n",
            "  [9.99821126e-01 1.72092132e-05 4.88498918e-05 2.39751844e-05\n",
            "   2.34711151e-05 1.51108388e-05 1.31310417e-05 8.10484198e-06\n",
            "   6.38255960e-06 2.27031887e-05]\n",
            "  [9.99799907e-01 1.76730464e-05 5.75036465e-05 2.87187049e-05\n",
            "   2.50954545e-05 1.55172438e-05 1.39866515e-05 8.88008435e-06\n",
            "   7.38209701e-06 2.53470680e-05]\n",
            "  [9.99767005e-01 1.96099572e-05 6.88528889e-05 3.57261633e-05\n",
            "   2.82774945e-05 1.69455325e-05 1.55758898e-05 1.00008865e-05\n",
            "   8.64417325e-06 2.93747635e-05]\n",
            "  [9.99721110e-01 2.28010267e-05 8.33500526e-05 4.55060654e-05\n",
            "   3.31873271e-05 1.94025197e-05 1.79777999e-05 1.15427292e-05\n",
            "   1.02394160e-05 3.49338952e-05]\n",
            "  [9.99659538e-01 2.72959569e-05 1.01650243e-04 5.87960385e-05\n",
            "   4.01746074e-05 2.30467194e-05 2.13585390e-05 1.36179515e-05\n",
            "   1.22677629e-05 4.23259808e-05]\n",
            "  [9.99578536e-01 3.32883938e-05 1.24605445e-04 7.65686636e-05\n",
            "   4.97590809e-05 2.81615357e-05 2.59697390e-05 1.63805653e-05\n",
            "   1.48609633e-05 5.19865353e-05]\n",
            "  [9.99472916e-01 4.10806824e-05 1.53282526e-04 1.00059806e-04\n",
            "   6.26410401e-05 3.51588860e-05 3.21598345e-05 2.00368067e-05\n",
            "   1.81898304e-05 6.44918691e-05]\n",
            "  [9.99336421e-01 5.10806931e-05 1.88996317e-04 1.30809844e-04\n",
            "   7.97239700e-05 4.45972437e-05 4.03933227e-05 2.48597225e-05\n",
            "   2.24751093e-05 8.05793097e-05]\n",
            "  [9.99161124e-01 6.38126949e-05 2.33350627e-04 1.70714484e-04\n",
            "   1.02142825e-04 5.72086428e-05 5.12762126e-05 3.12077391e-05\n",
            "   2.80013901e-05 1.01176149e-04]\n",
            "  [9.98936832e-01 7.99391710e-05 2.88294017e-04 2.22087576e-04\n",
            "   1.31302135e-04 7.39338357e-05 6.55885742e-05 3.95483112e-05\n",
            "   3.51354684e-05 1.27437757e-04]\n",
            "  [9.98651087e-01 1.00287900e-04 3.56178614e-04 2.87729024e-04\n",
            "   1.68915838e-04 9.59613171e-05 8.43214584e-05 5.04860036e-05\n",
            "   4.43478821e-05 1.60790194e-04]\n",
            "  [9.98288810e-01 1.25888502e-04 4.39831609e-04 3.71007598e-04\n",
            "   2.17058507e-04 1.24774539e-04 1.08721477e-04 6.47970373e-05\n",
            "   5.62401292e-05 2.02983472e-04]\n",
            "  [9.97831523e-01 1.58015784e-04 5.42635971e-04 4.75953828e-04\n",
            "   2.78224674e-04 1.62204538e-04 1.40342745e-04 8.34705788e-05\n",
            "   7.15775823e-05 2.56153260e-04]\n",
            "  [9.97256815e-01 1.98242502e-04 6.68622903e-04 6.07367023e-04\n",
            "   3.55401775e-04 2.10492202e-04 1.81106909e-04 1.07758118e-04\n",
            "   9.13294498e-05 3.22893378e-04]\n",
            "  [9.96537805e-01 2.48500757e-04 8.22570233e-04 7.70936138e-04\n",
            "   4.52156586e-04 2.72358855e-04 2.33373619e-04 1.39231270e-04\n",
            "   1.16716685e-04 4.06339648e-04]]]\n",
            "output tokens\n",
            "[9.96537805e-01 2.48500757e-04 8.22570233e-04 7.70936138e-04\n",
            " 4.52156586e-04 2.72358855e-04 2.33373619e-04 1.39231270e-04\n",
            " 1.16716685e-04 4.06339648e-04]\n",
            "output tokens\n",
            "[0.0002485  0.00082257 0.00077094 0.00045216 0.00027236 0.00023337\n",
            " 0.00013923 0.00011672 0.00040634]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[9.95641947e-01 3.11156939e-04 1.01012085e-03 9.73381393e-04\n",
            "   5.72744699e-04 3.51094990e-04 3.00025335e-04 1.79851588e-04\n",
            "   1.49270083e-04 5.10271755e-04]\n",
            "  [9.78024244e-01 1.70026626e-02 6.24195382e-04 4.90298087e-04\n",
            "   5.97998151e-04 1.58018142e-03 4.07509069e-04 2.48705241e-04\n",
            "   8.40210196e-05 9.40274156e-04]\n",
            "  [9.97452080e-01 6.08073431e-04 3.19656450e-04 2.43541333e-04\n",
            "   3.36964149e-04 3.74047348e-04 2.17897832e-04 1.03063096e-04\n",
            "   5.59808577e-05 2.88653682e-04]\n",
            "  [9.98334587e-01 2.27781900e-04 2.87028146e-04 1.90592982e-04\n",
            "   2.39578658e-04 2.19303402e-04 1.59274496e-04 8.90115916e-05\n",
            "   5.06558863e-05 2.02286450e-04]\n",
            "  [9.98585105e-01 1.43171157e-04 2.93439429e-04 1.80827265e-04\n",
            "   1.93740139e-04 1.60427138e-04 1.32487097e-04 8.26919349e-05\n",
            "   5.18995148e-05 1.76188871e-04]\n",
            "  [9.98634040e-01 1.19546472e-04 3.18489765e-04 1.91308383e-04\n",
            "   1.74949600e-04 1.34848960e-04 1.19579541e-04 8.01945207e-05\n",
            "   5.51511657e-05 1.71945925e-04]\n",
            "  [9.98571634e-01 1.16605413e-04 3.57801619e-04 2.17409892e-04\n",
            "   1.73432316e-04 1.26158091e-04 1.16068542e-04 8.07856195e-05\n",
            "   5.98420811e-05 1.80310977e-04]\n",
            "  [9.98420715e-01 1.24605751e-04 4.11339628e-04 2.59422726e-04\n",
            "   1.85493540e-04 1.28559943e-04 1.20141813e-04 8.46234034e-05\n",
            "   6.62084203e-05 1.98851456e-04]\n",
            "  [9.98181105e-01 1.40916381e-04 4.81024326e-04 3.19973711e-04\n",
            "   2.10593076e-04 1.40288306e-04 1.31421184e-04 9.21576138e-05\n",
            "   7.48127859e-05 2.27668919e-04]\n",
            "  [9.97840285e-01 1.65326957e-04 5.70021337e-04 4.03303304e-04\n",
            "   2.50153680e-04 1.61584830e-04 1.50520151e-04 1.04099323e-04\n",
            "   8.64162575e-05 2.68200733e-04]\n",
            "  [9.97377276e-01 1.98781418e-04 6.82535465e-04 5.15055726e-04\n",
            "   3.07065842e-04 1.94023742e-04 1.78899107e-04 1.21494224e-04\n",
            "   1.01990227e-04 3.22861859e-04]\n",
            "  [9.96762753e-01 2.42992217e-04 8.23789975e-04 6.62224600e-04\n",
            "   3.85493680e-04 2.40301946e-04 2.18848756e-04 1.45815298e-04\n",
            "   1.22781057e-04 3.94963718e-04]\n",
            "  [9.95959699e-01 3.00342159e-04 1.00008608e-03 8.53140256e-04\n",
            "   4.90793609e-04 3.04206973e-04 2.73542653e-04 1.79065799e-04\n",
            "   1.50397158e-04 4.88735852e-04]\n",
            "  [9.94922340e-01 3.73899238e-04 1.21889368e-03 1.09746063e-03\n",
            "   6.29465387e-04 3.90646805e-04 3.47118417e-04 2.23894211e-04\n",
            "   1.86911566e-04 6.09392824e-04]\n",
            "  [9.93596077e-01 4.67475387e-04 1.48892577e-03 1.40612852e-03\n",
            "   8.09091958e-04 5.05676493e-04 4.44758916e-04 2.83710455e-04\n",
            "   2.34969499e-04 7.63199991e-04]\n",
            "  [9.91916955e-01 5.85715577e-04 1.82021991e-03 1.79132505e-03\n",
            "   1.03827554e-03 6.56500750e-04 5.72757330e-04 3.62807157e-04\n",
            "   2.97904568e-04 9.57548385e-04]\n",
            "  [9.89811301e-01 7.34189758e-04 2.22417922e-03 2.26641330e-03\n",
            "   1.32657739e-03 8.51437508e-04 7.38551142e-04 4.66465630e-04\n",
            "   3.79853358e-04 1.20101019e-03]\n",
            "  [9.87195492e-01 9.19497514e-04 2.71360832e-03 2.84591154e-03\n",
            "   1.68450421e-03 1.09986647e-03 9.50735644e-04 6.01052714e-04\n",
            "   4.85869212e-04 1.50340598e-03]\n",
            "  [9.83975649e-01 1.14936358e-03 3.30271432e-03 3.54549219e-03\n",
            "   2.12354353e-03 1.41217967e-03 1.21905887e-03 7.74092914e-04\n",
            "   6.22023945e-04 1.87585596e-03]\n",
            "  [9.80046928e-01 1.43273582e-03 4.00709826e-03 4.38204641e-03\n",
            "   2.65628169e-03 1.79977599e-03 1.55443186e-03 9.94331669e-04\n",
            "   7.95506756e-04 2.33084988e-03]]]\n",
            "output tokens\n",
            "[9.8004693e-01 1.4327358e-03 4.0070983e-03 4.3820464e-03 2.6562817e-03\n",
            " 1.7997760e-03 1.5544319e-03 9.9433167e-04 7.9550676e-04 2.3308499e-03]\n",
            "output tokens\n",
            "[0.00143274 0.0040071  0.00438205 0.00265628 0.00179978 0.00155443\n",
            " 0.00099433 0.00079551 0.00233085]\n",
            "2\n",
            "(1, 20, 10)\n",
            "[[[9.75293219e-01 1.77987013e-03 4.84370347e-03 5.37374569e-03\n",
            "   3.29656852e-03 2.27511697e-03 1.96896843e-03 1.27178722e-03\n",
            "   1.01470656e-03 2.88230646e-03]\n",
            "  [8.76401722e-01 9.69402641e-02 2.67030858e-03 2.26975116e-03\n",
            "   3.06623988e-03 9.56054404e-03 2.37419247e-03 1.56143052e-03\n",
            "   5.59632841e-04 4.59586736e-03]\n",
            "  [7.46699870e-01 2.37140983e-01 6.82983606e-04 4.21728735e-04\n",
            "   1.35215162e-03 9.37624276e-03 1.25582900e-03 7.06566556e-04\n",
            "   1.51028362e-04 2.21259031e-03]\n",
            "  [9.96404171e-01 1.21241540e-03 2.13169929e-04 1.14197326e-04\n",
            "   3.90597677e-04 7.39533745e-04 3.93239956e-04 1.69356354e-04\n",
            "   5.51500088e-05 3.08236660e-04]\n",
            "  [9.98838484e-01 1.90360850e-04 1.47665211e-04 6.27953050e-05\n",
            "   1.46847873e-04 1.97592788e-04 1.54375477e-04 9.49021196e-05\n",
            "   3.73808580e-05 1.29595152e-04]\n",
            "  [9.99337137e-01 7.66638550e-05 1.26849802e-04 4.75492197e-05\n",
            "   7.84196382e-05 8.41100118e-05 7.80254559e-05 5.91285752e-05\n",
            "   3.00564025e-05 8.18670524e-05]\n",
            "  [9.99497533e-01 4.96034409e-05 1.22094585e-04 4.44277830e-05\n",
            "   5.48466560e-05 4.96492503e-05 4.95396162e-05 4.14316310e-05\n",
            "   2.58766377e-05 6.48860805e-05]\n",
            "  [9.99547541e-01 4.12890950e-05 1.26075014e-04 4.76451678e-05\n",
            "   4.66952515e-05 3.70960443e-05 3.80429592e-05 3.26080844e-05\n",
            "   2.35875759e-05 5.93218938e-05]\n",
            "  [9.99543726e-01 3.98557131e-05 1.36732473e-04 5.59209657e-05\n",
            "   4.58468385e-05 3.29022187e-05 3.38817372e-05 2.85484548e-05\n",
            "   2.27727523e-05 5.98281695e-05]\n",
            "  [9.99502182e-01 4.22558442e-05 1.53821660e-04 6.95447670e-05\n",
            "   4.98856971e-05 3.30874100e-05 3.37681049e-05 2.73924416e-05\n",
            "   2.32381972e-05 6.47517445e-05]\n",
            "  [9.99426365e-01 4.76564273e-05 1.77929440e-04 8.96045603e-05\n",
            "   5.83801921e-05 3.64706248e-05 3.66081294e-05 2.83486315e-05\n",
            "   2.49276527e-05 7.37756927e-05]\n",
            "  [9.99312639e-01 5.60084191e-05 2.10175931e-04 1.17762167e-04\n",
            "   7.18280935e-05 4.29565771e-05 4.22310295e-05 3.11772746e-05\n",
            "   2.79101841e-05 8.72409219e-05]\n",
            "  [9.99154449e-01 6.76495692e-05 2.52134661e-04 1.56198585e-04\n",
            "   9.13236508e-05 5.30327125e-05 5.09722231e-05 3.59712358e-05\n",
            "   3.23783279e-05 1.05928106e-04]\n",
            "  [9.98940885e-01 8.31833240e-05 3.05832742e-04 2.07619349e-04\n",
            "   1.18450786e-04 6.76207201e-05 6.35397300e-05 4.30721702e-05\n",
            "   3.86540050e-05 1.30995468e-04]\n",
            "  [9.98658895e-01 1.03451661e-04 3.73788789e-04 2.75287108e-04\n",
            "   1.55252987e-04 8.80494990e-05 8.09878475e-05 5.30509642e-05\n",
            "   4.72043503e-05 1.63977485e-04]\n",
            "  [9.98291075e-01 1.29547101e-04 4.59067349e-04 3.63066298e-04\n",
            "   2.04228592e-04 1.16069910e-04 1.04733597e-04 6.67222193e-05\n",
            "   5.86663009e-05 2.06812416e-04]\n",
            "  [9.97816563e-01 1.62845798e-04 5.65347611e-04 4.75478533e-04\n",
            "   2.68336822e-04 1.53882866e-04 1.36592687e-04 8.51774093e-05\n",
            "   7.38797316e-05 2.61884707e-04]\n",
            "  [9.97210324e-01 2.05054748e-04 6.96997973e-04 6.17768674e-04\n",
            "   3.51012801e-04 2.04169424e-04 1.78821239e-04 1.09830769e-04\n",
            "   9.39282691e-05 3.32077645e-04]\n",
            "  [9.96442616e-01 2.58271000e-04 8.59164458e-04 7.95988657e-04\n",
            "   4.56204434e-04 2.70119752e-04 2.34163017e-04 1.42473218e-04\n",
            "   1.20188066e-04 4.20840923e-04]\n",
            "  [9.95478332e-01 3.25050642e-04 1.05785846e-03 1.01710169e-03\n",
            "   5.88433293e-04 3.55469005e-04 3.05898662e-04 1.85332130e-04\n",
            "   1.54382476e-04 5.32264356e-04]]]\n",
            "output tokens\n",
            "[9.9547833e-01 3.2505064e-04 1.0578585e-03 1.0171017e-03 5.8843329e-04\n",
            " 3.5546900e-04 3.0589866e-04 1.8533213e-04 1.5438248e-04 5.3226436e-04]\n",
            "output tokens\n",
            "[0.00032505 0.00105786 0.0010171  0.00058843 0.00035547 0.0003059\n",
            " 0.00018533 0.00015438 0.00053226]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[9.94275987e-01 4.08488821e-04 1.30006333e-03 1.28911983e-03\n",
            "   7.52899155e-04 4.64548968e-04 3.97908356e-04 2.41140486e-04\n",
            "   1.98646754e-04 6.71176240e-04]\n",
            "  [9.70856488e-01 2.26017535e-02 7.94731837e-04 6.38030411e-04\n",
            "   7.82132789e-04 2.11565499e-03 5.39656088e-04 3.32789408e-04\n",
            "   1.13074384e-04 1.22559734e-03]\n",
            "  [9.33555305e-01 6.18622527e-02 2.49458302e-04 1.53348476e-04\n",
            "   4.16260358e-04 2.47578137e-03 3.48973379e-04 1.87317695e-04\n",
            "   3.81260797e-05 7.13168178e-04]\n",
            "  [9.99033689e-01 3.29815521e-04 7.13058471e-05 3.72539434e-05\n",
            "   1.08747925e-04 1.82844189e-04 9.42447878e-05 3.99137134e-05\n",
            "   1.41031014e-05 8.81139640e-05]\n",
            "  [9.99643087e-01 6.13962111e-05 5.23357267e-05 2.15681375e-05\n",
            "   4.74195222e-05 5.67320894e-05 4.16935800e-05 2.43334307e-05\n",
            "   1.04313403e-05 4.10033608e-05]\n",
            "  [9.99773204e-01 2.73519618e-05 4.74889675e-05 1.73044791e-05\n",
            "   2.85200895e-05 2.76328155e-05 2.40994250e-05 1.69069444e-05\n",
            "   9.17080706e-06 2.83189584e-05]\n",
            "  [9.99813616e-01 1.89616094e-05 4.79099908e-05 1.69128343e-05\n",
            "   2.16859844e-05 1.80376828e-05 1.70739568e-05 1.31475326e-05\n",
            "   8.59266402e-06 2.40801583e-05]\n",
            "  [9.99822199e-01 1.65730944e-05 5.14529274e-05 1.87070254e-05\n",
            "   1.94840686e-05 1.44443675e-05 1.42049230e-05 1.12785674e-05\n",
            "   8.43404723e-06 2.32128514e-05]\n",
            "  [9.99813497e-01 1.65627589e-05 5.76098719e-05 2.23862353e-05\n",
            "   1.97369900e-05 1.33917520e-05 1.33596459e-05 1.05423369e-05\n",
            "   8.64380036e-06 2.43245831e-05]\n",
            "  [9.99791205e-01 1.79875497e-05 6.64603504e-05 2.81506382e-05\n",
            "   2.17991274e-05 1.38127889e-05 1.37813413e-05 1.05970385e-05\n",
            "   9.22650179e-06 2.70304608e-05]\n",
            "  [9.99755323e-01 2.06134555e-05 7.83775176e-05 3.64787011e-05\n",
            "   2.56100029e-05 1.54010158e-05 1.52337570e-05 1.13096085e-05\n",
            "   1.02162303e-05 3.13315650e-05]\n",
            "  [9.99704421e-01 2.44710900e-05 9.39418314e-05 4.80709314e-05\n",
            "   3.14126337e-05 1.81724190e-05 1.77260135e-05 1.26686336e-05\n",
            "   1.16765350e-05 3.74368210e-05]\n",
            "  [9.99634862e-01 2.97304214e-05 1.13925205e-04 6.38472193e-05\n",
            "   3.96658033e-05 2.23329189e-05 2.14196752e-05 1.47485644e-05\n",
            "   1.37053894e-05 4.57103451e-05]\n",
            "  [9.99542356e-01 3.66637760e-05 1.39302414e-04 8.49670323e-05\n",
            "   5.10225582e-05 2.82422516e-05 2.66019815e-05 1.76983940e-05\n",
            "   1.64419325e-05 5.66626295e-05]\n",
            "  [9.99421000e-01 4.56409798e-05 1.71279826e-04 1.12862581e-04\n",
            "   6.63348837e-05 3.64145453e-05 3.36871017e-05 2.17441375e-05\n",
            "   2.00757604e-05 7.09622036e-05]\n",
            "  [9.99263227e-01 5.71385863e-05 2.11332881e-04 1.49282452e-04\n",
            "   8.66705595e-05 4.75350498e-05 4.32313209e-05 2.71998942e-05\n",
            "   2.48589458e-05 8.94575205e-05]\n",
            "  [9.99059975e-01 7.17583753e-05 2.61253561e-04 1.96343535e-04\n",
            "   1.13337504e-04 6.24854656e-05 5.59569417e-05 3.44855143e-05\n",
            "   3.11212170e-05 1.13207447e-04]\n",
            "  [9.98799920e-01 9.02524553e-05 3.23204615e-04 2.56593135e-04\n",
            "   1.47914310e-04 8.23750961e-05 7.27821316e-05 4.41499869e-05\n",
            "   3.92891634e-05 1.43518337e-04]\n",
            "  [9.98469055e-01 1.13555907e-04 3.99785204e-04 3.33082076e-04\n",
            "   1.92290216e-04 1.08576758e-04 9.48571687e-05 5.69007534e-05\n",
            "   4.99097150e-05 1.81988842e-04]\n",
            "  [9.98050809e-01 1.42826102e-04 4.94102715e-04 4.29450156e-04\n",
            "   2.48714554e-04 1.42768229e-04 1.23606296e-04 7.36388902e-05\n",
            "   6.36784753e-05 2.30564052e-04]]]\n",
            "output tokens\n",
            "[9.9805081e-01 1.4282610e-04 4.9410271e-04 4.2945016e-04 2.4871455e-04\n",
            " 1.4276823e-04 1.2360630e-04 7.3638890e-05 6.3678475e-05 2.3056405e-04]\n",
            "output tokens\n",
            "[1.4282610e-04 4.9410271e-04 4.2945016e-04 2.4871455e-04 1.4276823e-04\n",
            " 1.2360630e-04 7.3638890e-05 6.3678475e-05 2.3056405e-04]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[9.97524559e-01 1.79489856e-04 6.09855866e-04 5.50028344e-04\n",
            "   3.19863873e-04 1.86983219e-04 1.60778320e-04 9.55013238e-05\n",
            "   8.14749947e-05 2.91599572e-04]\n",
            "  [9.87614512e-01 9.56319086e-03 3.83643870e-04 2.90538010e-04\n",
            "   3.43276683e-04 8.47215299e-04 2.24679374e-04 1.34570946e-04\n",
            "   4.52743589e-05 5.53137565e-04]\n",
            "  [9.71303046e-01 2.66543347e-02 1.29701424e-04 7.78890389e-05\n",
            "   1.94551933e-04 1.04363775e-03 1.55626549e-04 8.19551715e-05\n",
            "   1.65237489e-05 3.42782732e-04]\n",
            "  [9.99537349e-01 1.60482145e-04 3.84734594e-05 1.94724453e-05\n",
            "   5.24120987e-05 8.17262408e-05 4.20338147e-05 1.79409781e-05\n",
            "   6.73312343e-06 4.34817885e-05]\n",
            "  [9.99815404e-01 3.29956347e-05 2.92654004e-05 1.16659658e-05\n",
            "   2.49534132e-05 2.77247873e-05 1.98756516e-05 1.14600898e-05\n",
            "   5.22609207e-06 2.15248347e-05]\n",
            "  [9.99874949e-01 1.56043643e-05 2.74856520e-05 9.72488760e-06\n",
            "   1.61269290e-05 1.46643415e-05 1.24243561e-05 8.46753755e-06\n",
            "   4.82954647e-06 1.56989554e-05]\n",
            "  [9.99892235e-01 1.12633743e-05 2.85567749e-05 9.79523793e-06\n",
            "   1.29081545e-05 1.01864953e-05 9.39408892e-06 6.98265876e-06\n",
            "   4.73946056e-06 1.39293843e-05]\n",
            "  [9.99893546e-01 1.01280684e-05 3.14278950e-05 1.10711089e-05\n",
            "   1.20015638e-05 8.52325684e-06 8.20616788e-06 6.29209808e-06\n",
            "   4.84374095e-06 1.38673577e-05]\n",
            "  [9.99885559e-01 1.03302364e-05 3.58981742e-05 1.34456350e-05\n",
            "   1.24203998e-05 8.13771749e-06 7.98887049e-06 6.11116548e-06\n",
            "   5.13119994e-06 1.48812733e-05]\n",
            "  [9.99869823e-01 1.13834185e-05 4.20802098e-05 1.70737439e-05\n",
            "   1.38851465e-05 8.54939026e-06 8.43473936e-06 6.31909916e-06\n",
            "   5.61932120e-06 1.68211645e-05]\n",
            "  [9.99845743e-01 1.31791530e-05 5.02538242e-05 2.22661256e-05\n",
            "   1.64048342e-05 9.63134880e-06 9.46166801e-06 6.87894271e-06\n",
            "   6.34049775e-06 1.97300069e-05]\n",
            "  [9.99812305e-01 1.57555187e-05 6.08256269e-05 2.94665278e-05\n",
            "   2.01500752e-05 1.14166824e-05 1.11026156e-05 7.80659320e-06\n",
            "   7.34227342e-06 2.37621189e-05]\n",
            "  [9.99767244e-01 1.92314037e-05 7.43246565e-05 3.92569891e-05\n",
            "   2.54152728e-05 1.40399570e-05 1.34690299e-05 9.15931923e-06\n",
            "   8.69080395e-06 2.91612450e-05]\n",
            "  [9.99707520e-01 2.37878103e-05 9.14136908e-05 5.23752533e-05\n",
            "   3.26126210e-05 1.77230777e-05 1.67422259e-05 1.10338060e-05\n",
            "   1.04755400e-05 3.62602877e-05]\n",
            "  [9.99629498e-01 2.96667313e-05 1.12910900e-04 6.97414725e-05\n",
            "   4.22804551e-05 2.27795317e-05 2.11778297e-05 1.35701457e-05\n",
            "   1.28154043e-05 4.54917026e-05]\n",
            "  [9.99528408e-01 3.71783826e-05 1.39817945e-04 9.24920460e-05\n",
            "   5.50989462e-05 2.96277121e-05 2.71176123e-05 1.69599662e-05\n",
            "   1.58666044e-05 5.74046499e-05]\n",
            "  [9.99398232e-01 4.67137506e-05 1.73355045e-04 1.22020647e-04\n",
            "   7.19109375e-05 3.88098051e-05 3.50062401e-05 2.14581487e-05\n",
            "   1.98323378e-05 7.26871003e-05]\n",
            "  [9.99231458e-01 5.87623435e-05 2.15003980e-04 1.60027790e-04\n",
            "   9.37489458e-05 5.10159334e-05 4.54132569e-05 2.73986334e-05\n",
            "   2.49752575e-05 9.21937171e-05]\n",
            "  [9.99019027e-01 7.39341413e-05 2.66555493e-04 2.08579309e-04\n",
            "   1.21866557e-04 6.71122252e-05 5.90590389e-05 3.52136376e-05\n",
            "   3.16326550e-05 1.16979070e-04]\n",
            "  [9.98749852e-01 9.29874077e-05 3.30168958e-04 2.70174438e-04\n",
            "   1.57779621e-04 8.81745800e-05 7.68467507e-05 4.54579531e-05\n",
            "   4.02355472e-05 1.48337902e-04]]]\n",
            "output tokens\n",
            "[9.9874985e-01 9.2987408e-05 3.3016896e-04 2.7017444e-04 1.5777962e-04\n",
            " 8.8174580e-05 7.6846751e-05 4.5457953e-05 4.0235547e-05 1.4833790e-04]\n",
            "output tokens\n",
            "[9.2987408e-05 3.3016896e-04 2.7017444e-04 1.5777962e-04 8.8174580e-05\n",
            " 7.6846751e-05 4.5457953e-05 4.0235547e-05 1.4833790e-04]\n",
            "1\n",
            "(1, 20, 10)\n",
            "[[[9.98409986e-01 1.16862502e-04 4.08437889e-04 3.47828842e-04\n",
            "   2.03315998e-04 1.15528994e-04 9.99001350e-05 5.88385337e-05\n",
            "   5.13319210e-05 1.87853730e-04]\n",
            "  [9.92119193e-01 6.07364485e-03 2.60349392e-04 1.90168386e-04\n",
            "   2.21645780e-04 5.19474444e-04 1.41551121e-04 8.34866587e-05\n",
            "   2.80896711e-05 3.62398365e-04]\n",
            "  [9.81658518e-01 1.70168504e-02 9.11699826e-05 5.38522909e-05\n",
            "   1.29304739e-04 6.54377160e-04 1.01287653e-04 5.28005694e-05\n",
            "   1.06449588e-05 2.31123660e-04]\n",
            "  [9.99684334e-01 1.10489083e-04 2.78534917e-05 1.38079940e-05\n",
            "   3.57660574e-05 5.34920982e-05 2.76395822e-05 1.18709941e-05\n",
            "   4.61269428e-06 3.00704287e-05]\n",
            "  [9.99868751e-01 2.39424626e-05 2.15991913e-05 8.42829741e-06\n",
            "   1.78268219e-05 1.90228457e-05 1.35163118e-05 7.76978595e-06\n",
            "   3.67100279e-06 1.53851597e-05]\n",
            "  [9.99908209e-01 1.16872052e-05 2.06680252e-05 7.17418425e-06\n",
            "   1.19664019e-05 1.05121626e-05 8.79815434e-06 5.92617198e-06\n",
            "   3.48107028e-06 1.15522907e-05]\n",
            "  [9.99918938e-01 8.61717126e-06 2.18175956e-05 7.34617970e-06\n",
            "   9.84247981e-06 7.54813209e-06 6.88123100e-06 5.03602450e-06\n",
            "   3.49733591e-06 1.04840919e-05]\n",
            "  [9.99918461e-01 7.86445617e-06 2.43299892e-05 8.40340999e-06\n",
            "   9.32140483e-06 6.46648550e-06 6.16716898e-06 4.65399808e-06\n",
            "   3.64775360e-06 1.06173347e-05]\n",
            "  [9.99911189e-01 8.10738948e-06 2.80921140e-05 1.02924450e-05\n",
            "   9.76151750e-06 6.27401141e-06 6.11556698e-06 4.61081163e-06\n",
            "   3.92935635e-06 1.15393977e-05]\n",
            "  [9.99897957e-01 9.00279701e-06 3.32171658e-05 1.31462857e-05\n",
            "   1.09898228e-05 6.66020560e-06 6.53943243e-06 4.83912254e-06\n",
            "   4.35977927e-06 1.31648922e-05]\n",
            "  [9.99878526e-01 1.04803285e-05 3.99441524e-05 1.72137297e-05\n",
            "   1.30320759e-05 7.54971325e-06 7.39701909e-06 5.32424610e-06\n",
            "   4.96762550e-06 1.55433627e-05]\n",
            "  [9.99851465e-01 1.25777942e-05 4.86112440e-05 2.28461195e-05\n",
            "   1.60305935e-05 8.97783229e-06 8.72428063e-06 6.08618666e-06\n",
            "   5.79267771e-06 1.88054528e-05]\n",
            "  [9.99815404e-01 1.53942165e-05 5.96542850e-05 3.05038393e-05\n",
            "   2.02206902e-05 1.10531228e-05 1.06130310e-05 7.17362809e-06\n",
            "   6.88859427e-06 2.31495542e-05]\n",
            "  [9.99767601e-01 1.90769842e-05 7.36181173e-05 4.07722328e-05\n",
            "   2.59290628e-05 1.39495551e-05 1.32070345e-05 8.66402024e-06\n",
            "   8.32674414e-06 2.88435131e-05]\n",
            "  [9.99705255e-01 2.38215598e-05 9.11738825e-05 5.43843453e-05\n",
            "   3.35820623e-05 1.79111667e-05 1.67066537e-05 1.06672842e-05\n",
            "   1.02010472e-05 3.62340397e-05]\n",
            "  [9.99624610e-01 2.98778305e-05 1.13144146e-04 7.22503464e-05\n",
            "   4.37201961e-05 2.32635775e-05 2.13789881e-05 1.33326866e-05\n",
            "   1.26342147e-05 4.57613460e-05]\n",
            "  [9.99520779e-01 3.75603522e-05 1.40532080e-04 9.54926873e-05\n",
            "   5.70165612e-05 3.04299210e-05 2.75717484e-05 1.68582574e-05\n",
            "   1.57854811e-05 5.79776060e-05]\n",
            "  [9.99387741e-01 4.72629108e-05 1.74557790e-04 1.25489212e-04\n",
            "   7.43004857e-05 3.99513592e-05 3.57313511e-05 2.15033815e-05\n",
            "   1.98604248e-05 7.35709255e-05]\n",
            "  [9.99218345e-01 5.94768608e-05 2.16700879e-04 1.63924531e-04\n",
            "   9.65860600e-05 5.25112264e-05 4.64249970e-05 2.76045776e-05\n",
            "   2.51232777e-05 9.33931879e-05]\n",
            "  [9.99003232e-01 7.48133898e-05 2.68750242e-04 2.12849292e-04\n",
            "   1.25106875e-04 6.89639201e-05 6.03670196e-05 3.55948760e-05\n",
            "   3.19119754e-05 1.18493997e-04]]]\n",
            "output tokens\n",
            "[9.9900323e-01 7.4813390e-05 2.6875024e-04 2.1284929e-04 1.2510688e-04\n",
            " 6.8963920e-05 6.0367020e-05 3.5594876e-05 3.1911975e-05 1.1849400e-04]\n",
            "output tokens\n",
            "[7.4813390e-05 2.6875024e-04 2.1284929e-04 1.2510688e-04 6.8963920e-05\n",
            " 6.0367020e-05 3.5594876e-05 3.1911975e-05 1.1849400e-04]\n",
            "1\n",
            "Generated summary:  obama obama obama obama syrian obama obama obama obama\n",
            "\n",
            "\n",
            "ROUGE score: \n",
            "[{'rouge-1': {'f': 0.39999999680000003, 'p': 0.25, 'r': 1.0}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.2615384615381813, 'p': 0.25, 'r': 1.0}}]\n",
            "0.39999999680000003\n",
            "0.25\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}