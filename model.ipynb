{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "colab_type": "code",
    "id": "bV27LCvjfwkR",
    "outputId": "a04607a8-4104-4fac-f7a9-bcf188644af3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "# !python -m nltk.downloader stopwords wordnet punkt averaged_perceptron_tagger\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.layers import Attention\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2feqtBEHiaS4"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omclwb_CiEZr"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=40\n",
    "EPOCHS=2\n",
    "latent_dim=128\n",
    "embedding_dim=128\n",
    "test_train_split=0.15\n",
    "build_number=\"1\"\n",
    "# LEARNING_RATE=0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gNPOLXNLiiX5"
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cchT-sW8kGP4"
   },
   "source": [
    "Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "1LLVyg34iLP5",
    "outputId": "5c7f9c18-8095-4ea8-a1ed-96d81e0494a1"
   },
   "outputs": [],
   "source": [
    "# Only needed if running on Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "colab_type": "code",
    "id": "Y3Op7xyUiHSv",
    "outputId": "4ede3aaf-b804-4c17-ec67-da51ca0ab2c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01.story</td>\n",
       "      <td>Its official US President Barack Obama want la...</td>\n",
       "      <td>Syrian official Obama climbed top tree doesnt ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            file  \\\n",
       "0           0  0001d1afc246a7964130f43ae940af6bc6c57f01.story   \n",
       "\n",
       "                                                text  \\\n",
       "0  Its official US President Barack Obama want la...   \n",
       "\n",
       "                                             summary  \n",
       "0  Syrian official Obama climbed top tree doesnt ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('./drive/My Drive/originals-l.csv')\n",
    "df = pd.read_csv('./originals-l.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "ptOkktH2CLqg",
    "outputId": "b18d889a-8154-4e55-bb8c-c8777b968dfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of       Unnamed: 0                                            file  \\\n",
       "0              0  0001d1afc246a7964130f43ae940af6bc6c57f01.story   \n",
       "1              1  0002095e55fcbd3a2f366d9bf92a95433dc305ef.story   \n",
       "2              2  00027e965c8264c35cc1bc55556db388da82b07f.story   \n",
       "3              3  0002c17436637c4fe1837c935c04de47adb18e9a.story   \n",
       "4              4  0003ad6ef0c37534f80b55b4235108024b407f0b.story   \n",
       "...          ...                                             ...   \n",
       "3995        3995  0b2f5ff6d136ed5431229f08fbf23e7fd7319ae9.story   \n",
       "3996        3996  0b30f402176c2c2315fe346252b4019b9dc619f7.story   \n",
       "3997        3997  0b32ef8b9275c4d5a0cef388c229d2a34eaef8f4.story   \n",
       "3998        3998  0b330e583d945d6db1e0dfaef689023bdf181c18.story   \n",
       "3999        3999  0b35b8df4fb055e27f21c3fc102f56202e779341.story   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Its official US President Barack Obama want la...   \n",
       "1     Usain Bolt round world championship Sunday cla...   \n",
       "2     Kansas City Missouri The General Services Admi...   \n",
       "3     Los Angeles A medical doctor Vancouver British...   \n",
       "4     Police arrest another teen Thursday sixth susp...   \n",
       "...                                                 ...   \n",
       "3995  A 23yearold exchange student attack Toronto ap...   \n",
       "3996  New York He call widow Roger Maris day ago sur...   \n",
       "3997  John Cossmans friend call cancer iron man Hes ...   \n",
       "3998  The state New Jersey impose harsher restrictio...   \n",
       "3999  A fastmoving brush fire burning south Reno Nev...   \n",
       "\n",
       "                                                summary  \n",
       "0     Syrian official Obama climbed top tree doesnt ...  \n",
       "1     Usain Bolt wins third gold world championship ...  \n",
       "2     The employee agencys Kansas City office among ...  \n",
       "3     NEW A Canadian doctor says part team examining...  \n",
       "4     Another arrest made gang rape outside Californ...  \n",
       "...                                                 ...  \n",
       "3995  A friend China sees woman attacked Toronto apa...  \n",
       "3996  Jeff Pearlman says Mark McGwire owed delivered...  \n",
       "3997  John Cossman battling cancer eight years He tu...  \n",
       "3998  Riders must 54 inches tall ride without superv...  \n",
       "3999  Fire affects 3000 acres North Washoe Valley At...  \n",
       "\n",
       "[4000 rows x 4 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ogB1RqsqreG2"
   },
   "source": [
    "Split for now so we are only aiming for one summary per text (This is now in dataprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4e3a1UjziN5g"
   },
   "outputs": [],
   "source": [
    "# print(df['summary'][0])\n",
    "# df['summary'] = df['summary'].apply(lambda x: re.sub(r'\\..*$',' ',str(x)))\n",
    "# print(df['summary'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QZzZjP4vFzVw"
   },
   "source": [
    "Remove .'s that appear in stuff like U.S.A and U.N - Eventually need to move this to dataprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "60CqA1Km6PvJ",
    "outputId": "97d25b7d-2550-4b2b-922c-dbdb103f520b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syrian official Obama climbed top tree doesnt know get Obama sends letter heads House Senate Obama seek congressional approval military action Syria Aim determine whether CW used says U.N. spokesman\n",
      "Syrian official Obama climbed top tree doesnt know get Obama sends letter heads House Senate Obama seek congressional approval military action Syria Aim determine whether CW used says UN spokesman\n"
     ]
    }
   ],
   "source": [
    "print(df['summary'][0])\n",
    "df['summary'] = df['summary'].apply(lambda x: re.sub(r'\\.','',str(x)))\n",
    "print(df['summary'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmYf4I1bGA8N"
   },
   "source": [
    "Check for rows with null values in them, and copy these into a new dataframe (df1). Drop any rows in df1 from df to ensure no NaN valued rows are present/\n",
    "\n",
    "*Note. using simply dropna(how='any') does not seem to drop any of the rows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "5Ws0uSZv8Xnw",
    "outputId": "1fd60887-8a8d-45f4-8058-461451510fdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(4000, 4)\n",
      "(3, 4)\n",
      "(3997, 4)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().values.any())\n",
    "print(df.shape)\n",
    "\n",
    "df1 = df[df.isna().any(axis=1)]\n",
    "print(df1.shape)\n",
    "\n",
    "df.drop(df1.index, axis=0,inplace=True)\n",
    "print(df.shape)\n",
    "print(df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSVW1P-Ji_7R"
   },
   "source": [
    "Word Count Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "M72pGpsDjCrc",
    "outputId": "a0a964c6-2199-4af9-bcca-483858455fbf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in df['text']:\n",
    "      text_word_count.append(len(i.split(' ')))\n",
    "\n",
    "for i in df['summary']:\n",
    "      summary_word_count.append(len(i.split(' ')))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.ylabel('Documents')\n",
    "plt.xlabel('Word Count')\n",
    "plt.savefig('word_count_distro' + str(build_number) + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nNZ2tVpljHTc"
   },
   "source": [
    "Max Text Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "3T01Jf-XjGKO",
    "outputId": "9391bff2-c725-4c04-be4b-1787052d38a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7823\n",
      "333\n"
     ]
    }
   ],
   "source": [
    "max_text_len = max([len(txt) for txt in df['text']])\n",
    "max_summary_len = max([len(txt) for txt in df['summary']])\n",
    "print(max_text_len)\n",
    "print(max_summary_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CGl1z0OFjTsr"
   },
   "source": [
    "### Training-Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SwmBST04juu6"
   },
   "source": [
    "X - Articles text </br>\n",
    "Y - Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f1_YrHcDjN6e"
   },
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X = np.array(df['text'])\n",
    "Y = np.array(df['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "XGHJXwaojYAV",
    "outputId": "b7e01904-a40c-48aa-c9dd-e8edbdc72303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3397,)\n",
      "(600,)\n",
      "(3397,)\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "x_tr,x_val,y_tr,y_val=train_test_split(X,Y,test_size=test_train_split,random_state=0,shuffle=True)\n",
    "print(x_tr.shape)\n",
    "print(x_val.shape)\n",
    "print(y_tr.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SzWpoc9OjjdV"
   },
   "source": [
    "### Word Embeddings - Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iLVdVklnjq1i"
   },
   "source": [
    "X Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7qUrNpbjpI2"
   },
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "text = df['text']\n",
    "\n",
    "for row in text: \n",
    "  for word in row.split(\" \"):\n",
    "    if word not in word_dict:\n",
    "      word_dict[word] = 1\n",
    "    else:\n",
    "      word_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "6qbg_6TKj4HK",
    "outputId": "87fc2439-5039-480b-a9d3-0a23b4020b78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72199\n"
     ]
    }
   ],
   "source": [
    "# #prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=len(word_dict)) \n",
    "x_tokenizer.fit_on_texts(list(X))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1\n",
    "print(x_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DdwGLWiRloV9"
   },
   "outputs": [],
   "source": [
    "with open('xtokenizer.pickle', 'wb') as handle:\n",
    "  pickle.dump(x_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NsdijM3j6RJ"
   },
   "source": [
    "Y Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CG6Q2G-Wj79A"
   },
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "text = df['summary']\n",
    "\n",
    "for row in text: \n",
    "  for word in row.split(\" \"):\n",
    "    if word not in word_dict:\n",
    "      word_dict[word] = 1\n",
    "    else:\n",
    "      word_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "C5ugAAnIj91g",
    "outputId": "7dba3458-13b0-4c88-f300-e120ac7a024d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23202\n"
     ]
    }
   ],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=len(word_dict)) \n",
    "y_tokenizer.fit_on_texts(list(Y))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1\n",
    "print(y_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JzpeT5fXlp3-"
   },
   "outputs": [],
   "source": [
    "with open('ytokenizer.pickle', 'wb') as handle:\n",
    "  pickle.dump(y_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zntqptcwj_lh"
   },
   "source": [
    "## Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uc0JOUvqkWUL"
   },
   "source": [
    "#### Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "id": "9dx-9BT6kZMw",
    "outputId": "d63bb2a5-6f96-475a-ed30-62bc910b40f9"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc,embedding_dim,trainable=True)(encoder_inputs)\n",
    "#encoder lstm \n",
    "encoder_lstm = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8JJUPBdfkdlb"
   },
   "source": [
    "#### Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLgYfdF3kb1A"
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "                                                          \n",
    "#dense layer\n",
    "decoder_dense = Dense(y_voc, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rIpBF_fAkfuG"
   },
   "source": [
    "#### Combined LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "ASIlTOT_khrn",
    "outputId": "2040df81-aa4a-46d0-d333-3ca27ae0e22a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 7823)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 7823, 128)    9241472     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 128)    2969856     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 7823, 128),  131584      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 128),  131584      embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 23202)  2993058     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 15,467,554\n",
      "Trainable params: 15,467,554\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "gMQ1ZrF0ksMT",
    "outputId": "b9e0f087-6ffe-4e9c-bf9a-9cd44cb5183a"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o12XRjJykuA-"
   },
   "source": [
    "Early Stopping Callback to ensure we stop when Validation Loss is lowest - minimises risk of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6R-qwZoNkspo"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "colab_type": "code",
    "id": "Pbnxf9ZWk4I0",
    "outputId": "75fa86fc-41d5-40f5-b8be-adc5e841ea69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /bham/modules/roots/neural-comp/2019-20/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /bham/modules/roots/neural-comp/2019-20/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 3397 samples, validate on 600 samples\n",
      "Epoch 1/2\n",
      "3397/3397 [==============================] - 831s 245ms/step - loss: 2.1687 - val_loss: 0.7860\n",
      "Epoch 2/2\n",
      "1680/3397 [=============>................] - ETA: 6:40 - loss: 0.7761"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:], batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[es], validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HEkRn71fk7up"
   },
   "outputs": [],
   "source": [
    "model.save('model' + str(build_number) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "N52zaYcKlAXE",
    "outputId": "ecb37c11-d7b1-4dd6-b2f6-818668982686"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngMKcBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.savefig('loss' + str(build_number) + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gxSFAxiWlDad"
   },
   "source": [
    "## Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cm1b46qtlFnT"
   },
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1Q7SWH_lGxE"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_inputs)\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c], [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "biBjzpLQlPhf",
    "outputId": "2860850a-d076-4102-9f76-e0f1b63899bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 7301)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 7301, 128)         3803136   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 7301, 128), (None 131584    \n",
      "=================================================================\n",
      "Total params: 3,934,720\n",
      "Trainable params: 3,934,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "colab_type": "code",
    "id": "wmvKd7pNlQXs",
    "outputId": "ae6d08b1-ccca-421d-9597-40e81cb9ea2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 128)    489728      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 128),  131584      embedding_2[1][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 3826)   493554      lstm_2[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,114,866\n",
      "Trainable params: 1,114,866\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywir6L6wlUE-"
   },
   "source": [
    "### Methhods for Reversing Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qoKuk0dElZZm"
   },
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jSR-0MHclb0G"
   },
   "source": [
    "### Summarisation Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WYZgAXelbLU"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq): \n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, max_summary_len))\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "      output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c]) \n",
    "      # print(output_tokens[0, -1, :][1:])\n",
    "      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "      # print(sampled_token_index)\n",
    "      # print(sampled_token_index)\n",
    "      if (sampled_token_index != 0 ):\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_token\n",
    "      else :\n",
    "        stop_condition = True\n",
    "      if (len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "              stop_condition = True\n",
    "       # Update the target sequence (of length 1).\n",
    "      # target_seq = np.zeros((1,1))\n",
    "      target_seq = np.zeros((1, max_summary_len))\n",
    "      target_seq[0, sampled_token_index] = 1\n",
    "\n",
    "      # Update internal states\n",
    "      e_h, e_c = h, c\n",
    "      \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STnQkiZzlhbb"
   },
   "source": [
    "## Test Model Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AisRsa573_L3"
   },
   "source": [
    "Note: *I think there isn't enough data being passed in and so the argmax value always is 0 - it can't learn what should be next*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "IC1oCOOHlgjh",
    "outputId": "c93bf6f0-f462-4ff3-b0c2-9ac79671518a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: a prosecute attorney greet jury george zimmerman trial monday quote full expletive adversary decide appropriate tell juror knockknock joke and begin opening statement zimmermans longanticipated murder trial in case ignite national debate gun law race relation zimmerman neighborhood watch captain accuse seconddegree murder fatal shoot 17yearold trayvon martin february 2012 sanford florida prosecutor john guys first word sixwoman jury may raise eyebrow good morning fg punk get away guy quote zimmerman these word grown man mouth follow boy didnt know those word mine zimmerman guy say get car pistol two flashlight follow trayvon benjamin martin walk home 7eleven arm fruit drink bag candy eventually two become entangle ground fight a witness say martin top zimmerman guy say the defendant claim trayvon martin top say go die tonight say guy nobody heard guy told juror witness saw happen night shoot begin end witnesses saw slice happen say we confident end trial know head heart stomach george zimmerman shoot trayvon martin guy say he shot bad reason want fast fact trayvon martin shoot in first day testimony juror heard witness recount martins trip convenience store zimmermans call complain suspicious person walk neighborhood martins kill call previous august zimmerman report allege burglary police proceedings end day defense attorney mark omara object earlier call prosecutor argue necessary explain zimmermans remark burglar get away the martin family sat watch proceeding behind state attorney angela corey before witness testimony begin judge debra nelson deny defense request martins father tracy martin leave courtroom tracy martin potential witness potential witness force sit outside courtroom keep testimony taint witness but nextofkin victim allow remain court even theyre expect testify omara also accuse tracy martin use obscenity toward friend zimmermans hold door hearing two week ago the friend timothy tucholski testify hadnt want make issue i wasnt planning come i dont want sit say but nelson deny request martin remain court zimmermans parent cover rule regard potential witness sit outside benjamin crump lawyer martins parent at one point martins father begin cry guy detailed officer try save son life zimmerman mostly star straight ahead without sign emotion following guys statement defense attorney don west come forward woo jury as begin told knockknock joke but fail win laugh knock knock whos george zimmerman george zimmerman good youre jury say later west apologize no bad joke i promise told juror i convince delivery west quickly get business make case zimmerman force act selfdefense save life the evidence show sad case monster george zimmerman guilty murder he shot trayvon martin viciously attack with help powerpoint visuals west spent hour hammer home argument he broke zimmermans 911 call first report see martin told follow little george zimmerman know time less 10 minute first see travyon martin george zimmerman would suckered punch face head pound concrete wind shoot tragically kill trayvon martin west told juror west also deconstruct 911 call neighbor make possible hear scream shot background west say sound fatal bullet as dramatic record audio fill courtroom zimmerman show emotion martins mother left courtroom at moment actually become physical trayvon martin i use word trayvon martin decide confront george zimmerman west say that instead go home he plenty time this 60 70 yard plenty time he couldve go back forth four five time west quote witness name john good described fight he call ground pound martin say top zimmerman beating he saw enough serious west say zimmerman cry help look good say help but beating continued good go inside home call 911 west say there shot shortly afterward accord west zimmerman say martin beating i shot west also dispute prosecution claim martin unarmed travyon martin arm concrete sidewalk use smash george zimmermans head say west no different picked brick smash head wall that deadly weapon west show juror photo take zimmerman fight what really see picture evidence lump west say the big knot side head consistent head slam concrete allfemale jury try zimmerman among first prosecution witness call 911 dispatcher take zimmermans call shoot seat noffke testify train give general command instead direct order people when zimmerman say follow martin noffke told okay dont need noffke told prosecutor he liable direct order give someone on crossexamination defense attorney omara point noffke ask zimmerman which way run if tell somebody twice let know person theyre concerned anything else think theyre go keep eye ask omara i cant answer say noffke you tell twice let know guy anything else say omara yes sir say noffke noffke go say want location suspect officer never told zimmerman follow keep eye martin shortly court get way martins mother sybrina fulton spoke reporter ask people pray family i dont want mother experience im go judge no state expert testimony 911 call martin black zimmerman identifies hispanic in cnn poll release monday morning 62 respondent say charge zimmerman probably definitely true \n",
      "Original summary: defense lawyer apologizes telling joke opening statements \n",
      "Generated summary: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,1):\n",
    "    print(\"Article:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    x_i = x_tr[i].reshape(1,max_text_len)\n",
    "    print(\"Generated summary:\",decode_sequence(x_i))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JNy_KJPb4PXc"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMRIXeuz8hYn"
   },
   "source": [
    "Using ROUGE (Recall-Orientated Understanding Gisting Evaluation) to evaluate the generated summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqM1FoWQFsqJ"
   },
   "outputs": [],
   "source": [
    "def get_overlapping_words(x, y):\n",
    "  num=0\n",
    "  x = nltk.word_tokenize(x)\n",
    "  y = nltk.word_tokenize(y)\n",
    "  for word in y:\n",
    "    if word in x:\n",
    "      num = num+1\n",
    "      x.remove(word)\n",
    "    else:\n",
    "      return num\n",
    "\n",
    "def precision(target, generated):\n",
    "  length = len(target)\n",
    "  for i in range (0, length):\n",
    "    num_overlapping_words = get_overlapping_words(target[i], generated[i])\n",
    "    generated_summary_len = len(generated[i])\n",
    "    if generated_summary_len == 0 :\n",
    "        return 0.0\n",
    "    else : \n",
    "      return num_overlapping_words / generated_summary_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nwTD6W5kFmvk"
   },
   "source": [
    "### For Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "OUr2YcMoDGEt",
    "outputId": "975bec9a-bdd2-4ead-aa41-9a8eb4bb44bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\n"
     ]
    }
   ],
   "source": [
    "print(len(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "colab_type": "code",
    "id": "-BKXHKbaDS8G",
    "outputId": "e57e5de1-e341-4d9e-d5ff-eeee0baa7d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "val_target_summary = []\n",
    "val_generated_summary = []\n",
    "# x_val_len = len(x_val)\n",
    "x_val_len = 1\n",
    "for i in range(0,x_val_len):\n",
    "  print(i)\n",
    "  val_target_summary.append((y_val[i]))\n",
    "  x_i = x_val[i].reshape(1,max_text_len)\n",
    "  val_generated_summary.append(decode_sequence(x_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "DuzxQo3E4SlK",
    "outputId": "2f3d240c-5169-4bef-8800-3c85b2530cfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"precision : \" + str(precision(tr_target_summary, tr_generated_summary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KiHBkkwmFTPt"
   },
   "source": [
    "### For Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "B2QGuitHFZD1",
    "outputId": "5d8559aa-68b2-4492-c879-57b5a2e2e1ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "val_target_summary = []\n",
    "val_generated_summary = []\n",
    "# x_val_len = len(x_val)\n",
    "x_val_len = 1\n",
    "for i in range(0,x_val_len):\n",
    "  print(i)\n",
    "  val_target_summary.append((y_val[i]))\n",
    "  x_i = x_val[i].reshape(1,max_text_len)\n",
    "  val_generated_summary.append(decode_sequence(x_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "id": "S9n0nDG-F6KN",
    "outputId": "b31a3a45-9b75-410a-83c5-f75a3cea0dfe"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-22d0f559d8f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_target_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_generated_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-87698e18893e>\u001b[0m in \u001b[0;36mprecision\u001b[0;34m(target, generated)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mnum_overlapping_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_overlapping_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mgenerated_summary_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgenerated_summary_len\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-87698e18893e>\u001b[0m in \u001b[0;36mget_overlapping_words\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_overlapping_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[1;32m     94\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# Standard word tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \"\"\"\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \"\"\"\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \"\"\"\n\u001b[1;32m   1315\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0msl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \"\"\"\n\u001b[1;32m    311\u001b[0m     \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_tok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "# pre = precision(val_target_summary, val_generated_summary)\n",
    "# print(pre)\n",
    "# print(\"precision : \" + str(pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "faHKW5pUF9KH"
   },
   "source": [
    "# Inputting New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srBPE2ZxZH72"
   },
   "outputs": [],
   "source": [
    "def getpos(word):\n",
    "  pos = nltk.pos_tag([word])[0][1][0]\n",
    "  wordnet_conv = {\"J\": wn.ADJ, \"N\": wn.NOUN, \"V\": wn.VERB, \"R\": wn.ADV}\n",
    "  if pos in wordnet_conv.keys():\n",
    "    return wordnet_conv.get(pos)\n",
    "  return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5aEv4W8ZM81"
   },
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  text_tokenized = inp_df['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "  print(\"lemmatize with pos\")\n",
    "  for i in range(0,len(text_tokenized)):\n",
    "    text_lemmatized = []\n",
    "    for word in text_tokenized[i]:\n",
    "      pos = getpos(word)\n",
    "      if pos != \"\":\n",
    "        lemma = lemmatizer.lemmatize(word, pos)\n",
    "        text_lemmatized.append(lemma)\n",
    "      else :\n",
    "        text_lemmatized.append(word)\n",
    "    text_lemmatized = ' '.join(map(str, text_lemmatized))\n",
    "    inp_df['text'][i] = text_lemmatized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "colab_type": "code",
    "id": "5tlZ-4XXuctn",
    "outputId": "06fd2777-a9d5-4479-c8a6-3fbf3bc7d9f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)  Earlier this year, Delta Air Lines ann...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text summary\n",
       "0  (CNN)  Earlier this year, Delta Air Lines ann...        "
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = \"(CNN)  Earlier this year, Delta Air Lines announced a rethink on reclining seats. In an effort to disrupt fewer passengers' travel experiences, Delta said it'd begin revamping some of its jets to reduce the recline of coach seats from four inches to two inches and the recline of first class seats from 5.5 inches to 3.5 inches. For those who abhor the recline option, it's a small step. And for those who value it, well, it's a compromise. This seemingly innocuous topic is one where there are very much two minds on what's acceptable and what's not. Two CNN Travel staffers engage in a friendly debate about seat recline. Your seat. Your decision. Stacey Lastoe, senior editor at CNN Travel, is of above-average height and makes no apology about reclining; it's her right as a plane, train and bus passenger. She encourages the person sitting in front of her to recline as well. On the first leg of my flight to Japan for my honeymoon, my husband and I got upgraded to first class. Although it would just be a few hours in the sky en route to Dallas, I was excited about sipping Champagne, sitting back and relaxing. Flute in hand, I pushed back to recline my seat for maximum relaxation. But it would not budge; I appeared to be stuck in a dysfunctional seat. Or was I? Turns out the gentleman behind me had a dog in a crate down between his legs, positioned so the seat in front of his -- my seat -- had nowhere to go. Because we were newlyweds and loving every moment of it, I did not mind when my husband turned to the man and told him his wife wanted to recline her seat and asked if he could please rearrange his dog crate to allow for everyones comfort.\"\n",
    "inp_df = pd.DataFrame(columns=['text', 'summary'])\n",
    "inp_df = inp_df.append({'text': str(input1), 'summary': \"\"}, ignore_index=True)\n",
    "inp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyDVNd3pvxIX"
   },
   "outputs": [],
   "source": [
    "inp_df['text'] = inp_df['text'].apply(lambda x: re.sub(r'\\(CNN\\)|--|[^\\w\\s\\.]','',x)).apply(lambda x: re.sub(r'(\\.(?=[\\s\\r\\n]|$))','',x)).apply(lambda x: re.sub(r'\\n',' ',x)).apply(lambda x: re.sub(r'\\.','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5WyRVL-DGACF"
   },
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "inp_df['text'] = inp_df['text'].apply(lambda x: nltk.word_tokenize(x)).apply(lambda x: \" \".join([word for word in x if not word in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "Nd2C6wFAxU3K",
    "outputId": "b376cba2-7e6d-4bec-bb18-4728cfe5e1d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatize with pos\n",
      "0    Earlier year Delta Air Lines announce rethink ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#lemmatize\n",
    "lemmatization(inp_df['text'])\n",
    "print(inp_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "vwj2UIuQ20Hl",
    "outputId": "635efab9-66ef-4d2b-ec07-a69b07d0ed39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Earlier year Delta Air Lines announce rethink recline seat In effort disrupt few passenger travel experience Delta say itd begin revamp jet reduce recline coach seat four inch two inch recline first class seat 55 inch 35 inch For abhor recline option small step And value well compromise This seemingly innocuous topic one much two mind whats acceptable whats Two CNN Travel staffer engage friendly debate seat recline Your seat Your decision Stacey Lastoe senior editor CNN Travel aboveaverage height make apology recline right plane train bus passenger She encourages person sit front recline well On first leg flight Japan honeymoon husband I get upgraded first class Although would hour sky en route Dallas I excite sip Champagne sit back relax Flute hand I push back recline seat maximum relaxation But would budge I appear stuck dysfunctional seat Or I Turns gentleman behind dog crate leg position seat front seat nowhere go Because newlywed love every moment I mind husband turn man told wife want recline seat ask could please rearrange dog crate allow everyones comfort']\n"
     ]
    }
   ],
   "source": [
    "seq = np.array(inp_df['text'])\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Xx7fUFkZ0aAr",
    "outputId": "209a9b33-800e-43c9-bfcb-8e7de055e165"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Summary: \n"
     ]
    }
   ],
   "source": [
    "seq_tokenizer = x_tokenizer.texts_to_sequences(seq)\n",
    "#padding zero upto maximum length\n",
    "seq_tokenizer_padded = pad_sequences(seq_tokenizer,  maxlen=max_text_len, padding='post')\n",
    "\n",
    "summary = decode_sequence(seq_tokenizer_padded)\n",
    "\n",
    "# print(seq2text(seq))\n",
    "print(\"---\")\n",
    "print(\"Summary: \" + summary)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
